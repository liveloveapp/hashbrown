<?xml version="1.0" encoding="UTF-8" ?>
<15>
    <Session_ID>911821</Session_ID>
    <Title>A2A & MCP: Automating Business Processes with LLMs</Title>
    <Description>Ever wished your webhooks could think for themselves? Join us to discover how A2A agents can transform passive webhook endpoints into intelligent workflow processors.

In this session, we'll show you how to build a system that automatically spawns AI Agents to handle incoming webhooks. 

Using Google's Agent-to-Agent framework and MCP, you'll learn how to create dynamic AI agents that respond to events, communicate with external services, and make decisions based on content analysis.

See the future of workflow automation where webhooks don't just trigger actions—they trigger intelligence!</Description>
    <Session_Format>Workshop</Session_Format>
    <Level>Advanced</Level>
    <Scope>Technical deep dive</Scope>
    <Assigned_Track></Assigned_Track>
    <Room>Foothill G1&2: Workshops</Room>
    <Scheduled_At>3 Jun 2025 09:00 AM</Scheduled_At>
    <Speakers>Damien Murphy</Speakers>
    <Companies>Bench Computing</Companies>
    
    
</15>
<16>
    <Session_ID>915684</Session_ID>
    <Title>Beyond Benchmarks: Strategies for Evaluating LLMs in Production</Title>
    <Description>Accuracy scores and leaderboard metrics look impressive—but production-grade AI requires evals that reflect real-world performance, reliability, and user happiness. Traditional benchmarks rarely help you understand how your LLM will perform when embedded in complex workflows or agentic systems. How can you realistically and adequately measure reasoning quality, agent consistency, MCP integration, and user-focused outcomes?

In this practical, example-driven talk, we'll go beyond standard benchmarks and dive into tangible evaluation strategies using various open-source frameworks like GuideLLM and lm-eval-harness. You'll see concrete examples of how to create custom eval suites tailored to your use case, integrate human-in-the-loop feedback effectively, and implement agent reliability checks that reflect production conditions. Walk away with actionable insights and best practices for evaluating and improving your LLMs, ensuring they meet real-world expectations—not just leaderboard positions!</Description>
    <Session_Format>Workshop</Session_Format>
    <Level>Intermediate</Level>
    <Scope>Technical deep dive</Scope>
    <Assigned_Track>Workshop</Assigned_Track>
    <Room>Nobhill A&B: Workshops</Room>
    <Scheduled_At>3 Jun 2025 09:00 AM</Scheduled_At>
    <Speakers>Taylor Jordan Smith</Speakers>
    
    
    
</16>
<17>
    <Session_ID>915928</Session_ID>
    <Title>How LLMs work for Web Devs: GPT in 600 lines of Vanilla JS</Title>
    <Description>Don't be intimidated. Modern AI can feel like magic, but underneath the hood are principles that web developers can understand, even if you don't have a machine learning background. In this workshop, we'll explore a complete GPT-2 inference implementation built entirely in Vanilla JS. This JavaScript translation of the popular "Spreadsheets-are-all-you-need" approach will let you debug and step through a real LLM line by line without the overhead of learning a new language, framework, or even IDE.

All the major LLMs, including ChatGPT, Claude, DeepSeek, and Llama, inherit from GPT-2's architecture, making this exploration a solid foundation to understand modern AI systems and comprehend the latest research.

While we won't have time to cover *everything*, you'll gain the essential knowledge to understand the key concepts that matter when building with LLMs, including how they:

-Convert raw text into meaningful tokens
- Represent semantic meaning through vector embeddings
- Train neural networks through gradient descent
- Generate text with sampling algorithms like top-k, top-p, and temperature

This intense but beginner-friendly workshop is designed specifically for web developers diving into ML and AI for the first time. It’s your "missing AI degree" in just two hours. You'll walk away with an intuitive mental model of how Transformers work that you can apply immediately to your own LLM-powered projects.</Description>
    <Session_Format>Workshop</Session_Format>
    <Level>Introductory and overview</Level>
    <Scope>Technical deep dive</Scope>
    <Assigned_Track>Workshop</Assigned_Track>
    <Room>Golden Gate Ballroom A: Workshops</Room>
    <Scheduled_At>3 Jun 2025 09:00 AM</Scheduled_At>
    <Speakers>Ishan Anand</Speakers>
    <Companies>Independent</Companies>
    
    
</17>
<18>
    <Session_ID>916066</Session_ID>
    <Title>Introduction to LLM serving with SGLang</Title>
    <Description>Do you want to learn how to serve models like DeepSeek and Qwen with SOTA speeds on launch day? SGLang is an open-source fast serving framework for LLMs and VLMs that generates trillions of tokens per day at companies like xAI, AMD, and Meituan. This workshop guides AI engineers who are familiar with serving models using frameworks like vLLM, Ollama, and TensorRT-LLM through deploying and optimizing their first model with SGLang, as well as providing guidance on when SGLang is the appropriate tool for LLM workloads.</Description>
    <Session_Format>Workshop</Session_Format>
    <Level>Intermediate</Level>
    <Scope>Technical deep dive</Scope>
    <Assigned_Track>Workshop</Assigned_Track>
    <Room>SOMA: Workshops</Room>
    <Scheduled_At>3 Jun 2025 09:00 AM</Scheduled_At>
    <Speakers>Philip Kiely, Yineng Zhang</Speakers>
    <Companies>Baseten, Baseten</Companies>
    
    
</18>
<19>
    <Session_ID>929509</Session_ID>
    <Title>Kernels, RL, Reasoning, Reward Functions & Quantization</Title>
    <Description>Discover if writing custom kernels is still worth it, explore how to do Reinforcement Learning (RL) and reward functions properly, and learn why quantization is key to local LLMs - plus tips to gain accuracy.</Description>
    <Session_Format>Workshop</Session_Format>
    <Level>Advanced</Level>
    <Scope>Technical deep dive</Scope>
    <Assigned_Track>Workshop</Assigned_Track>
    <Room>Foothill C: Workshops</Room>
    <Scheduled_At>3 Jun 2025 09:00 AM</Scheduled_At>
    <Speakers>Daniel Han</Speakers>
    <Companies>Unsloth AI</Companies>
    
    
</19>
<20>
    <Session_ID>933714</Session_ID>
    <Title>Intro to GraphRAG</Title>
    <Description>Learn the foundations of GraphRAG, starting with knowledge graph construction and then common retrieval patterns.</Description>
    <Session_Format>Workshop</Session_Format>
    <Level>Introductory and overview</Level>
    <Scope>Technical deep dive</Scope>
    <Assigned_Track></Assigned_Track>
    <Room>Golden Gate Ballroom C: Workshops</Room>
    <Scheduled_At>3 Jun 2025 09:00 AM</Scheduled_At>
    <Speakers>Zach Blumenfeld</Speakers>
    <Companies>Neo4j </Companies>
    
    
</20>
<21>
    <Session_ID>936933</Session_ID>
    <Title>Forget RAG Pipelines—Build Production-Ready AI Agents in 15 Minutes</Title>
    <Description>Want to take advantage of your data, but don't want to reinvent RAG infrastructure? Join our workshop and see how you can deploy Agentic RAG in minutes using Contextual AI's managed RAG solution. We'll explore how Contextual handles intelligent parsing and chunking of your data, retrieves information with state of the art accuracy, and generates responses with a multi layered set of guardrails against hallucinations. Together, we'll build an end-to-end Agentic RAG pipeline and demonstrate its integration with Claude Desktop via MCP, so you can see how this could plug into your existing ecosystem. 

By the end of this session, you'll have a functioning Agentic RAG prototype that you can easily customize and deploy to production for your specific use cases, even with complex, unstructured documents. </Description>
    <Session_Format>Workshop</Session_Format>
    <Level>Intermediate</Level>
    <Scope>Technical deep dive</Scope>
    <Assigned_Track></Assigned_Track>
    <Room>Golden Gate Ballroom B: Workshops</Room>
    <Scheduled_At>3 Jun 2025 09:00 AM</Scheduled_At>
    <Speakers>Nina Lopatina, Rajiv Shah</Speakers>
    <Companies>Contextual AI, Contextual AI</Companies>
    
    
</21>
<22>
    <Session_ID>913965</Session_ID>
    <Title>The AI Engineer’s Guide to Raising VC</Title>
    <Description>A no fluff, all tactics discussion. More AI engineers should build startups, the world needs more software. But there’s a way to raise VC and it’s hard to do it if you’ve never seen it done. We are going to walk through the exact playbook to raise your first round of funding. We will show you real pitch decks, real cold emails and real term sheets so when you go out to raise your first round of funding, you are setup to do it. Every AI Engineer should be equip to start their own company and this session makes sure raising $$$ is not going to be the blocker.</Description>
    <Session_Format>Talk</Session_Format>
    <Level>Intermediate</Level>
    <Scope>Technical deep dive</Scope>
    <Assigned_Track></Assigned_Track>
    <Room>Salons 2-6: Workshops</Room>
    <Scheduled_At>3 Jun 2025 09:55 AM</Scheduled_At>
    <Speakers>Dani Grant, Chelcie Taylor</Speakers>
    <Companies>Jam.dev, Notable Capital</Companies>
    
    
</22>
<23>
    <Session_ID>907684</Session_ID>
    <Title>Solving for the hardest Eval challenge: Building Metrics that actually work</Title>
    <Description>One of the biggest challenges in building evals you can trust is building metrics that reliably measure goodness in your application; metrics that are highly accurate, rapid fast, and tunable to ground truth rater and user behavior. This workshop is inspired by decades of AI and machine learning development in Google Search, reinvented for the modern LLM stack by the Pi team over the past year.

In this workshop you will learn how to:
1) Brainstorm and design custom metrics tailored to your specific application needs.
2) Identify which types of signals (natural language, code, other models) work best for your use case through rapid trial and error.
3) Combine & calibrate your metrics against ground truth data using real examples from your domain.
4) Use simple tools like Google Sheets for visualizing and analyzing your inputs and outputs with those metrics.
5) Integrate your scoring models into both online workflows like agent control and offline ones like model comparison and training evaluation.

</Description>
    <Session_Format>Workshop</Session_Format>
    <Level>Intermediate</Level>
    <Scope>Technical deep dive</Scope>
    <Assigned_Track>Workshop</Assigned_Track>
    <Room>Foothill G1&2: Workshops</Room>
    <Scheduled_At>3 Jun 2025 10:40 AM</Scheduled_At>
    <Speakers>David Karam</Speakers>
    
    
    
</23>
<24>
    <Session_ID>915961</Session_ID>
    <Title>Ship Agents that Ship: A Hands-On Workshop for SWE Agent Builders</Title>
    <Description>Coding agents are transforming how software gets built, tested, and deployed, but engineering teams face a critical challenge: how to embrace this automation wave without sacrificing trust, control, or reliability.
In this 80 minute workshop, you’ll go beyond toy demos and build production-minded AI agents using Dagger, the programmable delivery engine designed for real CI/CD and AI-native workflows. Whether you're debugging failures, triaging pull requests, generating tests, or shipping features, you'll learn how to orchestrate autonomous agents that live in and around your codebase: from your laptop to your CI platform.
We’ll guide you through:

Building real-world agents with Dagger and popular LLMs (GPT, Claude, etc.)

Programming agent environments using real languages (Go, Python, TypeScript)

Executing agent workflows locally and in GitHub Actions, so you can bring them to production

Using a composable runtime that ensures isolation, determinism, traceability, and repeatability

Designing agents that automate and enhance debugging, test generation, code review, bug fixing, and feature implementation


By the end of the workshop, you’ll walk away ready to build your own army of autonomous agents, working collaboratively across your codebase, locally and in CI, accelerating development without ceding control. Let’s build agents that don’t just talk, they ship!</Description>
    <Session_Format>Workshop</Session_Format>
    <Level>Intermediate</Level>
    <Scope>Technical deep dive</Scope>
    <Assigned_Track>Workshop</Assigned_Track>
    <Room>Nobhill A&B: Workshops</Room>
    <Scheduled_At>3 Jun 2025 10:40 AM</Scheduled_At>
    <Speakers>Kyle Penfound, Jeremy Adams</Speakers>
    <Companies>unknown, unknown</Companies>
    
    
</24>
<25>
    <Session_ID>916131</Session_ID>
    <Title>Milliseconds to Magic: Real‑Time Workflows using the Gemini Live API and Pipecat</Title>
    <Description>The Gemini Live API GA  is now powered by Google's best cost-effective thinking model Gemini 2.5 Flash. We will do a deep dive on the capabilities that the Gemini Live API combined with Pipecat unlock for devs with special focus on session management, turn detection, tool use (including async function calls), proactivity, multilinguality and integration with telephony and other infra. We will demo some of the more innovative capabilities. We will also talk through some customer use cases - especially how customers can use Pipecat to extend these realtime multimodal capabilities to client side applications such as customer support agents, gaming agents, tutoring agents etc. In addition, we also have an experimental version of the Live API powered by with Google's native audio offering that can be tried in an experimental capacity . This experimental model  can communicate with seamless, emotive, steerable, multilingual dialogue and enhances use cases where more natural voices can be a big differentiator. </Description>
    <Session_Format>Workshop</Session_Format>
    <Level>Intermediate</Level>
    <Scope>Technical deep dive</Scope>
    <Assigned_Track></Assigned_Track>
    <Room>Salons 2-6: Workshops</Room>
    <Scheduled_At>3 Jun 2025 10:40 AM</Scheduled_At>
    <Speakers>Shrestha Basu Mallick, Kwindla Kramer</Speakers>
    <Companies>unknown, Daily</Companies>
    
    
</25>
<26>
    <Session_ID>933707</Session_ID>
    <Title>Building Multimodal AI Agents (From Scratch)</Title>
    <Description>In this hands-on workshop, you will build a multimodal AI agent capable of processing mixed-media content—from analyzing charts and diagrams to extracting insights from documents with embedded visuals. Using MongoDB as a vector database and memory store, and Google's Gemini for multimodal reasoning, you will gain hands-on experience with multimodal data processing pipelines and agent orchestration patterns by implementing core components directly, using good ol' Python.
</Description>
    <Session_Format>Workshop</Session_Format>
    <Level>Advanced</Level>
    <Scope>Technical deep dive</Scope>
    <Assigned_Track></Assigned_Track>
    <Room>SOMA: Workshops</Room>
    <Scheduled_At>3 Jun 2025 10:40 AM</Scheduled_At>
    <Speakers>Apoorva Joshi</Speakers>
    
    
    
</26>
<27>
    <Session_ID>935459</Session_ID>
    <Title>Piloting agents in GitHub Copilot</Title>
    <Description>The agent capabilities added to GitHub Copilot have enhanced its ability to act as a peer programmer. Copilot can now discover and generate code based on existing standards, run tests, recover from errors, and call tools using Model Context Protocol (MCP). This workshop will guide you through piloting Copilot's agent capabilities and how to best integrate with the most widely adopted AI coding assistant in the world.

Key takeaways include:

- Understanding how and when to bring agents into your software development workflow
- Providing context through the use of custom instructions and prompt files to ensure consistency across your team
- Discovering how MCP provides access to an additional set of external tools and capabilities that the agent can use
- Configuring Copilot's agentic capabilities to take advantage of your custom MCP server
- Recommended best practices to help your responsibly accelerate your development while maintaining code quality and governance</Description>
    <Session_Format>Workshop</Session_Format>
    <Level></Level>
    <Scope></Scope>
    <Assigned_Track></Assigned_Track>
    <Room>Nobhill C&D: Microsoft</Room>
    <Scheduled_At>3 Jun 2025 10:40 AM</Scheduled_At>
    <Speakers>Christopher Harrison</Speakers>
    
    
    
</27>
<28>
    <Session_ID>936937</Session_ID>
    <Title>Automating Escrow with USDC and AI</Title>
    <Description>This workshop explores how USDC, AI, and smart contracts can streamline escrow by automating fund release based on task or process verification. By using AI to interpret off-chain signals such as document validation, delivery confirmations, or milestone completion, we can trigger secure, programmable USDC payouts without manual intervention. The result is a faster, trust-minimized escrow system ideal for services, trade, and gig economy use cases.</Description>
    <Session_Format>Workshop</Session_Format>
    <Level>Introductory and overview</Level>
    <Scope>Technical deep dive</Scope>
    <Assigned_Track></Assigned_Track>
    <Room>Golden Gate Ballroom B: Workshops</Room>
    <Scheduled_At>3 Jun 2025 10:40 AM</Scheduled_At>
    <Speakers>Corey Cooper</Speakers>
    <Companies>Circle</Companies>
    
    
</28>
<29>
    <Session_ID>942803</Session_ID>
    <Title>Mastering AI Evaluation: From Playground to Production with Braintrust</Title>
    <Description>This hands-on workshop will guide participants through the complete AI evaluation lifecycle using Braintrust, from initial prompt testing to production monitoring. Attendees will learn to build evaluation frameworks that ensure their AI applications perform reliably in real-world scenarios. Topics covered include both offline and online evaluation strategies, logging and feedback systems, and human review processes.</Description>
    <Session_Format>Workshop</Session_Format>
    <Level>Intermediate</Level>
    <Scope>Technical deep dive</Scope>
    <Assigned_Track></Assigned_Track>
    <Room>Golden Gate Ballroom C: Workshops</Room>
    <Scheduled_At>3 Jun 2025 10:40 AM</Scheduled_At>
    <Speakers>Doug Guthrie</Speakers>
    <Companies>Braintrust</Companies>
    
    
</29>
<30>
    <Session_ID>915431</Session_ID>
    <Title>Build multilingual Conversational AI Agents</Title>
    <Description>In this workshop you will learn how to build multilingual Conversational AI agents that can automatically detect your user's spoken language and can seamlessly switch to their preferred language. </Description>
    <Session_Format>Workshop</Session_Format>
    <Level>Introductory and overview</Level>
    <Scope>Introductory (landscape)</Scope>
    <Assigned_Track>Voice (07)</Assigned_Track>
    <Room>Golden Gate Ballroom A: Workshops</Room>
    <Scheduled_At>3 Jun 2025 11:00 AM</Scheduled_At>
    <Speakers>Thor 雷神 Schaeff</Speakers>
    
    
    
</30>
<31>
    <Session_ID>929790</Session_ID>
    <Title>Useful General Intelligence</Title>
    <Description>We’re all hearing that AI agents will enable AGI, but they can’t yet reliably perform even basic computer tasks. It turns out that getting AI to click, type, and scroll is more challenging than getting it to generate code. How can we build general-purpose agents that can do anything we can do on a computer? 

This is our goal at the Amazon AGI SF Lab. In this talk, I’ll propose a new approach to agents that we call Useful General Intelligence. After describing how we’re solving the biggest challenges in computer use while enabling developers to access our tech in it’s earliest developmental stages, I’ll show real workflows that developers have built with Nova Act, our agentic model and SDK. </Description>
    <Session_Format>Keynote</Session_Format>
    <Level>Introductory and overview</Level>
    <Scope>Introductory (landscape)</Scope>
    <Assigned_Track></Assigned_Track>
    <Room>Golden Gate Ballroom A: Workshops</Room>
    <Scheduled_At>3 Jun 2025 12:40 PM</Scheduled_At>
    <Speakers>Danielle Perszyk</Speakers>
    <Companies>Amazon</Companies>
    
    
</31>
<32>
    <Session_ID>907544</Session_ID>
    <Title>Case Study + Deep Dive: Telemedicine Support Agents with LangGraph/MCP</Title>
    <Description>We've all seen website chat bots which can look up an order or answer a basic question -- but what does it take to build autonomous agents which manage long, delicate processes like multi-day medical treatments?  

In this workshop, we'll explore a workflow Stride built in partnership with Avila (https://avilascience.com/) that helps patients self-administer medication regimens at home.  The stack includes LangGraph/LangSmith, Claude, MCP, Node.js, React, MongoDB, and Twilio, and rests on a foundation of treatment "blueprints" which LLM-powered agents use to guide patients to good outcomes.  

You'll learn how to:
-Build a hybrid system of code and prompts that leverages LLM decisioning to drive a web application, message queue and database
-Design and maintain flexible agentic workflow blueprints, with no special tools (just Google Docs!)
-Create an agent evaluation system, which uses LLM-as-a-judge to evaluate the complexity of each interaction and escalate to human support when needed

We'll also talk about the prompt engineered guidelines and guardrails which helps agents adhere to protocol as much as possible, while gracefully handling curveballs from the patient.  Please bring questions -- we look forward to sharing our learnings on how to make agentic systems like this work in the real world!</Description>
    <Session_Format>Workshop</Session_Format>
    <Level>Advanced</Level>
    <Scope>Case Study/War Story</Scope>
    <Assigned_Track>Workshop</Assigned_Track>
    <Room>Foothill C: Workshops</Room>
    <Scheduled_At>3 Jun 2025 01:00 PM</Scheduled_At>
    <Speakers>Dan Mason</Speakers>
    <Companies>Stride</Companies>
    
    
</32>
<33>
    <Session_ID>910732</Session_ID>
    <Title>AI Engineering with the Google Gemini 2.5 Model Family</Title>
    <Description>Hands on Workshop on learning to use Gemini 2.5 Pro in combination with Agentic tooling and MCP Servers.</Description>
    <Session_Format>Workshop</Session_Format>
    <Level>Intermediate</Level>
    <Scope>Technical deep dive</Scope>
    <Assigned_Track>Workshop</Assigned_Track>
    <Room>SOMA: Workshops</Room>
    <Scheduled_At>3 Jun 2025 01:00 PM</Scheduled_At>
    <Speakers>Philipp Schmid</Speakers>
    <Companies>Google DeepMind</Companies>
    
    
</33>
<34>
    <Session_ID>916214</Session_ID>
    <Title>Information Retrieval from the Ground Up</Title>
    <Description>Vector search is only a feature. Search engines and information retrieval have retaken their position as the foundation of RAG. This workshop takes you through decades of research, what has been working for a long time, and how it got better with Machine Learning.</Description>
    <Session_Format>Workshop</Session_Format>
    <Level>Introductory and overview</Level>
    <Scope>Technical deep dive</Scope>
    <Assigned_Track>Workshop</Assigned_Track>
    <Room>Foothill G1&2: Workshops</Room>
    <Scheduled_At>3 Jun 2025 01:00 PM</Scheduled_At>
    <Speakers>Philipp Krenn</Speakers>
    
    
    
</34>
<35>
    <Session_ID>921229</Session_ID>
    <Title>Graph Intelligence: Enhance Reasoning and Retrieval Using Graph Analytics</Title>
    <Description>Advanced GraphRAG techniques apply graph ML and algorithms, wrapped into tidy notebooks.</Description>
    <Session_Format>Workshop</Session_Format>
    <Level>Advanced</Level>
    <Scope>Technical deep dive</Scope>
    <Assigned_Track>GraphRAG (08)</Assigned_Track>
    <Room>Golden Gate Ballroom C: Workshops</Room>
    <Scheduled_At>3 Jun 2025 01:00 PM</Scheduled_At>
    <Speakers>Alison Cossette, Andreas Kollegger</Speakers>
    <Companies>Neo4j , Neo4j</Companies>
    
    
</35>
<36>
    <Session_ID>930540</Session_ID>
    <Title>Model-Maxxing: RFT, DPO, SFT with OpenAI</Title>
    <Description>Covering all forms of fine-tuning and prompt engineering, like SFT, DPO, RFT, prompt engineering / optimization, and agent scaffolding.</Description>
    <Session_Format>Workshop</Session_Format>
    <Level>Intermediate</Level>
    <Scope>Technical deep dive</Scope>
    <Assigned_Track>Workshop</Assigned_Track>
    <Room>Golden Gate Ballroom B: Workshops</Room>
    <Scheduled_At>3 Jun 2025 01:00 PM</Scheduled_At>
    <Speakers>Ilan Bigio</Speakers>
    <Companies>OpenAI</Companies>
    
    
</36>
<37>
    <Session_ID>933607</Session_ID>
    <Title>Building Agents with Amazon Nova Act and MCP</Title>
    <Description>In this 2-hour workshop, participants will gain practical hands-on experience building sophisticated AI agents using Amazon's agent technologies. You'll learn to build agents that can navigate the web like humans, perform complex multi-step tasks, and leverage specialized tools through natural language commands. You’ll explore Amazon Nova Act for reliable web navigation, Model Context Protocol (MCP) for connecting agents to external data sources and APIs, and Amazon Bedrock Agents for orchestrating complex workflows. Through guided exercises, you'll create agents capable of retrieving information and taking action across web applications, all through natural language interactions. By the end of this workshop, you'll have the practical skills to build AI agents that can browse websites, interact with web interfaces, and solve multi-step problems by combining these powerful Amazon technologies.</Description>
    <Session_Format>Workshop</Session_Format>
    <Level>Advanced</Level>
    <Scope>Technical deep dive</Scope>
    <Assigned_Track></Assigned_Track>
    <Room>Golden Gate Ballroom A: Workshops</Room>
    <Scheduled_At>3 Jun 2025 01:00 PM</Scheduled_At>
    <Speakers>Duan Lightfoot</Speakers>
    <Companies>AWS</Companies>
    
    
</37>
<38>
    <Session_ID>935456</Session_ID>
    <Title>Real-World Development with GitHub Copilot and VS Code</Title>
    <Description>Join us for a hands-on workshop designed to demonstrate how VS Code and GitHub Copilot's expanding suite of AI features can match or even surpasses the benefits of other popular AI developer tools.  We'll focus on practical scenarios to ensure immediate applicability and work through live demos of Copilot features such as: Code generation using Edits, Planning/problem solving using Chat, Inline terminal command generation, Boilerplate code generation using Agent mode, Improving boilerplate with custom instructions and then refactoring using Agent mode and Edits, Improving test generation and code reviews with custom instructions, as well as an Introduction to MCP. 
Pre Requisit - install GitHub Copilot and VS Code</Description>
    <Session_Format>Workshop</Session_Format>
    <Level></Level>
    <Scope></Scope>
    <Assigned_Track></Assigned_Track>
    <Room>Salons 2-6: Workshops</Room>
    <Scheduled_At>3 Jun 2025 01:00 PM</Scheduled_At>
    <Speakers>Harald Kirschner, Christopher Harrison</Speakers>
    <Companies>unknown, unknown</Companies>
    
    
</38>
<39>
    <Session_ID>936905</Session_ID>
    <Title>Building Code-First AI Agents with Azure AI Agent Service: A Practical introduction</Title>
    <Description>This workshop offers a hands-on introduction to developing Large Language Model (LLM)-powered AI agents using Microsoft’s Azure AI Agent Service. Participants will build a conversational agent capable of analyzing sales data, generating visualizations, and delivering actionable insights.
 
The session takes a code-first approach using the Azure AI Foundry SDK for Python, and demonstrates how to integrate core Azure services including Azure OpenAI, Azure AI Search, and Azure Storage.
 
Attendees will explore key concepts such as function calling, document grounding, and leveraging code interpreters to generate diagrams. The workshop also covers how to connect agents to external data sources like SQL databases (e.g., SQLite), enabling access to legacy relational systems.
 
By the end of the session, participants will have a solid foundation for building and deploying intelligent, code-first AI agents with Azure AI Agent Service—ready to power real-world applications.</Description>
    <Session_Format>Workshop</Session_Format>
    <Level></Level>
    <Scope></Scope>
    <Assigned_Track></Assigned_Track>
    <Room>Nobhill C&D: Microsoft</Room>
    <Scheduled_At>3 Jun 2025 01:00 PM</Scheduled_At>
    <Speakers>Cedric  Vidal</Speakers>
    <Companies>Microsoft</Companies>
    
    
</39>
<40>
    <Session_ID>939088</Session_ID>
    <Title>From Mixture of Experts to Mixture of Agents … with Super Fast Inference</Title>
    <Description>Our hands-on workshop will walk you through how to build your own Mixture of Agents (MoA) system using the fastest, and most capable open models available: Qwen3-32B and Llama 3.3-70B. MoA is an emerging architecture that combines the strengths of multiple large language models in a layered, agent-based design. This approach delivers superior performance by enabling specialized agents to collaborate across layers—outperforming today’s frontier models in both accuracy and efficiency.

To ground this new paradigm in its roots, we’ll also explore how Mixture of Experts (MoE) architectures continue to push the boundaries of scale and specialization. Learn how Cerebras trains state-of-the-art MoEs from Daria Soboleva, Head Research Scientist.</Description>
    <Session_Format>Workshop</Session_Format>
    <Level>Intermediate</Level>
    <Scope>Technical deep dive</Scope>
    <Assigned_Track></Assigned_Track>
    <Room>Nobhill A&B: Workshops</Room>
    <Scheduled_At>3 Jun 2025 01:00 PM</Scheduled_At>
    <Speakers>Daniel Kim, Daria Soboleva</Speakers>
    <Companies>Cerebras, Cerebras</Companies>
    
    
</40>
<41>
    <Session_ID>914537</Session_ID>
    <Title>Building voice agents with OpenAI</Title>
    <Description>We'll walk through the differences between chained and speech-to-speech powered voice agents, how to approach them, best practices and transform a text-based agent into our first voice-enabled agent</Description>
    <Session_Format>Workshop</Session_Format>
    <Level>Introductory and overview</Level>
    <Scope>Technical deep dive</Scope>
    <Assigned_Track>Workshop</Assigned_Track>
    <Room>Golden Gate Ballroom B: Workshops</Room>
    <Scheduled_At>3 Jun 2025 03:30 PM</Scheduled_At>
    <Speakers>Dominik Kundel</Speakers>
    <Companies>OpenAI</Companies>
    
    
</41>
<42>
    <Session_ID>915269</Session_ID>
    <Title>Shipping AI That Works: An Evaluation Framework for PMs</Title>
    <Description>GenAI is reshaping the product landscape, creating huge opportunities (along with new expectations) for product managers. Yet while prompt engineering and model tuning get the spotlight, one critical skill can get overlooked: rigorous evaluation.

This talk will help PMs move beyond gut-feel “vibe checks” to adopt concrete, repeatable evaluation strategies for LLM-powered products. I'll break down essential eval methodologies, from human feedback and code-based checks to cutting-edge LLM-based evaluations. Drawing on real-world examples, I'll share a practical framework PMs can use to:

-Confidently evaluate AI-driven features
- Ground decisions in real, repeatable data
- Build trust and delight through consistent quality
</Description>
    <Session_Format>Workshop</Session_Format>
    <Level>Intermediate</Level>
    <Scope>Introductory (landscape)</Scope>
    <Assigned_Track>Workshop</Assigned_Track>
    <Room>Nobhill A&B: Workshops</Room>
    <Scheduled_At>3 Jun 2025 03:30 PM</Scheduled_At>
    <Speakers>Aman Khan</Speakers>
    <Companies>Arize</Companies>
    
    
</42>
<43>
    <Session_ID>933560</Session_ID>
    <Title>Navigating deep context in legacy code with Augment Agent</Title>
    <Description>Attendees will learn to use an AI coding agent as a fast and intuitive part of navigating and working with complex, production-grade legacy code bases. We will drop directly into the code–written in assembly–that landed the1969 Apollo 11 astronauts on the moon and, through a series of challenges, locate parts of the code tied to key functionality. Using the agent to convert a key guidance computer algorithm into a more modern programming language, attendees will then compete to see whose code has what it takes to land on the moon.</Description>
    <Session_Format>Workshop</Session_Format>
    <Level>Introductory and overview</Level>
    <Scope>Introductory (landscape)</Scope>
    <Assigned_Track></Assigned_Track>
    <Room>Foothill C: Workshops</Room>
    <Scheduled_At>3 Jun 2025 03:30 PM</Scheduled_At>
    <Speakers>Forrest Brazeal, Matt Ball</Speakers>
    <Companies>Augment Code, Augment Code </Companies>
    
    
</43>
<44>
    <Session_ID>933593</Session_ID>
    <Title>Building Voice Agents with Gemini and Pipecat</Title>
    <Description>Hands-on workshop led by engineers from Google and Daily</Description>
    <Session_Format>Workshop</Session_Format>
    <Level>Intermediate</Level>
    <Scope>Technical deep dive</Scope>
    <Assigned_Track></Assigned_Track>
    <Room>SOMA: Workshops</Room>
    <Scheduled_At>3 Jun 2025 03:30 PM</Scheduled_At>
    <Speakers>Chad Bailey, Kwindla Kramer</Speakers>
    <Companies>unknown, Daily</Companies>
    
    
</44>
<45>
    <Session_ID>933632</Session_ID>
    <Title>Agentic Coding with Windsurf</Title>
    <Description>Agentic coding marks a new era in software development, where AI agents take on autonomous roles in coding tasks. The Windsurf IDE embodies this shift by integrating intelligent agents like Cascade, which maintain full codebase context to perform multi-file edits, run terminal commands, and suggest changes through tools like Supercomplete and Flows. In this session, we will explore features that allow developers to guide strategy while the AI handles execution, enhancing productivity and enabling more creative, high-level work.</Description>
    <Session_Format>Workshop</Session_Format>
    <Level>Intermediate</Level>
    <Scope>Introductory (landscape)</Scope>
    <Assigned_Track></Assigned_Track>
    <Room>Golden Gate Ballroom A: Workshops</Room>
    <Scheduled_At>3 Jun 2025 03:30 PM</Scheduled_At>
    <Speakers>Numair Baseer</Speakers>
    
    
    
</45>
<46>
    <Session_ID>933688</Session_ID>
    <Title>AI Pipelines and Agents in Pure TypeScript with Mastra.ai</Title>
    <Description>This hands-on workshop introduces Mastra.ai, a TypeScript framework that streamlines the development of agentic AI systems compared to traditional approaches using LangChain and vector databases. Participants will learn to build structured AI workflows with composable tools and reliable control, enabling them to create internal AI assistants that can handle requests like data cleaning, email drafting, and document summarization with minimal code. The session covers Mastra installation, running a local MCP server, defining tools and agents in TypeScript, using the Mastra playground, and implementing practical examples such as RAG setups and tool-chaining agents—all designed to equip attendees with the skills to develop scalable AI-driven internal tools based on sound software engineering principles rather than just experimental prompts.</Description>
    <Session_Format>Workshop</Session_Format>
    <Level>Intermediate</Level>
    <Scope>Technical deep dive</Scope>
    <Assigned_Track></Assigned_Track>
    <Room>Salons 2-6: Workshops</Room>
    <Scheduled_At>3 Jun 2025 03:30 PM</Scheduled_At>
    <Speakers>Nick Nisi, Zack Proser</Speakers>
    <Companies>WorkOS , unknown</Companies>
    
    
</46>
<47>
    <Session_ID>933721</Session_ID>
    <Title>VoiceVision RAG - Integrating Visual Document Intelligence with Voice Response</Title>
    <Description>In this workshop we will explore the integration of Colpali, a cutting-edge Vision based Retrieval Model, with voice synthesis for next-generation RAG systems. We'll demonstrate how Colpali's ability to generate multi-vector embeddings directly from document images bypasses traditional OCR and complex preprocessing, while adding voice output creates a more intuitive and accessible user experience. Attendees will see how this combination handles documents with mixed textual and visual information, leading to more efficient and accurate information retrieval with natural voice responses.</Description>
    <Session_Format>Workshop</Session_Format>
    <Level>Intermediate</Level>
    <Scope>Technical deep dive</Scope>
    <Assigned_Track></Assigned_Track>
    <Room>Foothill G1&2: Workshops</Room>
    <Scheduled_At>3 Jun 2025 03:30 PM</Scheduled_At>
    <Speakers>Suman Debnath</Speakers>
    <Companies>Amazon Web Services</Companies>
    
    
</47>
<48>
    <Session_ID>940839</Session_ID>
    <Title>Collaborating with Agents in your Software Development Workflow</Title>
    <Description>GitHub Copilot's agentic capabilities enhance its ability to act as a peer programmer. From the IDE to the repository, Copilot can generate code, run tests, and perform tasks like creating pull requests using Model Context Protocol (MCP). This instructor-led lab will guide you through using agent capabilities on both the client and the server: Key takeaways include:
Understanding how to bring agents into your software development workflow
Identifying scenarios where agents can be most impactful, as well as tips and tricks to provide the right context to lead to success
Discovering how Model Context Protocol provides access to an additional set of external tools and capabilities that the agent can use
Recommended practices to accelerate your development while maintaining code quality.</Description>
    <Session_Format>Workshop</Session_Format>
    <Level></Level>
    <Scope></Scope>
    <Assigned_Track></Assigned_Track>
    <Room>Nobhill C&D: Microsoft</Room>
    <Scheduled_At>3 Jun 2025 03:30 PM</Scheduled_At>
    <Speakers>Jon Peck, Christopher Harrison</Speakers>
    <Companies>GitHub, GitHub</Companies>
    
    
</48>
<49>
    <Session_ID>942858</Session_ID>
    <Title>How to build world-class AI products (featuring Sarah Sachs, AI lead @ Notion)</Title>
    <Description>Join us for a hands-on workshop where you'll learn practical strategies to evaluate AI applications throughout their lifecycle—from initial testing of prompts to ongoing monitoring in production. We’re excited to host Sarah Sachs, AI Lead at Notion, who will share insights into how Notion built their acclaimed Notion AI.</Description>
    <Session_Format>Workshop</Session_Format>
    <Level>Intermediate</Level>
    <Scope>Technical deep dive</Scope>
    <Assigned_Track></Assigned_Track>
    <Room>Golden Gate Ballroom C: Workshops</Room>
    <Scheduled_At>3 Jun 2025 03:30 PM</Scheduled_At>
    <Speakers>Carlos  Esteban</Speakers>
    <Companies>Braintrust</Companies>
    
    
</49>
<50>
    <Session_ID>936800</Session_ID>
    <Title>Spark to System: Building the Open Agentic Web</Title>
    <Description>AI builders no longer ask whether to use agents—but how many and how fast. In this kickoff keynote, Microsoft’s Asha Sharma shows what happens when natural language creation meets an industrial grade backbone.  Watch live demos—to see agents move from idea to production in real time. Walk out with the commands, repos, and open protocols to build your piece of the agentic web.</Description>
    <Session_Format>Keynote</Session_Format>
    <Level>Intermediate</Level>
    <Scope>Introductory (landscape)</Scope>
    <Assigned_Track></Assigned_Track>
    <Room>Keynote/General Session (Yerba Buena 7&8)</Room>
    <Scheduled_At>4 Jun 2025 09:20 AM</Scheduled_At>
    <Speakers>Asha  Sharma</Speakers>
    
    
    
</50>
<51>
    <Session_ID>927324</Session_ID>
    <Title>Conviction Session</Title>
    <Description>Please Fill in</Description>
    <Session_Format>Keynote</Session_Format>
    <Level>Intermediate</Level>
    <Scope></Scope>
    <Assigned_Track></Assigned_Track>
    <Room>Keynote/General Session (Yerba Buena 7&8)</Room>
    <Scheduled_At>4 Jun 2025 09:40 AM</Scheduled_At>
    <Speakers>Sarah Guo</Speakers>
    
    
    
</51>
<52>
    <Session_ID>935987</Session_ID>
    <Title>Simon Willison Keynote</Title>
    <Description></Description>
    <Session_Format>Keynote</Session_Format>
    <Level></Level>
    <Scope></Scope>
    <Assigned_Track></Assigned_Track>
    <Room>Keynote/General Session (Yerba Buena 7&8)</Room>
    <Scheduled_At>4 Jun 2025 10:00 AM</Scheduled_At>
    <Speakers>Simon Willison</Speakers>
    
    
    
</52>
<53>
    <Session_ID>933450</Session_ID>
    <Title>Code Review for the Age of AI</Title>
    <Description>Today’s codebases move faster than ever, making human code reviews increasingly challenging. In this quick technical talk, we’ll explore how AI-driven code review technology changes the game, rapidly identifying subtle logic errors, hidden security vulnerabilities, and performance bottlenecks before they ever reach production. Drawing on insights from over millions of real-world pull requests reviewed by Diamond, Graphite’s AI code review agent, you'll learn how teams are achieving faster merges and higher code quality.

We'll wrap up with a brief introduction to Diamond, demonstrating how effortlessly it integrates into your GitHub workflows, followed by live demos and Q\&A with our engineers at the booth.</Description>
    <Session_Format></Session_Format>
    <Level>Introductory and overview</Level>
    <Scope>Introductory (landscape)</Scope>
    <Assigned_Track></Assigned_Track>
    <Room>Salons 9-15: Expo Hall</Room>
    <Scheduled_At>4 Jun 2025 10:45 AM</Scheduled_At>
    <Speakers>Tomas Reimers</Speakers>
    
    
    
</53>
<54>
    <Session_ID>933472</Session_ID>
    <Title>AI-powered entomology: Lessons from millions of AI code reviews</Title>
    <Description>This talk will explore insights from millions of automated code reviews, revealing trends in bugs, vulnerabilities, and code health that Graphite’s AI code review agent have uncovered. This talk will also provide meta commentary into the types of bugs AI code review agents are great at spotting, and how far the field of AI code review has come in the last year alone.</Description>
    <Session_Format></Session_Format>
    <Level>Introductory and overview</Level>
    <Scope>Introductory (landscape)</Scope>
    <Assigned_Track></Assigned_Track>
    <Room>Nobhill A&B: Expo Sessions</Room>
    <Scheduled_At>4 Jun 2025 10:45 AM</Scheduled_At>
    <Speakers>Tomas Reimers</Speakers>
    
    
    
</54>
<55>
    <Session_ID>933493</Session_ID>
    <Title>Realtime conversational video with Pipecat and Tavus</Title>
    <Description>Tavus shipped the world's first realtime video avatar platform last year. Developers use Tavus' conversational video APIs to create education, social, and customer support agents. The Tavus team built their innovative product using the Pipecat open source framework and Daily's global WebRTC infrastructure. Join us for a technical deep dive into conversational video.</Description>
    <Session_Format></Session_Format>
    <Level>Introductory and overview</Level>
    <Scope>Technical deep dive</Scope>
    <Assigned_Track></Assigned_Track>
    <Room>Juniper: Expo Sessions</Room>
    <Scheduled_At>4 Jun 2025 10:45 AM</Scheduled_At>
    <Speakers>Chad Bailey, Brian Johnson</Speakers>
    <Companies>Daily, Tavus</Companies>
    
    
</55>
<56>
    <Session_ID>933692</Session_ID>
    <Title>Architecting Agent Memory: Principles, Patterns, and Best Practices</Title>
    <Description>In the rapidly evolving landscape of agentic systems, memory management has emerged as a key pillar for building intelligent, context-aware AI Agents. Inspired by the complexity of human memory systems—such as episodic, working, semantic, and procedural memory—this talk unpacks how AI agents can achieve believability, reliability, and capability by retaining and reasoning over past experiences.
We’ll begin by establishing a conceptual framework based on real-world implementations from memory management libraries and system architectures:
Memory Components representing various structured memory types (e.g., conversation, workflow, episodic, persona)
Memory Modes reflecting operational strategies for short-term, long-term, and dynamic memory handling
Next, the talk transitions to practical implementation patterns critical for effective memory lifecycle management:
Maintaining rich conversation history and contextual awareness
Persistence strategies leveraging vector databases and hybrid search
Memory augmentation using embeddings, relevance scoring, and semantic retrieval
Production-ready practices for scaling memory in multi-agent ecosystems
We’ll also examine advanced memory strategies within agentic systems:
Memory cascading and selective deletion
Integration of tool use and persona memory
Optimizing performance around memory retrieval and LLM context window limits
Whether you're developing autonomous agents, chatbots, or complex workflow orchestration systems, this talk offers knowledge and tactical insights for building AI that can remember, adapt, and improve over time.
This session is ideal for:
AI engineers and agent framework developers
Architects designing Agentic RAG or multi-agent systems
Practitioners building contextual, personalized AI experiences
By the end of the session, you’ll understand how to leverage memory as a strategic asset in agentic design—and walk away ready to build agents that not only act and reason but also remember. </Description>
    <Session_Format></Session_Format>
    <Level>Intermediate</Level>
    <Scope>Introductory (landscape)</Scope>
    <Assigned_Track></Assigned_Track>
    <Room>Willow: Expo Sessions</Room>
    <Scheduled_At>4 Jun 2025 10:45 AM</Scheduled_At>
    <Speakers>Richmond Alake</Speakers>
    
    
    
</56>
<57>
    <Session_ID>933684</Session_ID>
    <Title>Mastering Engineering Flow with Windsurf</Title>
    <Description>As experienced engineers, especially senior and staff engineers, our focus shifts towards complex problem-solving, architectural decisions, and mentoring. While AI tools promise productivity gains, Windsurf offers more than just code completion and chat assistance – it's an agentic IDE built to enhance engineering flow. This talk explores how experienced engineers can leverage Windsurf's deep contextual awareness, structured guidance, and automated workflows to tackle sophisticated and complex tasks. We'll demonstrate practical strategies for accelerating feature development, automating code maintenance and reviews, and ultimately freeing up cognitive load to focus on high-impact engineering challenges. Learn how to move beyond basic AI assistance and truly partner with Windsurf to excel in your role.</Description>
    <Session_Format>Talk</Session_Format>
    <Level>Intermediate</Level>
    <Scope>Technical deep dive</Scope>
    <Assigned_Track></Assigned_Track>
    <Room>Nobhill A&B: Expo Sessions</Room>
    <Scheduled_At>4 Jun 2025 11:00 AM</Scheduled_At>
    <Speakers>Eashan Sinha</Speakers>
    
    
    
</57>
<58>
    <Session_ID>933706</Session_ID>
    <Title>GraphRAG: Integrating LLMs with Knowledge Graphs</Title>
    <Description>While traditional RAG is effective, it can struggle with complex relationships and reasoning across large knowledge bases. GraphRAG, an advanced variant, addresses these challenges by leveraging knowledge graphs to enable deeper understanding and improved response accuracy. Learn how LLMs extract key entities and relationships from your data to construct a graph structure, and how the system uses graph traversal to find related entities and enrich prompts. Stay for a live demo showcasing these concepts in action. </Description>
    <Session_Format></Session_Format>
    <Level>Intermediate</Level>
    <Scope>Technical deep dive</Scope>
    <Assigned_Track></Assigned_Track>
    <Room>Salons 9-15: Expo Hall</Room>
    <Scheduled_At>4 Jun 2025 11:00 AM</Scheduled_At>
    <Speakers>Thibaut  Gourdel</Speakers>
    
    
    
</58>
<59>
    <Session_ID>933709</Session_ID>
    <Title>What does Enterprise Ready MCP mean?</Title>
    <Description>Everyone is building MCP servers: from Slack integrations to personal data tools. They're good demos, but not ready to turn into production. So, what does it take to make MCP *enterprise-ready?*

We're going to cover the end-to-end process of getting a hacky MCP server authenticated, permissioned, and secure. We'll talk about registries, SSO, audit logs, agent identifiers, autonomy for agents, and oversight. Oh and we'll use MCP to buy some stuff.

Come learn the stack needed to scale your MCP to the enterprise and some fun hacks along the way.</Description>
    <Session_Format></Session_Format>
    <Level>Introductory and overview</Level>
    <Scope>Introductory (landscape)</Scope>
    <Assigned_Track></Assigned_Track>
    <Room>Willow: Expo Sessions</Room>
    <Scheduled_At>4 Jun 2025 11:00 AM</Scheduled_At>
    <Speakers>Tobin  South</Speakers>
    
    
    
</59>
<60>
    <Session_ID>936299</Session_ID>
    <Title>Vibe Coding in Production</Title>
    <Description>What's the role of vibe coding in a production-grade applications? Join Augment Code's Matt McClernan as he speaks to engineering leaders about building with AI. </Description>
    <Session_Format>Talk</Session_Format>
    <Level>Introductory and overview</Level>
    <Scope>Introductory (landscape)</Scope>
    <Assigned_Track></Assigned_Track>
    <Room>Juniper: Expo Sessions</Room>
    <Scheduled_At>4 Jun 2025 11:00 AM</Scheduled_At>
    <Speakers>Chris Kelly</Speakers>
    <Companies>Augment Code</Companies>
    
    
</60>
<61>
    <Session_ID>903524</Session_ID>
    <Title>From Copilot to Colleague: Building Trustworthy Productivity Agents for High-Stakes Work</Title>
    <Description>This keynote will explore what it takes to move from basic generative assistants to fully agentic AI—systems that don’t just suggest but plan, act, and adapt—all within the structured, high-trust environments where professionals actually work.</Description>
    <Session_Format>Talk</Session_Format>
    <Level>Intermediate</Level>
    <Scope>Product launch</Scope>
    <Assigned_Track>AI in the Fortune 500 (L2)</Assigned_Track>
    <Room>Golden Gate Ballroom C: AI in the Fortune 500</Room>
    <Scheduled_At>4 Jun 2025 11:15 AM</Scheduled_At>
    <Speakers>Joel Hron</Speakers>
    <Companies>Thomson Reuters</Companies>
    
    
</61>
<62>
    <Session_ID>915028</Session_ID>
    <Title>[Voice Keynote] Your realtime AI is ngmi</Title>
    <Description>Sean DuBois of OpenAI and Pion, and Kwindla Hultman Kramer of Daily and Pipecat, will talk about why you have to design realtime AI systems from the network layer up.

Most people who build realtime AI apps and frameworks get it wrong. They build from either the model out or the app layer down. But unless you start with the network layer and build up, you'll never be able to deliver realtime audio and video streams reliably. And perhaps even worse, you'll get core primitives wrong: interruption handling, conversation state management, asynchronous function calling.

Sean and Kwin agree on most things: old-school realtime systems people against the rest of the world. But they disagree on some important things, too, and will argue about those things live on stage. Do you need to give developers "thick" client-side realtime SDKs? Can you build truly great vendor neutral APIs? (You'll be surprised which of them argues which side, on that topic.)</Description>
    <Session_Format>Talk</Session_Format>
    <Level>Intermediate</Level>
    <Scope>Introductory (landscape)</Scope>
    <Assigned_Track>Voice (07)</Assigned_Track>
    <Room>Foothill E: Voice</Room>
    <Scheduled_At>4 Jun 2025 11:15 AM</Scheduled_At>
    <Speakers>Kwindla Kramer, Sean DuBois</Speakers>
    <Companies>Daily, OpenAI</Companies>
    
    
</62>
<63>
    <Session_ID>915992</Session_ID>
    <Title>HybridRAG: A Fusion of Graph and Vector Retrieval to Enhance Data Interpretation</Title>
    <Description>Interpreting complex information from unstructured text data poses significant challenges to Large Language Models (LLM), with difficulties often arising from specialized terminology and the multifaceted relationships between entities in document architectures. Conventional Retrieval Augmented Generation (RAG) methods face limitations in capturing these nuanced interactions, leading to suboptimal performance. In our talk, we introduce a novel approach integrating Knowledge Graph-based RAG (GraphRAG) with VectorRAG, designed to refine question-answering (Q&A) systems for more effective information extraction from complex texts. Our approach employs a dual retrieval strategy that harnesses both knowledge graphs and vector databases, enabling the generation of precise and contextually appropriate answers, thereby setting a new standard for LLMs in processing sophisticated data.</Description>
    <Session_Format>Talk</Session_Format>
    <Level>Intermediate</Level>
    <Scope>Technical deep dive</Scope>
    <Assigned_Track>GraphRAG (08)</Assigned_Track>
    <Room>Golden Gate Ballroom B: GraphRAG</Room>
    <Scheduled_At>4 Jun 2025 11:15 AM</Scheduled_At>
    <Speakers>Mitesh Patel</Speakers>
    <Companies>NVIDIA</Companies>
    
    
</63>
<64>
    <Session_ID>916117</Session_ID>
    <Title>AI Automation that actually works: $100M, messy data, zero surprises</Title>
    <Description>We will review the different kinds of automation use-cases, and the approach we used, that will drive over a $100M of expected annual impact by deploying AI for business critical initiatives. 

We will discuss what kinds of automation initiatives become possible because of Gen AI. These were not tenable before because of the amount of customization required per customer or per scenario, and the kind of data involved in these workflows. Previously, these workflows were driven manually which were both error prone and required expensive training. 

To replace or augment these manual business critical processes, automation _has_ to cross a very high bar of reliability. 

We will share how we addressed the inherent non-determinism of Gen AI to create a predictable system that doesn’t have any surprising failure modes. We’ll also discuss how we worked with our existing data that was spread across various systems without an expensive centralisation and clean up effort. </Description>
    <Session_Format>Talk</Session_Format>
    <Level>Intermediate</Level>
    <Scope>Case Study/War Story</Scope>
    <Assigned_Track>Agent Reliability (04)</Assigned_Track>
    <Room>Foothill C: Agent Reliability</Room>
    <Scheduled_At>4 Jun 2025 11:15 AM</Scheduled_At>
    <Speakers>Tanmai Gopal</Speakers>
    <Companies>PromptQL</Companies>
    
    
</64>
<65>
    <Session_ID>925337</Session_ID>
    <Title>[PM Keynote] Everything is ugly so go build something that isn't</Title>
    <Description>We're in an awkward adolescent phase of AI product (design). But what if this chaotic moment is actually our greatest opportunity? Enter the rebuilding revolution.

In this talk, we'll explore how the current state of AI interfaces offers a once-in-a-career chance to rethink fundamental UX patterns, with practical guidance on avoiding common pitfalls that plague first-generation AI products. 

Learn how to balance technical constraints with user needs, identify which conventional wisdom to keep versus discard, and ship AI experiences that actually delight users rather than frustrate them.</Description>
    <Session_Format>Talk</Session_Format>
    <Level>Introductory and overview</Level>
    <Scope>Introductory (landscape)</Scope>
    <Assigned_Track>Product Management (06)</Assigned_Track>
    <Room>Foothill G 1&2: Product Management</Room>
    <Scheduled_At>4 Jun 2025 11:15 AM</Scheduled_At>
    <Speakers>Raiza Martin</Speakers>
    <Companies>Huxe</Companies>
    
    
</65>
<66>
    <Session_ID>927452</Session_ID>
    <Title>[Placeholder] MCP Origins</Title>
    <Description>Early prototypes and demos from inside anthropic that have guided our thinking around MCP</Description>
    <Session_Format>Talk</Session_Format>
    <Level>Intermediate</Level>
    <Scope>Case Study/War Story</Scope>
    <Assigned_Track>MCP (02)</Assigned_Track>
    <Room>Yerba Buena Ballroom Salons 7-8: MCP</Room>
    <Scheduled_At>4 Jun 2025 11:15 AM</Scheduled_At>
    <Speakers>Jerome Swannack</Speakers>
    <Companies>Anthropic</Companies>
    
    
</66>
<67>
    <Session_ID>929337</Session_ID>
    <Title>Recsys Keynote: Improving Recommendation Systems & Search in the Age of LLMs</Title>
    <Description>Recommendation systems and search have long adopted advances in language modeling, from early adoption of Word2vec for embedding-based retrieval to the transformative impact of GRUs, Transformers, and BERT on predicting user interactions. Now, the rise of large language models (LLMs) is inspiring innovations in model architecture, scalable system designs, and richer customer experiences.

In this keynote, we'll dive into cutting-edge industry applications of LLMs in recommendation and search systems, exploring real-world implementations and measurable outcomes. Join us for an look at current trends and an exciting vision of how LLM-driven techniques will shape the future of content discovery and intelligent search.</Description>
    <Session_Format>Talk</Session_Format>
    <Level>Intermediate</Level>
    <Scope>Introductory (landscape)</Scope>
    <Assigned_Track>LLM RecSys (03)</Assigned_Track>
    <Room>Golden Gate Ballroom A: LLM RecSys</Room>
    <Scheduled_At>4 Jun 2025 11:15 AM</Scheduled_At>
    <Speakers>Eugene Yan</Speakers>
    <Companies>Amazon</Companies>
    
    
</67>
<68>
    <Session_ID>933719</Session_ID>
    <Title>What every AI engineer needs to know about GPUs</Title>
    <Description>Every programmer needs to know a few things about hardware, like processors, memory, and disks. Due to AI systems' extreme demand for mathematical processing power, AI engineers need to know a few things about GPUs -- the world's most popular high-throughput mathematical co-processor.

In this talk, I will explain the fundamental engineering constraints and design decisions that shape GPUs and trace those up to some counter-intuitive facts about the performance characteristics of AI systems, with actionable insights for their deployers and consumers.</Description>
    <Session_Format>Workshop</Session_Format>
    <Level>Intermediate</Level>
    <Scope>Introductory (landscape)</Scope>
    <Assigned_Track></Assigned_Track>
    <Room>Foothill F: Infrastructure</Room>
    <Scheduled_At>4 Jun 2025 11:15 AM</Scheduled_At>
    <Speakers>Charles Frye</Speakers>
    
    
    
</68>
<69>
    <Session_ID>939142</Session_ID>
    <Title>Bolt: The Dawn of the VibeCoder</Title>
    <Description>tbd</Description>
    <Session_Format>Talk</Session_Format>
    <Level></Level>
    <Scope></Scope>
    <Assigned_Track>Tiny Teams (01)</Assigned_Track>
    <Room>Yerba Buena Ballroom Salons 2-6: Tiny Teams</Room>
    <Scheduled_At>4 Jun 2025 11:15 AM</Scheduled_At>
    <Speakers>Eric Simons</Speakers>
    <Companies>Bolt</Companies>
    
    
</69>
<70>
    <Session_ID>941249</Session_ID>
    <Title>Rise of the AI Architect</Title>
    <Description>As the amount of consumer facing AI products grows, the most forward leaning enterprises have created a new role: the AI Architect. These leaders are responsible for helping define, manage, and evolve their company's AI agent experiences over time.

In this session, Clay Bavor (Cofounder of Sierra) will join Alessio Fanelli (co-host of Latent Space) in a fireside chat to share what it means to be an AI Architect, success stories from the market, and the future of the role.</Description>
    <Session_Format>Talk</Session_Format>
    <Level>Intermediate</Level>
    <Scope>Introductory (landscape)</Scope>
    <Assigned_Track></Assigned_Track>
    <Room>SOMA: AI Architects</Room>
    <Scheduled_At>4 Jun 2025 11:15 AM</Scheduled_At>
    <Speakers>Alessio Fanelli, Clay Bavor</Speakers>
    <Companies>Latent Space, Sierra</Companies>
    
    
</70>
<71>
    <Session_ID>904722</Session_ID>
    <Title>Accelerating Investment Operations: How BlackRock Builds Custom Knowledge Apps at Scale.</Title>
    <Description>Investment Operations teams are the backbone of asset and investment management firms. Their day-to-day work not only enables portfolio managers to respond swiftly to market events but also ensures that complex, unstructured data flows seamlessly across the organization.
In this talk, we introduce a modular, Kubernetes-native AI framework purpose-built to scale custom Knowledge Apps across the enterprise. Designed with speed, flexibility, and compliance in mind, the framework empowers teams to launch production-grade document extraction applications in minutes instead of months, unlocking new levels of automation and efficiency for investment management workflows.
We’ll also share how this framework has helped BlackRock streamline document extraction processes, generate investment signals, reduce operational overhead, and accelerate the delivery of high-impact business use cases—all while maintaining the robustness and control required in a regulated industry.</Description>
    <Session_Format>Talk</Session_Format>
    <Level>Intermediate</Level>
    <Scope>Case Study/War Story</Scope>
    <Assigned_Track>AI in the Fortune 500 (L2)</Assigned_Track>
    <Room>Golden Gate Ballroom C: AI in the Fortune 500</Room>
    <Scheduled_At>4 Jun 2025 11:35 AM</Scheduled_At>
    <Speakers>Vaibhav Page, Infant Vasanth</Speakers>
    <Companies>BlackRock, BlackRock</Companies>
    
    
</71>
<72>
    <Session_ID>905305</Session_ID>
    <Title>Building Hyperbolic: The On-Demand AI Cloud for GPUs, Inference, and AI Services</Title>
    <Description>AI moves fast. Legacy cloud can’t keep up. This session breaks down how Hyperbolic is redefining what developers should expect from AI infrastructure. We’ll cover how to instantly spin up low-cost GPUs, serve cutting-edge models with serverless inference, and deploy AI services at scale without the DevOps, rate limits, or pricing surprises. Whether you're training, fine-tuning, or just shipping fast, this is the new standard for building with AI.</Description>
    <Session_Format>Talk</Session_Format>
    <Level>Expert</Level>
    <Scope>Technical deep dive</Scope>
    <Assigned_Track>AI Infrastructure (05)</Assigned_Track>
    <Room>Foothill F: Infrastructure</Room>
    <Scheduled_At>4 Jun 2025 11:35 AM</Scheduled_At>
    <Speakers>Dr. Jasper Zhang, PhD</Speakers>
    
    
    
</72>
<73>
    <Session_ID>907834</Session_ID>
    <Title>Building Applications with AI Agents</Title>
    <Description>Generative AI has dramatically shortened the distance between ideas and implementation, enabling faster prototyping and deployment than ever before. But while language models can streamline individual tasks, true transformation comes from combining these capabilities into intelligent, autonomous systems—AI agents.

This talk explores how to build and deploy foundation model-enabled agent systems that go beyond simple prompt chaining or chatbots. Drawing from real-world implementations and the latest research, it offers a clear and practical path to designing both single-agent and multi-agent systems capable of handling complex workflows with minimal oversight.

Attendees will gain a deeper understanding of the core design principles behind agentic systems, the architectural trade-offs involved in orchestrating multiple agents, and the strategies required to develop tailored solutions that enhance efficiency and innovation. Whether just beginning or scaling up, participants will leave with actionable insights to navigate the rapidly evolving world of AI autonomy.</Description>
    <Session_Format>Talk</Session_Format>
    <Level>Advanced</Level>
    <Scope>Technical deep dive</Scope>
    <Assigned_Track>AI Architects (L1)</Assigned_Track>
    <Room>SOMA: AI Architects</Room>
    <Scheduled_At>4 Jun 2025 11:35 AM</Scheduled_At>
    <Speakers>Michael Albada</Speakers>
    <Companies>Microsoft Research</Companies>
    
    
</73>
<74>
    <Session_ID>914080</Session_ID>
    <Title>12 Factor Agents - Principles of Reliable LLM Applications</Title>
    <Description>Hi, I'm Dex. I've been hacking on AI agents for a while.

I've tried every agent framework out there, from the plug-and-play crew/langchains to the "minimalist" smolagents of the world to the "production grade" langraph, griptape, etc.

I've talked to a lot of really strong founders who are all building really impressive things with AI. Most of them are rolling the stack themselves. I don't see a lot of frameworks in production customer-facing agents.

I've been surprised to find that most of the products out there billing themselves as "AI Agents" are not all that agentic. A lot of them are mostly deterministic code, with LLM steps sprinkled in at just the right points to make the experience truly magical.

Agents, at least the good ones, don't follow the "here's your prompt, here's a bag of tools, loop until you hit the goal" pattern. Rather, they are comprised of mostly just software.

So, I set out to answer:

What are the principles we can use to build LLM-powered software that is actually good enough to put in the hands of production customers?
</Description>
    <Session_Format>Talk</Session_Format>
    <Level>Advanced</Level>
    <Scope>Technical deep dive</Scope>
    <Assigned_Track>Agent Reliability (04)</Assigned_Track>
    <Room>Foothill C: Agent Reliability</Room>
    <Scheduled_At>4 Jun 2025 11:35 AM</Scheduled_At>
    <Speakers>Dexter Horthy</Speakers>
    <Companies>HumanLayer</Companies>
    
    
</74>
<75>
    <Session_ID>914548</Session_ID>
    <Title>Wisdom Discovery at Scale: Code Less KAG with n8n MultiAI Agents</Title>
    <Description>"Wisdom Discovery at Scale: Code Less KAG with n8n MultiAI Agents"</Description>
    <Session_Format>Talk</Session_Format>
    <Level>Intermediate</Level>
    <Scope>Case Study/War Story</Scope>
    <Assigned_Track>GraphRAG (08)</Assigned_Track>
    <Room>Golden Gate Ballroom B: GraphRAG</Room>
    <Scheduled_At>4 Jun 2025 11:35 AM</Scheduled_At>
    <Speakers>Chin Keong Lam</Speakers>
    <Companies>Patho.ai</Companies>
    
    
</75>
<76>
    <Session_ID>914550</Session_ID>
    <Title>The New Lean Startup</Title>
    <Description>In this session, I will be presenting a case study of Oleve's journey, revealing how we've scaled a profitable multi-product portfolio with a tiny team. I'll walk you through the emergence of "tiny teams," our two-track engineering methodology that has become our blueprint, as well as an inside look at our technical alpha – specifically how we've engineered deterministic AI agents to deliver magical and reliable consumer experiences to millions. You'll learn how we've built internal tools to grow leanly and created operating playbooks to scale operations without traditional headcount requirements. I'll also share our approach to scrappy infrastructure innovation and how our investment in internal tooling has served as a critical force multiplier. Finally, I'll give an overview of parts of the profitable portfolio playbook that keeps us lean, adaptable, and profitable across multiple product lines.

Structure of talk:
- the tiny teams revolution
- the two-track engineering approach
- technical alpha: deterministic ai agents at scale
- scrappy infrastructure innovation
- internal tooling as a multiplier
- the profitable portfolio playbook</Description>
    <Session_Format>Talk</Session_Format>
    <Level>Introductory and overview</Level>
    <Scope>Case Study/War Story</Scope>
    <Assigned_Track>Tiny Teams (01)</Assigned_Track>
    <Room>Yerba Buena Ballroom Salons 2-6: Tiny Teams</Room>
    <Scheduled_At>4 Jun 2025 11:35 AM</Scheduled_At>
    <Speakers>Sid Bendre</Speakers>
    <Companies>Oleve</Companies>
    
    
</76>
<77>
    <Session_ID>914842</Session_ID>
    <Title>Why your product needs an AI product manager, and why it should be you</Title>
    <Description>So you've built another cool demo. Now what? You have hype, but not impact. You have kudos but no users. Ultimately you have a demo, but not a product.

The unique uncertainty of AI technology demands a new approach – beyond traditional product management. You need an AI Product Manager. This talk explains why this role is essential for building real AI products, using real case studies from the incubator for Artificial Intelligence in the UK Government.

More importantly, it reveals why your technical depth makes you uniquely suited to step into this critical leadership gap. Discover why could be the ideal candidate to be the AI Product Manager your product needs, and how to step into that role.</Description>
    <Session_Format>Talk</Session_Format>
    <Level>Intermediate</Level>
    <Scope>Case Study/War Story</Scope>
    <Assigned_Track>Product Management (06)</Assigned_Track>
    <Room>Foothill G 1&2: Product Management</Room>
    <Scheduled_At>4 Jun 2025 11:35 AM</Scheduled_At>
    <Speakers>James Lowe</Speakers>
    <Companies>Incubator for AI </Companies>
    
    
</77>
<78>
    <Session_ID>931123</Session_ID>
    <Title>Shipping an Enterprise Voice AI Agent in 100 Days</Title>
    <Description>What does it take to go from blank page to live enterprise voice agent in 100 days?

That’s the challenge we took on with Fin Voice at Intercom. Enterprise customer service demands high-quality, reliable voice interactions - but delivering that fast means wrestling with tough problems like latency, hallucinations, voice quality, and answer accuracy.

We rapidly evaluated and integrated a full voice stack - including transcription, language model, text-to-speech, retrieval-augmented generation, and telephony - while designing tools that fit seamlessly into existing human support workflows.

In this session, I’ll share key lessons from our accelerated development of Fin Voice. We'll explore the technical and operational hurdles we faced, the trade-offs we made, and how we built deployment and handover tools that work for customer service teams. You'll leave with insights into building AI-driven voice products that are both powerful and practical.</Description>
    <Session_Format>Talk</Session_Format>
    <Level>Intermediate</Level>
    <Scope>Case Study/War Story</Scope>
    <Assigned_Track>Voice (07)</Assigned_Track>
    <Room>Foothill E: Voice</Room>
    <Scheduled_At>4 Jun 2025 11:35 AM</Scheduled_At>
    <Speakers>Peter Bar</Speakers>
    <Companies>Intercom</Companies>
    
    
</78>
<79>
    <Session_ID>932498</Session_ID>
    <Title>What We Learned from Using LLMs in Pinterest Search</Title>
    <Description>Pinterest Search integrates Large Language Models (LLMs) to enhance relevance scoring by combining search queries with rich multimodal content, including visual captions, link-based text, and user curation signals. A semi-supervised learning framework enables scaling to large and multilingual datasets, going beyond English and limited human labels. These LLM-driven models are distilled into efficient architectures for real-time serving, with experimental validation and large-scale deployment demonstrating substantial improvements in search relevance for Pinterest users worldwide.</Description>
    <Session_Format>Talk</Session_Format>
    <Level>Intermediate</Level>
    <Scope>Technical deep dive</Scope>
    <Assigned_Track></Assigned_Track>
    <Room>Golden Gate Ballroom A: LLM RecSys</Room>
    <Scheduled_At>4 Jun 2025 11:35 AM</Scheduled_At>
    <Speakers>Mukuntha Narayanan, Han Wang</Speakers>
    <Companies>Pinterest, Inc., Pinterest</Companies>
    
    
</79>
<80>
    <Session_ID>942943</Session_ID>
    <Title>What we learned from shipping remote MCP support at Anthropic</Title>
    <Description>We recently released remote MCP support for both claude.ai and the Anthropic API. This talk will cover architectural decisions we made in our implementation, remote MCP authentication, supporting engineers who are building out agentic AI tools, implementing custom internal transports, and whatever else we can fit into 18 minutes of your time.</Description>
    <Session_Format>Talk</Session_Format>
    <Level>Advanced</Level>
    <Scope>Technical deep dive</Scope>
    <Assigned_Track></Assigned_Track>
    <Room>Yerba Buena Ballroom Salons 7-8: MCP</Room>
    <Scheduled_At>4 Jun 2025 11:35 AM</Scheduled_At>
    <Speakers>John Welsh</Speakers>
    <Companies>Anthropic</Companies>
    
    
</80>
<81>
    <Session_ID>911846</Session_ID>
    <Title>Using OSS models to build AI apps with millions of users</Title>
    <Description>In this talk, Hassan will go over how he builds open source AI apps that get millions of users like roomGPT.io (2.9 million users), restorePhotos.io (1.1 million users), Blinkshot.io (1 million visitors), and LlamaCoder.io (1.4 million visitors). He'll go over his journey in AI, demo some of the apps that he's built, and dig into his tech stack and code to explain how he builds these apps from scratch. He’ll also go over how to market them and go over his top tips and tricks for building great full-stack AI applications quickly and efficiently.

This talk will start from first principles and give you a glimpse into Hassan’s workflow of idea -> working app -> many users. Attendees should come out of this session equipped with the resources to build impressive AI applications and understand some of the behind the scenes of how they’re built and marketed. This will hopefully serve as an educational and inspirational talk that encourages builders to go build cool things.</Description>
    <Session_Format>Talk</Session_Format>
    <Level>Introductory and overview</Level>
    <Scope>Introductory (landscape)</Scope>
    <Assigned_Track>Tiny Teams (01)</Assigned_Track>
    <Room>Yerba Buena Ballroom Salons 2-6: Tiny Teams</Room>
    <Scheduled_At>4 Jun 2025 11:55 AM</Scheduled_At>
    <Speakers>Hassan El Mghari</Speakers>
    <Companies>Together AI</Companies>
    
    
</81>
<82>
    <Session_ID>912811</Session_ID>
    <Title>When Vectors Break Down: Graph-Based RAG for Dense Enterprise Knowledge</Title>
    <Description>Enterprise knowledge bases are filled with "dense mapping," thousands of documents where similar terms appear repeatedly, causing traditional vector retrieval to return the wrong version or irrelevant information. When our customers kept hitting this wall with their RAG systems, we knew we needed a fundamentally different approach.

In this talk, I'll share Writer's journey developing a graph-based RAG architecture that achieved 86.31% accuracy on the RobustQA benchmark while maintaining sub-second response times, significantly outperforming vector approaches.

I'll survey the key techniques behind this performance leap and why graph-based approaches excel with complex enterprise information structures like product documentation, financial documents, and technical specifications that challenge traditional RAG systems. You'll learn about using specialized LLMs to build semantic relationships, how compression techniques efficiently handle concentrated enterprise data patterns, and how infusing key data points in the memory layer of the LLM lowers hallucination.

The presentation will provide practical insights into identifying when graph-based approaches make sense for your organization's specific data challenges, helping you make informed architectural decisions for your next enterprise RAG system.</Description>
    <Session_Format>Talk</Session_Format>
    <Level>Intermediate</Level>
    <Scope>Technical deep dive</Scope>
    <Assigned_Track>GraphRAG (08)</Assigned_Track>
    <Room>Golden Gate Ballroom B: GraphRAG</Room>
    <Scheduled_At>4 Jun 2025 11:55 AM</Scheduled_At>
    <Speakers>Sam Julien</Speakers>
    <Companies>Writer</Companies>
    
    
</82>
<83>
    <Session_ID>913755</Session_ID>
    <Title>Scaling AI agents without breaking reliability</Title>
    <Description>As AI agents move from prototypes to production, developers are running into new challenges with orchestration, failure handling, and infrastructure. This session will unpack lessons from teams already building real-world systems and share how to design for reliability from the start.</Description>
    <Session_Format>Talk</Session_Format>
    <Level>Intermediate</Level>
    <Scope>Technical deep dive</Scope>
    <Assigned_Track>AI Infrastructure (05)</Assigned_Track>
    <Room>Foothill C: Agent Reliability</Room>
    <Scheduled_At>4 Jun 2025 11:55 AM</Scheduled_At>
    <Speakers>Preeti Somal</Speakers>
    <Companies>Temporal</Companies>
    
    
</83>
<84>
    <Session_ID>914489</Session_ID>
    <Title>Full Spectrum MCP: Uncovering Hidden Servers and Clients Capabilities</Title>
    <Description>The true power of Model Context Protocol emerges when clients and servers collaborate across the full spectrum of the specification. This talk presents practical examples of how VS Code's comprehensive implementation of MCP transforms the capabilities of AI assistants, making them more contextual, efficient, and user-friendly. We'll showcase advanced features like dynamic tool discovery and workspace-aware roots, demonstrating how they create experiences impossible with standard tools integrations while confronting the reality gap between MCP's theoretical potential and practical implementation challenges.</Description>
    <Session_Format>Talk</Session_Format>
    <Level>Intermediate</Level>
    <Scope>Technical deep dive</Scope>
    <Assigned_Track></Assigned_Track>
    <Room>Yerba Buena Ballroom Salons 7-8: MCP</Room>
    <Scheduled_At>4 Jun 2025 11:55 AM</Scheduled_At>
    <Speakers>Harald Kirschner</Speakers>
    
    
    
</84>
<85>
    <Session_ID>915031</Session_ID>
    <Title>What we can learn from self driving in autonomous voice agents</Title>
    <Description>The reliability challenges facing voice & chat AI deployment today mirror those that the autonomous vehicle industry confronted years ago. This talk explores how evaluation methodologies developed for self-driving cars can be transferred to create autonomous, self-improving evaluation systems for conversational AI. Drawing from my experience building evaluation infrastructure at Waymo and now developing Coval, an enterprise-grade reliability platform for conversational agents, I'll demonstrate how systematic testing infrastructure is not just a technical requirement but a competitive advantage in the rapidly evolving AI landscape.</Description>
    <Session_Format>Talk</Session_Format>
    <Level>Advanced</Level>
    <Scope>Introductory (landscape)</Scope>
    <Assigned_Track>Voice (07)</Assigned_Track>
    <Room>Foothill E: Voice</Room>
    <Scheduled_At>4 Jun 2025 11:55 AM</Scheduled_At>
    <Speakers>Brooke Hopkins</Speakers>
    <Companies>Coval</Companies>
    
    
</85>
<86>
    <Session_ID>915616</Session_ID>
    <Title>How agents will unlock the $500B promise of AI</Title>
    <Description>AI agents are on the cusp of revolutionizing work as we know it. The number of use cases software can tackle is set to explode as AI handles tasks requiring real judgment. But to cross the gap between an interesting AI prototype and an essential business tool, you need agents built by developers with real guardrails and security.

This means blending AI assistance with traditional coding in a multimodal approach that maximizes efficiency and control. The future isn't about dropping in an LLM — it requires integrating any model, any data, any system to deliver results. 

Companies utilizing this approach can finally turn their slice of the $500B+ of total AI investment into real business results. 
</Description>
    <Session_Format>Talk</Session_Format>
    <Level>Advanced</Level>
    <Scope>Technical deep dive</Scope>
    <Assigned_Track>AI in the Fortune 500 (L2)</Assigned_Track>
    <Room>Golden Gate Ballroom C: AI in the Fortune 500</Room>
    <Scheduled_At>4 Jun 2025 11:55 AM</Scheduled_At>
    <Speakers>David Hsu</Speakers>
    <Companies>Retool </Companies>
    
    
</86>
<87>
    <Session_ID>915990</Session_ID>
    <Title>The Rise of Open Models in the Enterprise</Title>
    <Description>This year kicked off with the DeepSeek-R1 news cycle breaking out of our AI Engineering bubble into the mainstream tech and business world. Leaders at the highest levels of the largest enterprises started asking how open source models could enhance and accelerate their AI strategy.

Open source models promise increased ownership of AI systems: control over performance and price, improved uptime and reliability, better compliance, and flexible hosting options. How are these promises playing out after months of implementation? In this talk, I’ll draw on hundreds of conversations with AI leaders at enterprise companies to discuss what has — and hasn’t — changed about enterprise AI strategy in a world where open-source models compete on the frontier of intelligence.</Description>
    <Session_Format>Talk</Session_Format>
    <Level>Introductory and overview</Level>
    <Scope>Introductory (landscape)</Scope>
    <Assigned_Track>AI Architects (L1)</Assigned_Track>
    <Room>SOMA: AI Architects</Room>
    <Scheduled_At>4 Jun 2025 11:55 AM</Scheduled_At>
    <Speakers>Amir Haghighat</Speakers>
    <Companies>Baseten</Companies>
    
    
</87>
<88>
    <Session_ID>936205</Session_ID>
    <Title>360Brew LLM-based Foundation Model for Personalized Ranking and Recommendation</Title>
    <Description>We will give a talk about our journey of building a foundation model for solving ranking and recommendation tasks across LinkedIn platform</Description>
    <Session_Format>Talk</Session_Format>
    <Level>Intermediate</Level>
    <Scope>Technical deep dive</Scope>
    <Assigned_Track></Assigned_Track>
    <Room>Golden Gate Ballroom A: LLM RecSys</Room>
    <Scheduled_At>4 Jun 2025 11:55 AM</Scheduled_At>
    <Speakers>Hamed Firooz, Maziar Sanjabi</Speakers>
    <Companies>LinkedIn, LinkedIn</Companies>
    
    
</88>
<89>
    <Session_ID>937137</Session_ID>
    <Title>Large Scale AI on Apple Silicon using EXO</Title>
    <Description>The hardware lottery: when a research idea wins because it is better suited to current hardware and software, and not because it is universally superior.

Machine learning researchers frequently regard hardware as a hard limit and halt their exploration. Yet throughout history, the decisive factor has often been which algorithm best fits the prevailing hardware-software stack - neural networks being the classic example.

In this talk, EXO Labs co-founder Alex Cheema will share recent algorithmic improvements for running large scale AI workloads on Apple Silicon.

Alex will demonstrate how the EXO Framework enables inference, fine-tuning, and training of large ML models on Apple Silicon, from the scale of one MacBook locally to clusters of colocated M3 Ultra Mac Studios.</Description>
    <Session_Format>Talk</Session_Format>
    <Level>Introductory and overview</Level>
    <Scope>Introductory (landscape)</Scope>
    <Assigned_Track></Assigned_Track>
    <Room>Foothill F: Infrastructure</Room>
    <Scheduled_At>4 Jun 2025 11:55 AM</Scheduled_At>
    <Speakers>Alex Cheema</Speakers>
    <Companies>EXO Labs</Companies>
    
    
</89>
<90>
    <Session_ID>945392</Session_ID>
    <Title>Shipping something to someone always wins</Title>
    <Description>Learnings from building products at Stripe and applying them in an AI native word</Description>
    <Session_Format>Talk</Session_Format>
    <Level>Advanced</Level>
    <Scope>Technical deep dive</Scope>
    <Assigned_Track></Assigned_Track>
    <Room>Foothill G 1&2: Product Management</Room>
    <Scheduled_At>4 Jun 2025 11:55 AM</Scheduled_At>
    <Speakers>Kenneth  Auchenberg</Speakers>
    <Companies>AlleyCorp </Companies>
    
    
</90>
<91>
    <Session_ID>914975</Session_ID>
    <Title>Survive the AI Knife-Fight: Building Products That Win</Title>
    <Description>If you’ve ever been blocked by vague specs, shifting goals, or chasing “vibes,” things have only gotten messier in the age of AI. Everyone is obsessing over engineers doing PM work and PMs cranking out prototypes—but that skips the hardest question: What should we build, and why will it win? Today’s competitive landscape is a knife-fight.  When it’s trivial to ship “something,” true differentiation becomes brutally difficult.</Description>
    <Session_Format>Keynote</Session_Format>
    <Level>Intermediate</Level>
    <Scope>Case Study/War Story</Scope>
    <Assigned_Track>Product Management (06)</Assigned_Track>
    <Room>Foothill G 1&2: Product Management</Room>
    <Scheduled_At>4 Jun 2025 12:15 PM</Scheduled_At>
    <Speakers>Brian Balfour</Speakers>
    <Companies>Reforge</Companies>
    
    
</91>
<92>
    <Session_ID>915023</Session_ID>
    <Title>Stop Using RAG as Memory</Title>
    <Description>RAG is great for static knowledge retrieval—but terrible at memory. Vectorstore-based systems sold as memory lack relational and temporal awareness, leading agents astray with outdated or ambiguous information.

Discover how temporally-aware knowledge graphs—built by the open-source Graphiti framework—solve these limitations. You’ll learn practical strategies to maintain precise, context-rich memory, enabling agents to reason accurately about historical context and knowledge provenance.</Description>
    <Session_Format>Online Talk</Session_Format>
    <Level>Intermediate</Level>
    <Scope>Technical deep dive</Scope>
    <Assigned_Track>GraphRAG (08)</Assigned_Track>
    <Room>Golden Gate Ballroom B: GraphRAG</Room>
    <Scheduled_At>4 Jun 2025 12:15 PM</Scheduled_At>
    <Speakers>Daniel Chalef</Speakers>
    
    
    
</92>
<93>
    <Session_ID>915312</Session_ID>
    <Title>Production software keeps breaking and it will only get worse.  Here’s how Traversal is fixing it.</Title>
    <Description>Software is eating the world. AI is eating software. AI-powered SWE means a whole lot more software is going to be written that powers mission critical systems in the coming years, with hardly any of it written by humans. Hence, when these software systems inevitably break, it’s going to be next to impossible to troubleshoot them. Towards addressing this issue, we’ll do a product launch of Traversal’s AI, a significant step towards self-healing software systems. We will showcase how it is already used to autonomously troubleshoot production incidents in some of the most complex enterprise environments.</Description>
    <Session_Format>Talk</Session_Format>
    <Level>Introductory and overview</Level>
    <Scope>Product launch</Scope>
    <Assigned_Track>SWE Agents (11)</Assigned_Track>
    <Room>Foothill C: Agent Reliability</Room>
    <Scheduled_At>4 Jun 2025 12:15 PM</Scheduled_At>
    <Speakers>Anish Agarwal, Matthew Schoenbauer, Raj Agrawal, Raaz Dwivedi</Speakers>
    <Companies>Traversal, Traversal, Traversal, Traversal</Companies>
    
    
</93>
<94>
    <Session_ID>933545</Session_ID>
    <Title>Mentoring the Machine</Title>
    <Description>You’d never let a swarm of fresh interns ship to prod on day one—same deal with AI agents. Mentoring the Machine dives into how acting like a tech lead (not just a user) turns those bots into real leverage. In this talk, Eric will deliver practical advice for working with AI agents in the SDLC. He'll also preview how effective use of AI agents changes the calculus of software engineering at both a micro and macro level.
</Description>
    <Session_Format>Talk</Session_Format>
    <Level>Intermediate</Level>
    <Scope>Technical deep dive</Scope>
    <Assigned_Track></Assigned_Track>
    <Room>SOMA: AI Architects</Room>
    <Scheduled_At>4 Jun 2025 12:15 PM</Scheduled_At>
    <Speakers>Eric Hou</Speakers>
    <Companies>Augment Computing</Companies>
    
    
</94>
<95>
    <Session_ID>937225</Session_ID>
    <Title>3 ingredients for building reliable enterprise agents</Title>
    <Description>It's easy to build a prototype of an agent, but hard to put an agent in production - especially in an enterprise setting. In this section, will talk about three ingredients for building reliable agents in the enterprise.</Description>
    <Session_Format>Talk</Session_Format>
    <Level>Intermediate</Level>
    <Scope>Introductory (landscape)</Scope>
    <Assigned_Track></Assigned_Track>
    <Room>Golden Gate Ballroom C: AI in the Fortune 500</Room>
    <Scheduled_At>4 Jun 2025 12:15 PM</Scheduled_At>
    <Speakers>Harrison Chase</Speakers>
    <Companies>LangChain</Companies>
    
    
</95>
<96>
    <Session_ID>937506</Session_ID>
    <Title>Serving Voice AI at $1/hr: Open-source, LoRAs, Latency, Load Balancing</Title>
    <Description>This is a talk that goes over our experience deploying Orpheus (Emotive, Realtime TTS) to production. It will cover topics:

- Latency and optimizations
- High fidelity voice clones w/ examples
- Load balancing w/ multiple GPUs and multiple LoRas</Description>
    <Session_Format></Session_Format>
    <Level>Intermediate</Level>
    <Scope>Technical deep dive</Scope>
    <Assigned_Track></Assigned_Track>
    <Room>Foothill E: Voice</Room>
    <Scheduled_At>4 Jun 2025 12:15 PM</Scheduled_At>
    <Speakers>Neil Dwyer, Jack Dwyer</Speakers>
    <Companies>Gabber, Gabber</Companies>
    
    
</96>
<97>
    <Session_ID>940118</Session_ID>
    <Title>Gumloop's Path to be a 10 person unicorn</Title>
    <Description>An overview of how Gumloop is scaling automation across companies like Instacart, Webflow and Shopify with less than 10 people.</Description>
    <Session_Format>Talk</Session_Format>
    <Level>Introductory and overview</Level>
    <Scope>Case Study/War Story</Scope>
    <Assigned_Track>Tiny Teams (01)</Assigned_Track>
    <Room>Yerba Buena Ballroom Salons 2-6: Tiny Teams</Room>
    <Scheduled_At>4 Jun 2025 12:15 PM</Scheduled_At>
    <Speakers>Max Brodeur-Urbas</Speakers>
    <Companies>Gumloop</Companies>
    
    
</97>
<98>
    <Session_ID>933629</Session_ID>
    <Title>How to trust an agent with software delivery</Title>
    <Description>AI-powered agents promise faster, easier software delivery, but their unpredictable behavior often makes engineers hesitant to fully trust them with critical workflows. Sam Alba, Co-founder of Dagger (and previously co-creator of Docker), explains how teams can reliably integrate agents into their delivery pipelines by shifting how they structure and manage automation.

He'll share four practical strategies learned from real-world experience:

1. Treat agents as workflow participants, not isolated tools.
Stop using agents as disconnected scripts or IDE plugins. Treating them as first-class parts of your delivery process simplifies your architecture, reduces hidden complexity, and makes agent outcomes more predictable.

2. Use many small agents instead of one big one.
Just as software evolved from monoliths to microservices, software delivery benefits from smaller, specialized agents with clearly defined responsibilities. Smaller agents are easier to understand, maintain, and integrate.

3. Define clear environments—the real lever for reliability.
Instead of chasing perfect prompts or models, focus on clearly defining the tools, resources, and permissions around your agents. Precisely controlling their environments makes agents behave consistently and reliably.

4. Design workflows for easy debugging and observability.
Agents will sometimes fail unexpectedly. Sam will share simple, effective ways to build clear tracing and observability into your workflows from the start, making debugging quicker and less frustrating.

You'll leave with practical, immediately usable techniques that give you the confidence to trust AI agents in your software delivery pipelines.</Description>
    <Session_Format></Session_Format>
    <Level>Intermediate</Level>
    <Scope>Technical deep dive</Scope>
    <Assigned_Track></Assigned_Track>
    <Room>Willow: Expo Sessions</Room>
    <Scheduled_At>4 Jun 2025 12:45 PM</Scheduled_At>
    <Speakers>Sam Alba</Speakers>
    <Companies>Dagger</Companies>
    
    
</98>
<99>
    <Session_ID>933716</Session_ID>
    <Title>How fast are LLM inference engines anyway?</Title>
    <Description>Open weights models and open source inference servers have made massive strides in the year since we last got together at AIE World's Fair.

Where once we had only pirated LLaMA 2 weights and Transformers, we now have an embarrassment of riches. In fact, we have too many choices! What's an AI engineer looking to self-host inference to do?

In this session, we'll share our benchmarking results from hundreds of runs across models, frameworks, and hardware. We'll also share tips and tricks from working with teams deploying LLM inference at scale.</Description>
    <Session_Format></Session_Format>
    <Level>Intermediate</Level>
    <Scope>Technical deep dive</Scope>
    <Assigned_Track></Assigned_Track>
    <Room>Juniper: Expo Sessions</Room>
    <Scheduled_At>4 Jun 2025 12:45 PM</Scheduled_At>
    <Speakers>Charles Frye</Speakers>
    <Companies>Modal Labs</Companies>
    
    
</99>
<100>
    <Session_ID>939093</Session_ID>
    <Title>Building Agentic Applications with Heroku Managed Inference and Agents</Title>
    <Description>In this workshop, you’ll learn how to use Heroku Managed Inference and Agents to build agentic applications. We’ll cover how to provision and deploy LLM models to your app, run untrusted code securely in Python, Node.js, Go, and Ruby using built-in tools, and use the Model Context Protocol (MCP) to connect tools and actions that extend your agents' capabilities.</Description>
    <Session_Format>Workshop</Session_Format>
    <Level>Introductory and overview</Level>
    <Scope>Introductory (landscape)</Scope>
    <Assigned_Track></Assigned_Track>
    <Room>Nobhill A&B: Expo Sessions</Room>
    <Scheduled_At>4 Jun 2025 12:45 PM</Scheduled_At>
    <Speakers>Julián  Duque, Anush Dsouza</Speakers>
    <Companies>Heroku, Heroku</Companies>
    
    
</100>
<101>
    <Session_ID>944039</Session_ID>
    <Title>AI Red Teaming Agent: Accelerate your AI safety and security journey with Azure AI Foundry</Title>
    <Description>In the age of autonomous AI agents, ensuring their safety and reliability is paramount. But how can we proactively uncover vulnerabilities before they impact real-world scenarios? Enter Azure AI Evaluation SDK’s Red Teaming Agent—a cutting-edge tool designed to rigorously challenge your AI agents, exposing hidden risks and unexpected behaviors. This session will guide you through the powerful capabilities of Azure’s Red Teaming Agent, demonstrating how it simulates adversarial scenarios, stress-tests agentic decision-making, and ensures your applications remain robust, ethical, and safe. You’ll learn practical techniques for systematically identifying weaknesses, interpreting evaluation results, and integrating safety checks into your development lifecycle. Join us to explore how embracing adversarial testing not only mitigates risks but strengthens trust in your AI solutions—keeping you ahead in the rapidly evolving landscape of responsible AI.</Description>
    <Session_Format></Session_Format>
    <Level></Level>
    <Scope></Scope>
    <Assigned_Track></Assigned_Track>
    <Room>Nobhill C&D: Microsoft</Room>
    <Scheduled_At>4 Jun 2025 12:45 PM</Scheduled_At>
    <Speakers>Nagkumar Arkalgud, Keiji Kanazawa</Speakers>
    <Companies>Microsoft, Microsoft</Companies>
    
    
</101>
<102>
    <Session_ID>916143</Session_ID>
    <Title>Make Your AI Agents Remember What They Do!</Title>
    <Description>Are you ready to give your AI agents a memory upgrade? 
Join us for a hands-on, fast-paced workshop where we explore how memory can transform your agents.

What You'll Do:
Set Up Leading Memory Solutions: Get practical, side-by-side experience with open-source tools including AIUS, Cognee, LangMem, MemGPT, Mem0, and Zep.

Explore Memory Types: Learn the theory behind agent memory, including long-term, short-term, episodic, semantic, and other memory types.

Run Experiments: Test how memory improves recall, contextual awareness, and reasoning in autonomous agents.

Compare Implementations: Get a snapshot of how different solutions implement memory—what’s built-in, what’s flexible, and what’s experimental.

Whether you’re working on AI copilots, agentic workflows, or research prototypes—this workshop will help you embed real memory into your AI stack.</Description>
    <Session_Format>Workshop</Session_Format>
    <Level>Introductory and overview</Level>
    <Scope>Technical deep dive</Scope>
    <Assigned_Track></Assigned_Track>
    <Room>Golden Gate Ballroom B: GraphRAG</Room>
    <Scheduled_At>4 Jun 2025 01:00 PM</Scheduled_At>
    <Speakers>Mark Bain</Speakers>
    <Companies>AIUS Technologies Inc.</Companies>
    
    
</102>
<103>
    <Session_ID>933621</Session_ID>
    <Title>Effective agent design patterns in production</Title>
    <Description>At LlamaIndex we see a lot of agents built every day, and we've got a sense of what works and what doesn't. We've distilled those learnings down into a series of patterns and best practices for building real-world, production agents, and we're here to share them. You'll learn patterns for applying structure and guidance to famously nondeterministic LLMs and get concrete instruction on how to implement them.</Description>
    <Session_Format></Session_Format>
    <Level>Intermediate</Level>
    <Scope>Technical deep dive</Scope>
    <Assigned_Track></Assigned_Track>
    <Room>Juniper: Expo Sessions</Room>
    <Scheduled_At>4 Jun 2025 01:00 PM</Scheduled_At>
    <Speakers>Laurie Voss</Speakers>
    
    
    
</103>
<104>
    <Session_ID>933636</Session_ID>
    <Title>Everything is changing</Title>
    <Description>We believe programming with AI is going through massive changes — again.

Turns out the models yearn for the tools and tokens. We hold them back if we make them ask before they can change a file.

Give them tools & tokens and everything changes: what we use them for, how we use them, how many we run at the same time, how they talk to each other, how they talk to you, what they even are...

It's all going to change.

And with Amp, we're embracing it.

If you want to find out where this is all going — come with us.</Description>
    <Session_Format></Session_Format>
    <Level>Introductory and overview</Level>
    <Scope>Introductory (landscape)</Scope>
    <Assigned_Track></Assigned_Track>
    <Room>Salons 9-15: Expo Hall</Room>
    <Scheduled_At>4 Jun 2025 01:00 PM</Scheduled_At>
    <Speakers>Ado Kukic</Speakers>
    
    
    
</104>
<105>
    <Session_ID>933652</Session_ID>
    <Title>Events are the Wrong Abstraction for Your AI Agents</Title>
    <Description>AI Agents are distributed systems. Agents need to connect and communicate with tools, data repositories, other agents, etc., all over a network. Event-Driven Architecture is a common pattern for facilitating this connectivity, using Events as the communication abstraction. However, this pattern introduces complexities as well, such as fragmented logic, increased latency, decreased observability, and more. But what if there were a way to get the benefits of Event-Driven Architecture without the complexities? Enter Durable Execution. In this talk, we'll discuss the pitfalls of Event-Driven Architecture, how Durable Execution solves these issues, and why Durable Execution, not Events, is the correct abstraction for building AI Agents.</Description>
    <Session_Format></Session_Format>
    <Level>Intermediate</Level>
    <Scope>Introductory (landscape)</Scope>
    <Assigned_Track></Assigned_Track>
    <Room>Willow: Expo Sessions</Room>
    <Scheduled_At>4 Jun 2025 01:00 PM</Scheduled_At>
    <Speakers>Mason Egger</Speakers>
    
    
    
</105>
<106>
    <Session_ID>936818</Session_ID>
    <Title>Agentic Excellence: Mastering Evaluation of AI Agents with Azure AI Evaluation SDK</Title>
    <Description>As AI agents transition from experimental assistants to critical components of enterprise workflows, reliably evaluating their performance becomes essential. But how do you systematically measure an AI agent’s capabilities, contextual understanding, and accuracy across diverse scenarios?

In this talk, we'll dive deep into the Azure AI Evaluation SDK, an innovative tool designed to rigorously assess agentic applications. Learn how to create powerful evaluations using structured test plans, scenarios, and advanced analytics that pinpoint strengths and expose hidden weaknesses. Through practical examples and real-world case studies, you'll discover how companies are already leveraging this SDK to enhance agent trustworthiness, reliability, and performance.

Whether you're developing conversational agents, data-driven decision-makers, or autonomous workflow orchestrators, this session equips you with the techniques and insights needed to ensure your AI solutions deliver exceptional value and exceed user expectations.""
</Description>
    <Session_Format>Talk</Session_Format>
    <Level></Level>
    <Scope></Scope>
    <Assigned_Track></Assigned_Track>
    <Room>Nobhill C&D: Microsoft</Room>
    <Scheduled_At>4 Jun 2025 01:10 PM</Scheduled_At>
    <Speakers>Cedric  Vidal</Speakers>
    <Companies>Microsoft</Companies>
    
    
</106>
<107>
    <Session_ID>933641</Session_ID>
    <Title>Revenue Engineering: How to Price (and Reprice) Your AI Product</Title>
    <Description>You’ve trained the model—now it’s time to train the business. This talk dives into the engineering behind pricing systems that can evolve as fast as your AI stack.

Orb CTO Kshitij Grover will walk through how leading AI companies design infrastructure to support experimentation, scale, and real-world monetization constraints.

Topics include:
- How to meter usage and map it to pricing with accuracy and auditability
- Factoring in margins and underlying costs when designing pricing strategy
- Handling complexity across motions: self-serve vs. enterprise, pay-as-you-go vs. committed contracts
- How to test pricing changes safely (and roll them back when needed)

Whether you’re bootstrapping a pricing system from scratch or replacing a brittle V1, you’ll leave with architectural patterns and mental models to make pricing a first-class engineering concern.
</Description>
    <Session_Format></Session_Format>
    <Level>Introductory and overview</Level>
    <Scope>Technical deep dive</Scope>
    <Assigned_Track></Assigned_Track>
    <Room>Juniper: Expo Sessions</Room>
    <Scheduled_At>4 Jun 2025 01:15 PM</Scheduled_At>
    <Speakers>Kshitij  Grover</Speakers>
    
    
    
</107>
<108>
    <Session_ID>936903</Session_ID>
    <Title>Real-world MCPs in GitHub Copilot Agent Mode</Title>
    <Description>As developers, we don't spend most of our time vibe-coding prototypes. More often, we're adding features, squashing bugs, and building tests for existing apps across a wide variety of services and technologies. Come learn how MCPs help GitHub Copilot to untangle real engineering problems. By allowing agent mode to securely work with data sources, testing tools, infrastructure providers, and even core DevOps tooling -- we can go beyond the hype, and solve the actual engineering problems we face every day.</Description>
    <Session_Format>Talk</Session_Format>
    <Level></Level>
    <Scope></Scope>
    <Assigned_Track></Assigned_Track>
    <Room>Willow: Expo Sessions</Room>
    <Scheduled_At>4 Jun 2025 01:15 PM</Scheduled_At>
    <Speakers>Jon Peck</Speakers>
    <Companies>GitHub</Companies>
    
    
</108>
<109>
    <Session_ID>944044</Session_ID>
    <Title>Run 1000 branches of code with sandbox snapshotting</Title>
    <Description>A peek under the hood of how we built container checkpoints and restores to enable massively parallel agentic workflows.

No one wants to wait on infrastructure. In this short talk we’ll go through a demo and system design of container checkpoint/restore, which supports both burst autoscaling and agent branching for Modal's serverless Functions and Sandboxes.

Can you save a live container to a file? Can you save a live GPU? Come by the Modal booth to find out!</Description>
    <Session_Format>Talk</Session_Format>
    <Level>Introductory and overview</Level>
    <Scope>Technical deep dive</Scope>
    <Assigned_Track></Assigned_Track>
    <Room>Salons 9-15: Expo Hall</Room>
    <Scheduled_At>4 Jun 2025 01:15 PM</Scheduled_At>
    <Speakers>Jonathon Belotti</Speakers>
    <Companies>Modal</Companies>
    
    
</109>
<110>
    <Session_ID>933549</Session_ID>
    <Title>Agentic GraphRAG: AI’s Logical Edge</Title>
    <Description>AI models are getting tasked to do increasingly complex and industry specific tasks where different retrieval approaches provide distinct advantages in accuracy, explainability, and cost to execute. GraphRAG retrieval models have become a powerful tool to solve domain specific problems where answers require logical reasoning and correlation that can be aided by graph relationships and proximity algorithms. We will demonstrate how an agent architecture combining RAG and GraphRAG retrieval patterns can bridge the gap in data analysis, strategic planning, and retrieval to solve complex domain specific problems. </Description>
    <Session_Format></Session_Format>
    <Level>Intermediate</Level>
    <Scope>Introductory (landscape)</Scope>
    <Assigned_Track></Assigned_Track>
    <Room>Willow: Expo Sessions</Room>
    <Scheduled_At>4 Jun 2025 01:30 PM</Scheduled_At>
    <Speakers>Stephen Chin</Speakers>
    <Companies>Neo4j</Companies>
    
    
</110>
<111>
    <Session_ID>933568</Session_ID>
    <Title>The Agent Cockpit: Reimagining Developer UX for Orchestrating AI Fleets</Title>
    <Description>Today's development experiences are trapped in a craftsperson paradigm - one human, one agent, one task. But true productivity comes when developers can orchestrate multiple agents working in parallel, just as managers coordinate teams. This talk explores the radical UX transformation needed to support this new "software conductor" workflow. We'll share our discoveries building a multi-modal interface where developers fluidly shift between conversational commands, transient editing, and deep IDE immersion based on task complexity. Learn how notification design, contextual prompting, and background task vizualization enable true parallel development with AI and come together in a command centre like interface. </Description>
    <Session_Format>Online Talk</Session_Format>
    <Level>Intermediate</Level>
    <Scope>Introductory (landscape)</Scope>
    <Assigned_Track></Assigned_Track>
    <Room>Salons 9-15: Expo Hall</Room>
    <Scheduled_At>4 Jun 2025 01:30 PM</Scheduled_At>
    <Speakers>Lou Bichard</Speakers>
    
    
    
</111>
<112>
    <Session_ID>933669</Session_ID>
    <Title>"Data readiness" is a myth: Make AI Reliabile with an Agentic Semantic Layer</Title>
    <Description>The rapid progress in LLM capability has not translated to increased reliability for business critical AI use cases. The root-cause? Data is "not ready".
Conversational analytics doesn't go beyond the analyst team because it's hard to verify if the generated queries are actually doing what they are supposed to.
RAG based systems often fail to handle the breadth and depth of real world use-cases because it requires a prohibitive amount of preparation & maintenance of an underlying knowledge graph.

Agentic AI systems need to hard-code specific workflows to work reliably and end up looking more like software engineering with LLM calls instead of delivering on the promise of truly agentic workflows.

In all of these failure modes, the common culprit is that the planning or reasoning done by the LLM fails to accurately capture the user's intent or the domain's context aka the lack of a well prepared semantic data layer.

Enterprise data is silo-ed and vastly varying levels of quality and the perfect "semantic layer" and "metadata" is a moving target. New data is continuously being created and business definitions are rapidly changing and often entirely on-demand.
In this talk we'll share how you can build and maintain a semantic data layer that is maintained entirely by AI, and show (with live examples) how that dramatically improves reliability of the AI system that needs dynamic access to data.
We'll demonstrate how this sufficiently augments existing RAG, text-to-SQL and tool calling techniques and starts opening the door to reliable AI deployments.
</Description>
    <Session_Format>Talk</Session_Format>
    <Level>Intermediate</Level>
    <Scope>Technical deep dive</Scope>
    <Assigned_Track></Assigned_Track>
    <Room>Juniper: Expo Sessions</Room>
    <Scheduled_At>4 Jun 2025 01:30 PM</Scheduled_At>
    <Speakers>Anushrut Gupta</Speakers>
    <Companies>PromptQL</Companies>
    
    
</112>
<113>
    <Session_ID>936908</Session_ID>
    <Title>Agentic RAG: build a reasoning retrieval engine with Azure AI Search</Title>
    <Description></Description>
    <Session_Format>Talk</Session_Format>
    <Level></Level>
    <Scope></Scope>
    <Assigned_Track></Assigned_Track>
    <Room>Nobhill C&D: Microsoft</Room>
    <Scheduled_At>4 Jun 2025 01:35 PM</Scheduled_At>
    <Speakers>Marco Casalaina</Speakers>
    <Companies>Microsoft</Companies>
    
    
</113>
<114>
    <Session_ID>933685</Session_ID>
    <Title>Windsurf & Wonders</Title>
    <Description>Come learn about why Windsurf is the premiere choice for engineers and enterprises alike in applications of AI for development.</Description>
    <Session_Format></Session_Format>
    <Level>Intermediate</Level>
    <Scope>Introductory (landscape)</Scope>
    <Assigned_Track></Assigned_Track>
    <Room>Salons 9-15: Expo Hall</Room>
    <Scheduled_At>4 Jun 2025 01:45 PM</Scheduled_At>
    <Speakers>Tejashwa Tiwari, Tejashwa Tiwari</Speakers>
    <Companies>Windsurf, Windsurf</Companies>
    
    
</114>
<115>
    <Session_ID>911925</Session_ID>
    <Title>MCP is all you need</Title>
    <Description>Everyone is talking about agents, and right after that, they’re talking about agent-to-agent communications. Not surprisingly, various nascent, competing protocols are popping up to handle it.

But maybe all we need is MCP — the OG of GenAI communication protocols (it's from way back in 2024!).

Last year, Jason Liu gave the second most watched AIE talk — “Pydantic is all you need”.

This year, I (the creator of Pydantic) am continuing the tradition by arguing that MCP might be all we need for agent-to-agent communications.

What I’ll cover:

- Misusing Common Patterns: MCP was designed for desktop/IDE applications like Claude Code and Cursor. How can we adapt MCP for autonomous agents?
- Many Common Problems: MCP is great, but what can go wrong? How can you work around it? Can the protocol be extended to solve these issues?
- Monitoring Complex Phenomena: How does observability work (and not work) with MCP?
- Multiple Competing Protocols: A quick run-through of other agent communication protocols like A2A and AGNTCY, and probably a few more by June 😴
- Massive Crustaceans Party: What might success look like if everything goes to plan?</Description>
    <Session_Format>Talk</Session_Format>
    <Level>Intermediate</Level>
    <Scope>Introductory (landscape)</Scope>
    <Assigned_Track>MCP (02)</Assigned_Track>
    <Room>Yerba Buena Ballroom Salons 7-8: MCP</Room>
    <Scheduled_At>4 Jun 2025 02:00 PM</Scheduled_At>
    <Speakers>Samuel Colvin</Speakers>
    
    
    
</115>
<116>
    <Session_ID>915338</Session_ID>
    <Title>How to build Enterprise-aware agents</Title>
    <Description>While LLMs demonstrated impressive reasoning capabilities, their out-of-the-box reasoning is akin to hiring a brilliant but brand-new employee who doesn’t have the enterprise context of “how things are done at this company”. In this talk, I'll introduce “Workflow Search” as a paradigm to build enterprise-aware agents that can balance predictability on common tasks, and flexibility on unforeseen tasks.
</Description>
    <Session_Format>Talk</Session_Format>
    <Level>Advanced</Level>
    <Scope>Technical deep dive</Scope>
    <Assigned_Track>Agent Reliability (04)</Assigned_Track>
    <Room>Foothill C: Agent Reliability</Room>
    <Scheduled_At>4 Jun 2025 02:00 PM</Scheduled_At>
    <Speakers>Chau Tran, Chau Tran</Speakers>
    <Companies>unknown, Glean</Companies>
    
    
</116>
<117>
    <Session_ID>915648</Session_ID>
    <Title>Shipping Products When You Don’t Know What they Can Do</Title>
    <Description>A customer recently asked me: “Hey, can I tag your AI agent in a Google Doc comment?”

The honest answer: I have no idea! We never designed our agents to handle Google Doc comments, but we tried it anyway… and it worked! The agent performed beautifully, the customer was thrilled, and I was left bewildered.

Welcome to Product Management for AI agents, where roadmaps are fuzzy and we only learn the boundaries of our products after they’re released. When a product doesn’t follow predefined requirements but instead learns and improvises at runtime, PMs must give up control and lean into uncertainty, curiosity, experimentation, and fast feedback loops.

This talk is a field guide for Product/Engineering teams navigating this new reality. We’ll cover how to write specs for affordances instead of features, how to use AI evals as a product development tool, and how to perform User Acceptance Testing on undocumented emergent behavior. Most importantly, we’ll explore how to build trust with customers even when the answer is, truthfully, “I don’t know.”

If you’re managing AI-native products in 2025 the same way you managed web apps in 2020, you might find yourself A/B testing an agent that decided to go off and do C, D, and E all by themselves!
</Description>
    <Session_Format>Talk</Session_Format>
    <Level>Introductory and overview</Level>
    <Scope>Introductory (landscape)</Scope>
    <Assigned_Track>Product Management (06)</Assigned_Track>
    <Room>Foothill G 1&2: Product Management</Room>
    <Scheduled_At>4 Jun 2025 02:00 PM</Scheduled_At>
    <Speakers>Ben Stein</Speakers>
    <Companies>Teammates</Companies>
    
    
</117>
<118>
    <Session_ID>915740</Session_ID>
    <Title>Practical GraphRAG - Making LLMs smarter with Knowledge Graphs</Title>
    <Description>RAG has become one standard architecture component for GenAI applications to address hallucinations and integrate factual knowledge. While vector search over text is common, knowledge graphs represent a proven advancement by leveraging advanced RAG patterns to access and integrate interconnected factual information, complementing the language skills of LLMs. This talk explores GraphRAG challenges, implementation patterns, and real-world agentic examples with Google's ADK, demonstrating how this approach delivers more trustworthy and explainable GenAI solutions with enhanced reasoning capabilities.</Description>
    <Session_Format>Talk</Session_Format>
    <Level>Intermediate</Level>
    <Scope>Technical deep dive</Scope>
    <Assigned_Track>GraphRAG (08)</Assigned_Track>
    <Room>Golden Gate Ballroom B: GraphRAG</Room>
    <Scheduled_At>4 Jun 2025 02:00 PM</Scheduled_At>
    <Speakers>Michael Hunger, Jesús Barrasa, Stephen Chin</Speakers>
    <Companies>Neo4j, Neo4j, Neo4j</Companies>
    
    
</118>
<119>
    <Session_ID>916079</Session_ID>
    <Title>Building the Voice-First Future: Omnipresent Agents that Listen, Talk and Act</Title>
    <Description>We’re entering a world where talking to machines feels as natural as talking to people. Voice is about to become the dominant interface for technology - ambient, always-on, and human by default. To get there, we need infrastructure that can orchestrate voice, tools, memory, real-time reasoning and telephony. This talk explores the vision for voice and how we're making it work at scale. </Description>
    <Session_Format>Talk</Session_Format>
    <Level>Expert</Level>
    <Scope>Introductory (landscape)</Scope>
    <Assigned_Track>Voice (07)</Assigned_Track>
    <Room>Foothill E: Voice</Room>
    <Scheduled_At>4 Jun 2025 02:00 PM</Scheduled_At>
    <Speakers>Jordan Dearsley</Speakers>
    <Companies>Vapi</Companies>
    
    
</119>
<120>
    <Session_ID>916157</Session_ID>
    <Title>AI That Pays: Lessons from Revenue Cycle</Title>
    <Description>While much of the AI innovation in healthcare has centered on clinical and patient-facing applications, Revenue Cycle Management (RCM) remains an underexplored yet critical domain. Given the growing financial pressures facing providers, rethinking how healthcare gets paid is essential to ensuring access and sustainability. The combination of which makes RCM an opportune area for AI disruption.

This session explores how the combination of vast structured and unstructured data, often rule-based workflows, and direct financial opportunity to drive meaningful outcomes. We’ll also share practical lessons from our journey evolving a traditional machine learning mindset to incorporate the latest advances in Generative AI, and how that shift is reshaping what's possible in healthcare operations.</Description>
    <Session_Format>Talk</Session_Format>
    <Level>Introductory and overview</Level>
    <Scope>Introductory (landscape)</Scope>
    <Assigned_Track>AI Architects (L1)</Assigned_Track>
    <Room>SOMA: AI Architects</Room>
    <Scheduled_At>4 Jun 2025 02:00 PM</Scheduled_At>
    <Speakers>Nathan Wan</Speakers>
    <Companies>Ensemble Health Partners</Companies>
    
    
</120>
<121>
    <Session_ID>923914</Session_ID>
    <Title>Tiny Teams</Title>
    <Description>Sean reached out on X, happy to do a talk on how to build a tiny team</Description>
    <Session_Format>Talk</Session_Format>
    <Level>Introductory and overview</Level>
    <Scope>Introductory (landscape)</Scope>
    <Assigned_Track>Tiny Teams (01)</Assigned_Track>
    <Room>Yerba Buena Ballroom Salons 2-6: Tiny Teams</Room>
    <Scheduled_At>4 Jun 2025 02:00 PM</Scheduled_At>
    <Speakers>Grant Lee</Speakers>
    <Companies>Gamma</Companies>
    
    
</121>
<122>
    <Session_ID>928676</Session_ID>
    <Title>[Infra Keynote] Geopolitics of AI Infrastructure</Title>
    <Description>As AI reshapes the global balance of power, the infrastructure behind it—chips, data centers, power, and supply chains—has become a new arena for geopolitical competition. This talk explores how nations are racing to secure critical AI hardware, control compute capacity, and assert influence over the technologies and talent that define the future.</Description>
    <Session_Format>Talk</Session_Format>
    <Level>Advanced</Level>
    <Scope>Technical deep dive</Scope>
    <Assigned_Track>AI Infrastructure (05)</Assigned_Track>
    <Room>Foothill F: Infrastructure</Room>
    <Scheduled_At>4 Jun 2025 02:00 PM</Scheduled_At>
    <Speakers>Dylan Patel</Speakers>
    <Companies>SemiAnalysis</Companies>
    
    
</122>
<123>
    <Session_ID>932429</Session_ID>
    <Title>Building an Agentic Platform</Title>
    <Description>Explore the technical evolution of metadata extraction at Box and how it shaped the foundation of our AI platform. We’ll walk through our transition to an agentic-first design—why it was necessary, how we approached the rebuild, challenges we encountered along the way, and the advantages it unlocked.</Description>
    <Session_Format>Talk</Session_Format>
    <Level>Intermediate</Level>
    <Scope>Case Study/War Story</Scope>
    <Assigned_Track>AI in the Fortune 500 (L2)</Assigned_Track>
    <Room>Golden Gate Ballroom C: AI in the Fortune 500</Room>
    <Scheduled_At>4 Jun 2025 02:00 PM</Scheduled_At>
    <Speakers>Ben Kus</Speakers>
    <Companies>Box</Companies>
    
    
</123>
<124>
    <Session_ID>932583</Session_ID>
    <Title>One model to rule recommendations: Netflix's Big Bet</Title>
    <Description>Discuss the foundation model strategy for personalization at Netflix based on this post https://netflixtechblog.com/foundation-model-for-personalized-recommendation-1a0bd8e02d39 and recent developments. </Description>
    <Session_Format>Talk</Session_Format>
    <Level>Expert</Level>
    <Scope>Technical deep dive</Scope>
    <Assigned_Track></Assigned_Track>
    <Room>Golden Gate Ballroom A: LLM RecSys</Room>
    <Scheduled_At>4 Jun 2025 02:00 PM</Scheduled_At>
    <Speakers>Yesu Feng</Speakers>
    <Companies>Netflix</Companies>
    
    
</124>
<125>
    <Session_ID>904822</Session_ID>
    <Title>Structuring a modern AI team</Title>
    <Description>You've been given an AI mandate but don't have additional headcount, what next? Re-skilling, up-skilling and team augmentation become essential to delivering on a new mandate. In this talk we'll cover strategies to structure cross functional AI teams with domain experts, software engineers and ML engineers. We'll cover key skills and milestones that each traditional role can contribute to in unique ways.</Description>
    <Session_Format>Talk</Session_Format>
    <Level>Introductory and overview</Level>
    <Scope>Introductory (landscape)</Scope>
    <Assigned_Track>AI Architects (L1)</Assigned_Track>
    <Room>SOMA: AI Architects</Room>
    <Scheduled_At>4 Jun 2025 02:20 PM</Scheduled_At>
    <Speakers>Denys Linkov</Speakers>
    <Companies>Wisedocs</Companies>
    
    
</125>
<126>
    <Session_ID>914015</Session_ID>
    <Title>Agents vs Workflows: Why Not Both?</Title>
    <Description>One current hot debate is should you make your top-level abstraction a ReAct type agent running in a loop? or should you make it a structured workflow graph?

OpenAI is launching their new framework and throwing shade on workflow graph approaches

TBH we think this whole debate is kinda dumb. 

We've seen a lot of folks be able to structure the problem in a way that a workflow graph makes a lot of sense. 

We also see a ton of agents where you need to run the core bit in a loop for a long time.

You can also give your agents structured workflow graphs as a tool. You can use structured workflow graphs as a handoff mechanism between agents. What we've seen from the community is frankly that folks need to tinker with multiple approaches and combine primitives in interesting ways

We'll share a couple stories where teams ended up with workflow graph based approaches, a couple where teams ended up with agent based approaches, and a couple where a blended approach made sense.</Description>
    <Session_Format>Talk</Session_Format>
    <Level>Intermediate</Level>
    <Scope>Case Study/War Story</Scope>
    <Assigned_Track>Agent Reliability (04)</Assigned_Track>
    <Room>Foothill C: Agent Reliability</Room>
    <Scheduled_At>4 Jun 2025 02:20 PM</Scheduled_At>
    <Speakers>Sam Bhagwat</Speakers>
    <Companies>Mastra</Companies>
    
    
</126>
<127>
    <Session_ID>914890</Session_ID>
    <Title>The Billable Hour is Dead; Long Live the Billable Hour?</Title>
    <Description>If software was eating the world before, knowledge work will soon be devoured by AI. In corporate America there are thousands of hours spent on rote tasks every day by employees, consultants, and lawyers alike. But is AI really capable of replacing work in the real world yet? 
Productivity estimates from GenAI range from 1.5% (NBER) to 96% (☝ us! ️). In this talk we'll share war stories of where the answer is yes (and no) and how we reduced human time spent on tasks from days to minutes in high-impact situations. 
The path from promise to actual product, used in real world settings, from our experience, is still unmapped. Learn what we built, how we built it - with code - and how we got stakeholder buy-in to deploy it.</Description>
    <Session_Format>Talk</Session_Format>
    <Level>Advanced</Level>
    <Scope>Case Study/War Story</Scope>
    <Assigned_Track>AI in the Fortune 500 (L2)</Assigned_Track>
    <Room>Golden Gate Ballroom C: AI in the Fortune 500</Room>
    <Scheduled_At>4 Jun 2025 02:20 PM</Scheduled_At>
    <Speakers>Kevin Madura, Mo Bhasin</Speakers>
    <Companies>AlixPartners, unknown</Companies>
    
    
</127>
<128>
    <Session_ID>915013</Session_ID>
    <Title>Observable tools - the state of MCP observability</Title>
    <Description>AI Engineers deserve observable tools! 

MCP getting adoption means that less and less of your agents code is running under your control, and this has DX and observability challenges, let's fix that! 

Join Alex Volkov from Weights & Biases and Steve Manual from mcp.run on this recap of the current state of MCP observability, including the observable.tools initiative, a recap of where the field stands and what to look forward to + a practical example of MCP tool usage evaluation framework from mcp.run! </Description>
    <Session_Format>Talk</Session_Format>
    <Level>Expert</Level>
    <Scope>Technical deep dive</Scope>
    <Assigned_Track>MCP (02)</Assigned_Track>
    <Room>Yerba Buena Ballroom Salons 7-8: MCP</Room>
    <Scheduled_At>4 Jun 2025 02:20 PM</Scheduled_At>
    <Speakers>Alex Volkov, Steve Manuel, Benjamin Eckel</Speakers>
    <Companies>Weights & Biases, Dylibso, Dylibso</Companies>
    
    
</128>
<129>
    <Session_ID>915471</Session_ID>
    <Title>Hacking the Inference Pareto Frontier for Cheaper and Faster Tokens Without Breaking SLAs</Title>
    <Description>Your model works! It aces the evals! It even passes the vibe check! All that’s required is inference, right? Oops, you’ve just stepped into a minefield:

-Not low-latency enough? Choppy experience. Users churn from your app. 
-Not cheap enough? You’re losing money on every query.
-Not high enough output quality? Your system can’t be used for that application.

A model and the inference system around it form a “token factory” associated with a Pareto frontier— a curve representing the best possible trade-offs between cost, throughput, latency and quality, outside of which your LLM system cannot be applied successfully. 

Outside of the Pareto frontier? You’re back to square one.
That is, unless you’re able to change the shape of the Pareto frontier.

In this session, we’ll introduce NVIDIA Dynamo, a datacenter-scale distributed inference framework as well as the bleeding-edge techniques it enables to hack the Pareto frontier of your inference systems, including:

-Disaggregation - separating phases of LLM generation to make them more efficient
-Speculation - predicting multiple tokens per cycle
-KV routing, storage, and manipulation - ensuring that we don’t redo work that has already been done
-Pipelining improvements for agents - accelerating our workflows using information about the agent

By the end of the talk, we’ll understand how the Pareto frontier limits where models can be applied, the intuition behind how inference techniques can be used to modify it, as well as the mechanics of how these techniques work.
</Description>
    <Session_Format>Talk</Session_Format>
    <Level>Intermediate</Level>
    <Scope>Introductory (landscape)</Scope>
    <Assigned_Track>AI Infrastructure (05)</Assigned_Track>
    <Room>Foothill F: Infrastructure</Room>
    <Scheduled_At>4 Jun 2025 02:20 PM</Scheduled_At>
    <Speakers>Kyle Kranen US</Speakers>
    <Companies>NVIDIA</Companies>
    
    
</129>
<130>
    <Session_ID>915738</Session_ID>
    <Title>Make your LLM app a Domain Expert: How to Build an LLM-Native Expert System</Title>
    <Description>Vertical AI is a multi-trillion-dollar opportunity. But you can't build a domain-expert application simply by grabbing the latest LLMs off-the-shelf: you need a system for codifying latent insights from domain experts and using that to drive development of your application.

In this talk, we'll describe the system we've built at Anterior which has enabled us to achieve SOTA clinical reasoning and serve health insurance providers covering 50 million American lives. We'll share:
- how and why to encode domain-specific failure modes as an ontology
- a practical system for converting domain expertise into quantifiable eval metrics
- how we structure work and collaboration between our clinicians, engineer and PMs
- our eval-driven AI iteration process and how this can be adapted to any industry</Description>
    <Session_Format>Talk</Session_Format>
    <Level>Intermediate</Level>
    <Scope>Technical deep dive</Scope>
    <Assigned_Track>Product Management (06)</Assigned_Track>
    <Room>Foothill G 1&2: Product Management</Room>
    <Scheduled_At>4 Jun 2025 02:20 PM</Scheduled_At>
    <Speakers>Christopher Lovejoy</Speakers>
    <Companies>Anterior </Companies>
    
    
</130>
<131>
    <Session_ID>916063</Session_ID>
    <Title>Multi-Agent AI and Network Knowledge Graphs for Change Management and Network Testing</Title>
    <Description>Traditional ticketing and testing workflows for change management and network operations often operate independently and lack critical real-world context and adaptive decision making capabilities. This fragmented approach results in delayed resolutions, repeated incidents, escalations, and dissatisfied stakeholders.

This session explores an innovative solution leveraging the synergy of natural language processing from IT Service Management (ITSM) systems, Multi-agent reasoning, and dynamic context derived from live knowledge network graphs. Attendees will gain insights into an end-to-end architecture where natural language intents from ITSM tickets seamlessly integrate with experts AI agents for complex workflow tasks, supported by continuous network knowledge graph ingestion pipelines.

Through a detailed production case study, we will demonstrate how Agentic reasoning combined with dynamic network knowledge graph contexts significantly improves critical validation and workflow interactions. The showcased results will highlight dramatic improvements in ticket resolution efficiency, accuracy of network testing, and overall execution quality, delivering tangible value to both technical teams and business stakeholders.</Description>
    <Session_Format>Talk</Session_Format>
    <Level>Advanced</Level>
    <Scope>Technical deep dive</Scope>
    <Assigned_Track>GraphRAG (08)</Assigned_Track>
    <Room>Golden Gate Ballroom B: GraphRAG</Room>
    <Scheduled_At>4 Jun 2025 02:20 PM</Scheduled_At>
    <Speakers>Ola  Mabadeje</Speakers>
    <Companies>Cisco</Companies>
    
    
</131>
<132>
    <Session_ID>929231</Session_ID>
    <Title>Instacart’s LLM-driven approach to Search and Discovery</Title>
    <Description></Description>
    <Session_Format>Talk</Session_Format>
    <Level>Intermediate</Level>
    <Scope>Technical deep dive</Scope>
    <Assigned_Track>LLM RecSys (03)</Assigned_Track>
    <Room>Golden Gate Ballroom A: LLM RecSys</Room>
    <Scheduled_At>4 Jun 2025 02:20 PM</Scheduled_At>
    <Speakers>Tejaswi Tenneti, Vinesh Gudla</Speakers>
    <Companies>Instacart, Instacart</Companies>
    
    
</132>
<133>
    <Session_ID>932493</Session_ID>
    <Title>Why ChatGPT Keeps Interrupting You</Title>
    <Description>ChatGPT Advanced Voice Mode isn’t interrupting just you. Interruptions, and turn-taking in general, are unsolved problems for all Voice AI agents. Nobody likes being cut short – and people have much less patience for machines than they do for other humans. Turn-taking failures take many forms (e.g., the agent interrupts the user, the agent mistakes a cough for an interruption), and all of them lead to users immediately hanging up the phone.

In this talk, we use human conversation as a framework for understanding both today’s approaches to turn detection and where the field is headed. You’ll learn about how linguists think about turn detection in human dialogue, what’s working (and what’s broken) in current methods, and how we might build Voice AIs that interrupt you less than your human brother. </Description>
    <Session_Format>Talk</Session_Format>
    <Level>Introductory and overview</Level>
    <Scope>Introductory (landscape)</Scope>
    <Assigned_Track>Voice (07)</Assigned_Track>
    <Room>Foothill E: Voice</Room>
    <Scheduled_At>4 Jun 2025 02:20 PM</Scheduled_At>
    <Speakers>Tom Shapland, PhD</Speakers>
    <Companies>LiveKit</Companies>
    
    
</133>
<134>
    <Session_ID>939097</Session_ID>
    <Title>Building Small AI Teams with Huge Impact</Title>
    <Description>tbd</Description>
    <Session_Format>Talk</Session_Format>
    <Level></Level>
    <Scope></Scope>
    <Assigned_Track>Tiny Teams (01)</Assigned_Track>
    <Room>Yerba Buena Ballroom Salons 2-6: Tiny Teams</Room>
    <Scheduled_At>4 Jun 2025 02:20 PM</Scheduled_At>
    <Speakers>Vikas Paruchuri</Speakers>
    <Companies>Datalab</Companies>
    
    
</134>
<135>
    <Session_ID>900332</Session_ID>
    <Title>Beyond Documents: Implementing Knowledge Graphs in Legal Agents</Title>
    <Description>Structured Representations are pretty important in the law, where the relationships between clauses, documents, entities, and multiple parties matter. Structured Representation means Structured Context Injection. Better Context, Less Hallucinations. We walk through a couple of case studies of systems that we’ve built in production for legal use-cases - from recursive contractual clause retrieval, to HITL legal reasoning news agents.

You'll gain insights into how structured representations significantly improve the effectiveness and reliability of legal agents.
</Description>
    <Session_Format></Session_Format>
    <Level>Intermediate</Level>
    <Scope></Scope>
    <Assigned_Track>GraphRAG (08)</Assigned_Track>
    <Room>Golden Gate Ballroom B: GraphRAG</Room>
    <Scheduled_At>4 Jun 2025 02:40 PM</Scheduled_At>
    <Speakers>Tom Smoker</Speakers>
    <Companies>WhyHow.AI</Companies>
    
    
</135>
<136>
    <Session_ID>906567</Session_ID>
    <Title>Teaching Gemini to Speak YouTube: Adapting LLMs for Video Recommendations to 2B+ DAU</Title>
    <Description>YouTube recommendations drive nearly two-thirds of the platform's staggering 5 billion daily watch hours for 2 billion+ DAU. Traditionally powered by large embedding models (LEMs), we're undertaking a fundamental shift: rebuilding our recommendation stack using foundation models like Gemini. This talk dives into our engineering journey adapting general-purpose LLMs (Gemini) for the highly specialized, dynamic, and massive-scale task of YouTube recommendations.

We'll start with a critical first step: creating a "language" for YouTube videos. Learn how we developed 'SemanticID', a novel tokenization scheme that distills multimodal video features (text, audio, frames) into discrete tokens representable by an LLM. Our paper (Better Generalization with Semantic IDs: A Case Study in Ranking for Recommendations) is a landmark work in this space.  

We then adapt the base Gemini checkpoint to understand sequences of these video tokens alongside natural language, effectively teaching it the grammar of user watch behavior. A key insight: unlike static LLM training, YouTube's corpus evolves so rapidly (millions of new videos daily) that daily retraining is non-negotiable to maintain recommendation quality.

Now we can prompt LRM with user history and context to generate personalized candidate recommendations, achieving the biggest engagement wins on YouTube in the last ~decade. 

There’s a lot of attention on the LLM-led transformation of Search (with AI Overviews, Perplexity, ChatGPT-Search etc). However, across large consumer apps, it’s the recommendation systems & feeds that drive most consumer engagement, not just search (eg. YouTube recs drive 67% of WatchTime). This talk is about the LLM-led transformation of recommendations & feeds – building a recommendation engine on top of Gemini.
</Description>
    <Session_Format>Talk</Session_Format>
    <Level>Advanced</Level>
    <Scope>Technical deep dive</Scope>
    <Assigned_Track>LLM RecSys (03)</Assigned_Track>
    <Room>Golden Gate Ballroom A: LLM RecSys</Room>
    <Scheduled_At>4 Jun 2025 02:40 PM</Scheduled_At>
    <Speakers>Devansh Tandon</Speakers>
    <Companies>Google</Companies>
    
    
</136>
<137>
    <Session_ID>912986</Session_ID>
    <Title>Flipping the Inference Stack: Why GPUs Bottleneck Real-Time AI at Scale</Title>
    <Description>AI inference today is stuck in a loop: throw more GPUs at the problem, scale horizontally, rinse and repeat. But that playbook is hitting a wall. Latency, cost, and energy grids are all suffering, and the capability for real-time AI at scale looks further and further away. In this talk, AI hardware expert and founder Gavin Uberti will break down why the current approach to inference is masking deep inefficiencies, and how rethinking the hardware stack from the ground up (starting with inference-first chips) is the only way to unlock real-time AI at scale. </Description>
    <Session_Format>Talk</Session_Format>
    <Level>Intermediate</Level>
    <Scope>Technical deep dive</Scope>
    <Assigned_Track>AI Infrastructure (05)</Assigned_Track>
    <Room>Foothill F: Infrastructure</Room>
    <Scheduled_At>4 Jun 2025 02:40 PM</Scheduled_At>
    <Speakers>Robert  Wachen</Speakers>
    
    
    
</137>
<138>
    <Session_ID>915067</Session_ID>
    <Title>Building Effective Voice Agents</Title>
    <Description>How to build production voice applications and learnings from working with customers along the way</Description>
    <Session_Format>Talk</Session_Format>
    <Level>Intermediate</Level>
    <Scope>Technical deep dive</Scope>
    <Assigned_Track>AI Architects (L1)</Assigned_Track>
    <Room>SOMA: AI Architects</Room>
    <Scheduled_At>4 Jun 2025 02:40 PM</Scheduled_At>
    <Speakers>Anoop Kotha</Speakers>
    <Companies>OpenAI</Companies>
    
    
</138>
<139>
    <Session_ID>915770</Session_ID>
    <Title>From Hunch to Handoff: How AI PMs Can Help Turn Ideas Into Shippable Features Quickly</Title>
    <Description>"We should add AI to this!" Great, but how do you know if your idea will actually work? The gap between AI concept and engineering reality is where most promising features die.
In this talk, we will reveal a rapid validation framework developed through working with dozens of product teams—including within Workday's AI product efforts. We'll share a three-step process that starts with lightweight prototyping, builds a relevant evaluation suite, and creates the right artifacts for successful engineering handoffs. You'll see how leading teams use this approach to explore what's possible, establish practical quality benchmarks, and align cross-functional stakeholders before writing a single line of production code.
Eliza Cabrera (Principal PM, Workday) and Jeremy Silva (Product Lead, Freeplay) will share the playbook they use to turn “we should add AI here” hunches into AI features customers actually use and trust.
Attendees will leave with a field‑tested framework, real examples from enterprise teams, and ready‑to‑use templates that let AI PMs guide ideas from first spark to successful release—cheaply, quickly, and with confidence.
</Description>
    <Session_Format>Talk</Session_Format>
    <Level>Intermediate</Level>
    <Scope>Case Study/War Story</Scope>
    <Assigned_Track>AI in the Fortune 500 (L2)</Assigned_Track>
    <Room>Golden Gate Ballroom C: AI in the Fortune 500</Room>
    <Scheduled_At>4 Jun 2025 02:40 PM</Scheduled_At>
    <Speakers>Jeremy Silva, Eliza Cabrera</Speakers>
    <Companies>Freeplay, Workday</Companies>
    
    
</139>
<140>
    <Session_ID>915974</Session_ID>
    <Title>Benchmarks Are Memes: How What We Measure Shapes AI—and Us</Title>
    <Description>Benchmarks shape more than just AI models—they shape our future. The things we choose to measure become self-fulfilling prophecies, guiding AI toward specific abilities and, ultimately, defining humanity’s evolving role in the AI era. Today’s benchmarks have propelled incredible progress, but now we have an exciting opportunity: thoughtfully designing benchmarks around what genuinely matters to us—cooperation, creativity, education, and meaningful human experiences.

In this talk, we’ll explore how benchmarks function as powerful cultural memes, influencing not only technical outcomes but societal direction. Drawing on practical examples we have seen at Every consulting in industries like finance, journalism, education, and even personally making AI play diplomacy. We’ll uncover what makes a benchmark impactful, approachable, and inspiring. You’ll see our engaging new AI Diplomacy benchmark demo, illustrating vividly how thoughtful evaluation design can excite both engineers and the wider community.

You’ll hopefully walk away inspired and equipped to define benchmarks intentionally, helping steer AI toward outcomes that truly matter.</Description>
    <Session_Format>Talk</Session_Format>
    <Level>Intermediate</Level>
    <Scope>Case Study/War Story</Scope>
    <Assigned_Track>AI Architects (L1)</Assigned_Track>
    <Room>Yerba Buena Ballroom Salons 2-6: Tiny Teams</Room>
    <Scheduled_At>4 Jun 2025 02:40 PM</Scheduled_At>
    <Speakers>Alex Duffy</Speakers>
    <Companies>Every Inc.</Companies>
    
    
</140>
<141>
    <Session_ID>916115</Session_ID>
    <Title>Vibe Coding, with Confidence</Title>
    <Description>Everyone wants to do Vibe Code, even large Enterprises. But how can we ensure that the generated code is well-grounded with the dev team's code and software development standards? In this talk, Itamar will present how to use various tools and agents, including MCP and A2A, to achieve precisely that.</Description>
    <Session_Format>Talk</Session_Format>
    <Level>Advanced</Level>
    <Scope>Product launch</Scope>
    <Assigned_Track>Agent Reliability (04)</Assigned_Track>
    <Room>Foothill C: Agent Reliability</Room>
    <Scheduled_At>4 Jun 2025 02:40 PM</Scheduled_At>
    <Speakers>Itamar Friedman</Speakers>
    <Companies>Qodo</Companies>
    
    
</141>
<142>
    <Session_ID>926313</Session_ID>
    <Title>The rise of the agentic economy on the shoulders of MCP</Title>
    <Description>Thanks to MCP and all the MCP server directories, agents can now autonomously discover new tools and other agents. This lays down the foundation for the future agentic economy, where businesses will sell to autonomous agents (B2A) and eventually agents will sell to other agents (A2A).

But one key part is still missing: agents do not have a standard way to subscribe to external services and pay for them.

In this talk, we’ll show how to give agents full autonomy to discover and pay for new external MCP-enabled services, even if those services don’t support it, using a little-known MCP server nesting capability. We’ll also cover how to monetize AI agents and the B2A/A2A business models.
</Description>
    <Session_Format>Talk</Session_Format>
    <Level>Introductory and overview</Level>
    <Scope>Introductory (landscape)</Scope>
    <Assigned_Track>MCP (02)</Assigned_Track>
    <Room>Yerba Buena Ballroom Salons 7-8: MCP</Room>
    <Scheduled_At>4 Jun 2025 02:40 PM</Scheduled_At>
    <Speakers>Jan Curn</Speakers>
    <Companies>Apify</Companies>
    
    
</142>
<143>
    <Session_ID>933596</Session_ID>
    <Title>Milliseconds to Magic: Real‑Time Workflows using the Gemini Live API and Pipecat</Title>
    <Description>The Gemini Live API GA  is now powered by Google's best cost-effective thinking model Gemini 2.5 Flash. We will do a deep dive on the capabilities that the Gemini Live API combined with Pipecat unlock for devs with special focus on session management, turn detection, tool use (including async function calls), proactivity, multilinguality and integration with telephony and other infra. We will demo some of the more innovative capabilities. We will also talk through some customer use cases - especially how customers can use Pipecat to extend these realtime multimodal capabilities to client side applications such as customer support agents, gaming agents, tutoring agents etc. In addition, we also have an experimental version of the Live API powered by with Google's native audio offering that can be tried in an experimental capacity . This experimental model  can communicate with seamless, emotive, steerable, multilingual dialogue and enhances use cases where more natural voices can be a big differentiator. </Description>
    <Session_Format>Talk</Session_Format>
    <Level>Advanced</Level>
    <Scope>Technical deep dive</Scope>
    <Assigned_Track></Assigned_Track>
    <Room>Foothill E: Voice</Room>
    <Scheduled_At>4 Jun 2025 02:40 PM</Scheduled_At>
    <Speakers>Kwindla Kramer, Shrestha Basu Mallick</Speakers>
    <Companies>Daily, unknown</Companies>
    
    
</143>
<144>
    <Session_ID>940848</Session_ID>
    <Title>Building the platform for agent coordination</Title>
    <Description>Learn how we're evolving Linear into an operating system for engineering teams to ship product with agents as a first class citizen.</Description>
    <Session_Format>Talk</Session_Format>
    <Level>Introductory and overview</Level>
    <Scope>Product launch</Scope>
    <Assigned_Track>Product Management (06)</Assigned_Track>
    <Room>Foothill G 1&2: Product Management</Room>
    <Scheduled_At>4 Jun 2025 02:40 PM</Scheduled_At>
    <Speakers>Tom Moor</Speakers>
    <Companies>Linear</Companies>
    
    
</144>
<145>
    <Session_ID>933625</Session_ID>
    <Title>Vector Search Benchmark[eting]</Title>
    <Description>Every vector database out there is both faster and slower than any other competitor — if you believe all the benchmarketing out there.
Let's turn the marketing into useful benchmarks that actually help you:
1. How not to benchmark (spoiler: don’t trust the glossy charts).
2. What’s uniquely tricky about benchmarking vector search.
3. How to build meaningful benchmarks tailored to your use case.

PS: Yes, you will have to get your hands dirty. Never believe a benchmark that you haven't tweaked yourself.</Description>
    <Session_Format></Session_Format>
    <Level>Advanced</Level>
    <Scope>Technical deep dive</Scope>
    <Assigned_Track></Assigned_Track>
    <Room>Willow: Expo Sessions</Room>
    <Scheduled_At>4 Jun 2025 03:15 PM</Scheduled_At>
    <Speakers>Philipp Krenn</Speakers>
    
    
    
</145>
<146>
    <Session_ID>936894</Session_ID>
    <Title>Taming Rogue AI Agents with Observability-Driven Evaluation</Title>
    <Description>LLM agents often drift into failure when prompts, retrieval, external data, and policies interact in unpredictable ways. This session introduces a repeatable, metric-driven framework for detecting, diagnosing, and correcting these undesirable behaviors in agentic systems at production scale.</Description>
    <Session_Format>Talk</Session_Format>
    <Level>Intermediate</Level>
    <Scope>Technical deep dive</Scope>
    <Assigned_Track></Assigned_Track>
    <Room>Nobhill A&B: Expo Sessions</Room>
    <Scheduled_At>4 Jun 2025 03:15 PM</Scheduled_At>
    <Speakers>Jim Bennett</Speakers>
    <Companies>Galileo</Companies>
    
    
</146>
<147>
    <Session_ID>936906</Session_ID>
    <Title>GraphRAG methods to create optimized LLM context windows for retrieval</Title>
    <Description></Description>
    <Session_Format>Talk</Session_Format>
    <Level></Level>
    <Scope></Scope>
    <Assigned_Track></Assigned_Track>
    <Room>Juniper: Expo Sessions</Room>
    <Scheduled_At>4 Jun 2025 03:15 PM</Scheduled_At>
    <Speakers>Jonathan Larson</Speakers>
    <Companies>Microsoft</Companies>
    
    
</147>
<148>
    <Session_ID>933605</Session_ID>
    <Title>Data is Your Differentiator: Building Secure and Tailored AI Systems</Title>
    <Description>As  organizations seek to harness their proprietary data while maintaining  security and compliance, Amazon Bedrock provides a comprehensive framework  for building tailored AI applications. Using Amazon Bedrock Knowledge Bases  and Amazon Bedrock Data Automation, organizations can create AI solutions  that truly understand their unique business context, terminology, and  requirements. Combined with Amazon Bedrock Guardrails, these capabilities  enhance the accuracy and relevance of AI-generated responses, while ensuring  that sensitive information remains protected within the organization's  control - enabling businesses to build secure and compliant enterprise-grade  generative AI solutions that accelerate time to value.</Description>
    <Session_Format></Session_Format>
    <Level>Advanced</Level>
    <Scope>Technical deep dive</Scope>
    <Assigned_Track></Assigned_Track>
    <Room>Juniper: Expo Sessions</Room>
    <Scheduled_At>4 Jun 2025 03:30 PM</Scheduled_At>
    <Speakers>Mani Khanuja</Speakers>
    <Companies>Amazon Web Services</Companies>
    
    
</148>
<149>
    <Session_ID>936204</Session_ID>
    <Title>Engineering Better Evals: Scalable LLM Evaluation Pipelines That Work</Title>
    <Description>As LLM-powered products become more sophisticated, the need for scalable, reliable evaluation pipelines has never been more critical. This session dives deep into advanced LLM evaluation strategies that move beyond toy benchmarks and toward real-world production impact.

We’ll explore how to architect and implement evaluation pipelines that work across both online and offline environments—reducing dev complexity and accelerating iteration. The session will cover:

- LLM-as-a-judge frameworks
- Human-in-the-loop evaluation
- How hybrid approaches unlock more robust and nuanced performance assessments

We’ll break down technical architectures, share real implementation patterns, and examine trade-offs between evaluation techniques to help engineers make informed choices.
Whether you’re building from scratch or refining existing workflows, this talk offers practical strategies for crafting efficient, scalable, and accurate eval pipelines tailored to custom LLM products.</Description>
    <Session_Format></Session_Format>
    <Level>Advanced</Level>
    <Scope>Technical deep dive</Scope>
    <Assigned_Track></Assigned_Track>
    <Room>Nobhill A&B: Expo Sessions</Room>
    <Scheduled_At>4 Jun 2025 03:30 PM</Scheduled_At>
    <Speakers>Dat Ngo, Aman Khan</Speakers>
    <Companies>unknown, unknown</Companies>
    
    
</149>
<150>
    <Session_ID>937936</Session_ID>
    <Title>Polar Signals Expo Session</Title>
    <Description></Description>
    <Session_Format></Session_Format>
    <Level></Level>
    <Scope></Scope>
    <Assigned_Track></Assigned_Track>
    <Room>Willow: Expo Sessions</Room>
    <Scheduled_At>4 Jun 2025 03:30 PM</Scheduled_At>
    <Speakers>Matthias Loibl</Speakers>
    <Companies>Polar Signals</Companies>
    
    
</150>
<151>
    <Session_ID>933612</Session_ID>
    <Title>Building  Agents at Cloud-Scale</Title>
    <Description>Let's explore  practical strategies for building and scaling agents in production. Discover  how to move from local MCP implementations to cloud-scale architectures and  how engineering teams leverage these patterns to develop sophisticated agent  systems. Expect a mix of demos, use case discussions, and a glimpse into the  future of agentic services!</Description>
    <Session_Format>Keynote</Session_Format>
    <Level>Advanced</Level>
    <Scope>Technical deep dive</Scope>
    <Assigned_Track></Assigned_Track>
    <Room>Keynote/General Session (Yerba Buena 7&8)</Room>
    <Scheduled_At>4 Jun 2025 04:00 PM</Scheduled_At>
    <Speakers>Antje Barth</Speakers>
    <Companies>AWS</Companies>
    
    
</151>
<152>
    <Session_ID>933675</Session_ID>
    <Title>Windsurf everywhere, doing everything, all at once</Title>
    <Description>abstract tbd</Description>
    <Session_Format>Keynote</Session_Format>
    <Level>Intermediate</Level>
    <Scope>Introductory (landscape)</Scope>
    <Assigned_Track></Assigned_Track>
    <Room>Keynote/General Session (Yerba Buena 7&8)</Room>
    <Scheduled_At>4 Jun 2025 04:20 PM</Scheduled_At>
    <Speakers>Kevin Hou</Speakers>
    
    
    
</152>
<153>
    <Session_ID>936006</Session_ID>
    <Title>#define AI Engineer</Title>
    <Description>Greg Brockman's career and advice for AI Engineers</Description>
    <Session_Format>Keynote</Session_Format>
    <Level></Level>
    <Scope></Scope>
    <Assigned_Track></Assigned_Track>
    <Room>Keynote/General Session (Yerba Buena 7&8)</Room>
    <Scheduled_At>4 Jun 2025 04:40 PM</Scheduled_At>
    <Speakers>Greg Brockman, swyx .</Speakers>
    <Companies>unknown, unknown</Companies>
    
    
</153>
<154>
    <Session_ID>946658</Session_ID>
    <Title>Welcome to the Tollbit Afterparty</Title>
    <Description></Description>
    <Session_Format>Misc</Session_Format>
    <Level></Level>
    <Scope></Scope>
    <Assigned_Track></Assigned_Track>
    <Room>Keynote/General Session (Yerba Buena 7&8)</Room>
    <Scheduled_At>4 Jun 2025 05:20 PM</Scheduled_At>
    <Speakers>Ben Dunphy</Speakers>
    
    
    
</154>
<155>
    <Session_ID>935461</Session_ID>
    <Title>A year of Gemini progress + what comes next</Title>
    <Description>Over the last year, Google and Gemini models have shown rapid progress across all dimensions (model, product, etc). Let's highlight all the work that has happened, how we got the worlds best models, and where we are going next (across both the model landscape and out AI products).</Description>
    <Session_Format>Keynote</Session_Format>
    <Level>Introductory and overview</Level>
    <Scope>Case Study/War Story</Scope>
    <Assigned_Track></Assigned_Track>
    <Room>Keynote/General Session (Yerba Buena 7&8)</Room>
    <Scheduled_At>5 Jun 2025 09:05 AM</Scheduled_At>
    <Speakers>Logan Kilpatrick</Speakers>
    <Companies>Google</Companies>
    
    
</155>
<156>
    <Session_ID>936022</Session_ID>
    <Title>Jack Rae Keynote</Title>
    <Description></Description>
    <Session_Format>Keynote</Session_Format>
    <Level></Level>
    <Scope></Scope>
    <Assigned_Track></Assigned_Track>
    <Room>Keynote/General Session (Yerba Buena 7&8)</Room>
    <Scheduled_At>5 Jun 2025 09:25 AM</Scheduled_At>
    <Speakers>Jack Rae</Speakers>
    
    
    
</156>
<157>
    <Session_ID>942167</Session_ID>
    <Title>Why should anyone care about Evals?</Title>
    <Description>An introduction to the evals track </Description>
    <Session_Format></Session_Format>
    <Level>Introductory and overview</Level>
    <Scope>Introductory (landscape)</Scope>
    <Assigned_Track></Assigned_Track>
    <Room>Keynote/General Session (Yerba Buena 7&8)</Room>
    <Scheduled_At>5 Jun 2025 09:45 AM</Scheduled_At>
    <Speakers>Manu Goyal</Speakers>
    <Companies>Braintrust</Companies>
    
    
</157>
<158>
    <Session_ID>916116</Session_ID>
    <Title>Containing Agent Chaos</Title>
    <Description>AI agents promise breakthroughs but often deliver operational chaos. Building reliable, deployable systems with unpredictable LLMs feels like wrestling fog – testing outputs alone is insufficient when the underlying workflow is opaque and flaky. How do we move beyond fragile prototypes?

This talk, from the creator of Docker, argues the solution lies *outside* the model: engineering **reproducible execution workflows** built on rigorous architectural discipline. Learn how **containerization**, applied not just to deployment but to *each individual step* of an agent's workflow, provides the essential **isolation and environmental consistency** needed.

Discover how combining this granular container approach with patterns like immutable state management allows us to **contain agent chaos**, unlock effective testing, simplify debugging, and bring essential control and predictability back to building powerful AI agents you can actually ship with confidence.</Description>
    <Session_Format>Keynote</Session_Format>
    <Level>Advanced</Level>
    <Scope>Technical deep dive</Scope>
    <Assigned_Track></Assigned_Track>
    <Room>Keynote/General Session (Yerba Buena 7&8)</Room>
    <Scheduled_At>5 Jun 2025 09:50 AM</Scheduled_At>
    <Speakers>Solomon Hykes</Speakers>
    <Companies>Dagger</Companies>
    
    
</158>
<159>
    <Session_ID>916189</Session_ID>
    <Title>The infrastructure for the singularity</Title>
    <Description>We're at an inflection point where AI agents are transitioning from experimental tools to practical coworkers. This new world will demand new infrastructure for RL training, test-time scaling, and deployment. This is why Morph Labs developed Infinibranch last year, and we are excited to finally unveil what's next.</Description>
    <Session_Format>Keynote</Session_Format>
    <Level>Intermediate</Level>
    <Scope>Product launch</Scope>
    <Assigned_Track></Assigned_Track>
    <Room>Keynote/General Session (Yerba Buena 7&8)</Room>
    <Scheduled_At>5 Jun 2025 10:10 AM</Scheduled_At>
    <Speakers>Jesse Han</Speakers>
    <Companies>Morph Labs</Companies>
    
    
</159>
<160>
    <Session_ID>933462</Session_ID>
    <Title>The fastest software dev workflow in the world: AI meets stacked diffs</Title>
    <Description>Learn the secrets behind the workflows that engineers at the fastest moving companies in the world are using to build software for billions of users worldwide. This workshop will cover a comprehensive overview of how to leverage generative AI to write code, how to stack and submit these pull requests, and finally how to use AI to review them.</Description>
    <Session_Format>Workshop</Session_Format>
    <Level>Intermediate</Level>
    <Scope>Introductory (landscape)</Scope>
    <Assigned_Track></Assigned_Track>
    <Room>Willow: Expo Sessions</Room>
    <Scheduled_At>5 Jun 2025 10:45 AM</Scheduled_At>
    <Speakers>Kenneth DuMez</Speakers>
    
    
    
</160>
<161>
    <Session_ID>933603</Session_ID>
    <Title>Introducing Strands Agents, an Open Source AI Agents SDK</Title>
    <Description>Building AI agents used to require complex orchestration, extensive scaffolding, and months of tuning. With Strands Agents, an open source SDK from AWS. You can now build, test, and deploy intelligent agents in just a few lines of code. This session introduces the model-driven approach behind Strands, where a model, a prompt, and a set of tools are all you need to create powerful, production-ready agents. Learn how Strands leverages modern foundation models to handle reasoning, tool use, and reflection, reducing development time from months to days.</Description>
    <Session_Format></Session_Format>
    <Level>Advanced</Level>
    <Scope>Technical deep dive</Scope>
    <Assigned_Track></Assigned_Track>
    <Room>Nobhill A&B: Expo Sessions</Room>
    <Scheduled_At>5 Jun 2025 10:45 AM</Scheduled_At>
    <Speakers>Suman Debnath</Speakers>
    <Companies>Amazon Web Services</Companies>
    
    
</161>
<162>
    <Session_ID>933646</Session_ID>
    <Title>Why Your Agent’s Brain Needs a Playbook: Practical Wins from Using Ontologies</Title>
    <Description>You're trying to guide how your agents think and act. Code-orchestrated workflows are too rigid, but LLMs charting their own course feel too chaotic. When you need a middle ground, it’s time to reach for the secret weapon: ontologies. These graph-shaped fragments of actionable knowledge can fill in critical gaps.

In this talk, we’ll explore together how ontologies bring structure, semantics, and sanity to GenAI-powered applications. You’ll learn when they’re useful, how to apply them, and what kinds of problems they help solve. Through practical examples, we’ll show how ontologies (1) guide knowledge graph construction, (2) add a semantic layer for more efficient and accurate retrieval (GraphRAG), and (3) encode domain logic you don’t want to leave up to the LLM.</Description>
    <Session_Format></Session_Format>
    <Level>Introductory and overview</Level>
    <Scope>Technical deep dive</Scope>
    <Assigned_Track></Assigned_Track>
    <Room>Juniper: Expo Sessions</Room>
    <Scheduled_At>5 Jun 2025 10:45 AM</Scheduled_At>
    <Speakers>Jesús Barrasa</Speakers>
    <Companies>Neo4j</Companies>
    
    
</162>
<163>
    <Session_ID>933589</Session_ID>
    <Title>Pipecat Cloud: Enterprise Voice Agents Built On Open Source</Title>
    <Description>Voice AI agents today can conduct natural, human-like conversations and perform a wide variety of tasks: customer support, lead qualification, healthcare patient intake, market research, and more.

Today's best voice agents combine: realtime responsiveness, open-ended conversational intelligence, reliable instruction following, and flexible integration with existing back-end systems.

Learn how to build state of the art voice agents using Pipecat's open source, vendor neutral tooling. You can deploy Pipecat agents to your own infrastructure or to Pipecat Cloud.

Pipecat is used and supported by teams at NVIDIA, AWS, Google DeepMind, OpenAI, and hundreds of other companies.</Description>
    <Session_Format></Session_Format>
    <Level>Intermediate</Level>
    <Scope>Product launch</Scope>
    <Assigned_Track></Assigned_Track>
    <Room>Nobhill A&B: Expo Sessions</Room>
    <Scheduled_At>5 Jun 2025 11:00 AM</Scheduled_At>
    <Speakers>Mark Backman</Speakers>
    <Companies>Daily</Companies>
    
    
</163>
<164>
    <Session_ID>933622</Session_ID>
    <Title>The Build-Operate Divide: Bridging Product Vision and AI Operational Reality</Title>
    <Description>Product leaders see AI possibilities. Operations teams see implementation chaos. That disconnect can kill promising AI features before they ever reach users.

In this session, Chris Hernandez and Jeremy Silva share an integrated framework that bridges product strategy and operational reality. You'll learn how they transformed fragmented AI workflows into a unified approach—from prototyping and prompt testing to human review loops and model benchmarking.

We’ll explore how to build evaluation systems that satisfy both technical and business stakeholders, create effective HITL processes from day one, and use QA as a strategic enabler of generative AI quality. Most importantly, we’ll show how product and operations can move beyond friction—working together to deliver AI features that scale responsibly and ship faster, with confidence.</Description>
    <Session_Format></Session_Format>
    <Level>Intermediate</Level>
    <Scope>Case Study/War Story</Scope>
    <Assigned_Track></Assigned_Track>
    <Room>Willow: Expo Sessions</Room>
    <Scheduled_At>5 Jun 2025 11:00 AM</Scheduled_At>
    <Speakers>Chris Hernandez</Speakers>
    <Companies>Chime</Companies>
    
    
</164>
<165>
    <Session_ID>933689</Session_ID>
    <Title>The State of AI-Powered Search and Retrieval</Title>
    <Description>In this talk, we examine the state-of-the-art in AI-powered search and retrieval. We detail techniques for enhancing performance beyond base embedding models, including hybrid search, reranking strategies, query decomposition and document enrichment, the use of domain-specific and fine-tuned embeddings, custom data processing pipelines (ETL), and contextualized chunking methods.</Description>
    <Session_Format></Session_Format>
    <Level>Advanced</Level>
    <Scope>Technical deep dive</Scope>
    <Assigned_Track></Assigned_Track>
    <Room>Juniper: Expo Sessions</Room>
    <Scheduled_At>5 Jun 2025 11:00 AM</Scheduled_At>
    <Speakers>Frank Liu</Speakers>
    
    
    
</165>
<166>
    <Session_ID>910158</Session_ID>
    <Title>The State of Generative Media Today</Title>
    <Description>Generative AI is reshaping the creative landscape, enabling the production of images, audio, and video with unprecedented speed and sophistication. This session offers an in-depth exploration of the current state of generative media, highlighting cutting-edge models, platforms, and tools that are transforming the industry. </Description>
    <Session_Format>Talk</Session_Format>
    <Level>Introductory and overview</Level>
    <Scope>Technical deep dive</Scope>
    <Assigned_Track>Generative Media (14)</Assigned_Track>
    <Room>Foothill F: Generative Media</Room>
    <Scheduled_At>5 Jun 2025 11:15 AM</Scheduled_At>
    <Speakers>Gorkem Yurtseven</Speakers>
    <Companies>fal</Companies>
    
    
</166>
<167>
    <Session_ID>912033</Session_ID>
    <Title>Monetizing AI: From Zero to Profit</Title>
    <Description>As AI continues to transform industries, companies are faced with the critical challenge of effectively monetizing AI-driven products in a way that captures value, ensures customer adoption, and scales revenue sustainably. Unlike traditional SaaS models, AI-powered products have unique complexities - such as fluctuating usage patterns, variable compute costs, and evolving customer demands, making conventional pricing strategies unhelpful to the growth of an AI product-led startup.

In this session, Alvaro Morales, CEO and co-founder of Orb, will explore why the often overlooked monetization aspect of AI is critical for businesses. He’ll share real-world examples and data to demonstrate how adaptive pricing models can drive cost savings, enhance customer experience, and reduce operational bottlenecks.

Alvaro will lead a live demo, showcasing how engineers can simulate AI pricing strategies and subsequently integrate them with a simple plug-and-play solution. He’ll also share how real-world revenue simulations enable companies to test and refine pricing before implementing — reducing risk, boosting adoption, and unlocking new revenue streams. As a quick example, cloud software development platform Replit was looking to adopt a usage-based pricing model for a new product, but their existing billing system couldn't support the new model, and building a new billing system would delay the launch timeline. In order to get things done, they turned to Orb, which enabled them to make pricing changes up to the last minute. After the launch, Orb became the single source of truth for both Replit and its customers - providing usage alerts to notify Replit when users hit cost thresholds and provide insights into user spend and payment methods.

Key takeaways: 
The challenge of AI monetization – Why traditional subscription-based SaaS pricing models don’t work for AI-powered products.
Precision pricing – Exploring how usage-based, tiered, and hybrid pricing models can maximize revenue potential. 
Revenue simulation for AI pricing – Leveraging real-time data to test, adjust and optimize pricing strategies.
Avoiding common pricing pitfalls – Identifying mistakes that can lead to revenue leakage and customer churn.

This session is designed for AI executives, product leaders, and engineering teams looking for actionable strategies to build adaptive, scalable pricing models that drive long-term growth and profitability.

</Description>
    <Session_Format>Talk</Session_Format>
    <Level>Intermediate</Level>
    <Scope>Introductory (landscape)</Scope>
    <Assigned_Track>AI Architects (L1)</Assigned_Track>
    <Room>SOMA: AI Architects</Room>
    <Scheduled_At>5 Jun 2025 11:15 AM</Scheduled_At>
    <Speakers>Alvaro Morales</Speakers>
    <Companies>Orb</Companies>
    
    
</167>
<168>
    <Session_ID>914027</Session_ID>
    <Title>UX Design Principles for (Semi) Autonomous Multi-Agent Systems</Title>
    <Description>Autonomous or semi-autonomous multi-agent systems (MAS) involve exponentially complex configurations (system config, agent configs, task management and delegation, etc.). These present unique interface design challenges for both developer tooling and end-user experiences.
In this session, I'll explore UX design principles for multi-agent systems, addressing critical questions: What is the true configuration space for autonomous MAS? How can users arrive at the correct mental model of an MAS's capabilities, if at all? How can we improve trust and safety through techniques like cost-aware action delegation? What makes agent actions observable? How do we enable seamless interruptibility? Attendees will gain actionable insights to create more transparent, trustworthy, and user-centered multi-agent applications, illustrated through real-world implementations in AutoGen Studio - a low code developer tool built on AutoGen (44k stars on GitHub, MIT license) and similar tools.</Description>
    <Session_Format>Talk</Session_Format>
    <Level>Intermediate</Level>
    <Scope>Technical deep dive</Scope>
    <Assigned_Track>Design Engineering (10)</Assigned_Track>
    <Room>Foothill G 1&2: Design Engineering</Room>
    <Scheduled_At>5 Jun 2025 11:15 AM</Scheduled_At>
    <Speakers>Victor Dibia</Speakers>
    <Companies>Microsoft Research</Companies>
    
    
</168>
<169>
    <Session_ID>914401</Session_ID>
    <Title>From Hype to Habit: How We’re Building an AI-First SaaS Company—While Still Shipping the Roadmap</Title>
    <Description>What does it really take to move a modern SaaS company from AI experimentation to becoming truly AI-first?

At Sprout Social, we’re in the midst of that transformation—rearchitecting strategy, systems, teams, and incentives to put AI at the heart of how we think, build, and deliver value. This is a story in motion: a behind-the-scenes look at how we’re evolving from isolated AI feature experiments to an AI-native operating model.

I’ll share what we’re learning as we navigate the innovation dilemma—integrating disruptive AI capabilities without breaking what already works or our roadmap. That includes rethinking how we define success, how we hire, reward, grow talent, and how we handle legal and ethical complexity without slowing down. We’ll explore the real-world tensions between rapid innovation, value delivery, making progress on Responsible AI, all while elevating internal AI fluency, and engaging with the broader AI ecosystem to stay at the edge. 

This isn’t a playbook from the finish line—it’s a candid reflection from deep inside the journey.

My goal is to help other leaders chart their own AI path with greater clarity, confidence, and care.</Description>
    <Session_Format>Talk</Session_Format>
    <Level>Advanced</Level>
    <Scope>Introductory (landscape)</Scope>
    <Assigned_Track></Assigned_Track>
    <Room>Golden Gate Ballroom C: AI in the Fortune 500</Room>
    <Scheduled_At>5 Jun 2025 11:15 AM</Scheduled_At>
    <Speakers>Rossella Blatt Vital, Deepsha Menghani</Speakers>
    <Companies>unknown, Sprout Social</Companies>
    
    
</169>
<170>
    <Session_ID>914856</Session_ID>
    <Title>Training Agentic Reasoners</Title>
    <Description>This talk will be a technical deep dive into RL for agentic reasoning via multi-turn tool calling, similar to OpenAI's o3 and Deep Research. In particular, we'll cover:
- When, why, and how
- GRPO vs PPO vs etc
- Designing environments and rewards
- Survey of recent research highlights
- Results on example tasks
- Overview of open-source ecosystem (libraries, compute requirements, tradeoffs, etc.)</Description>
    <Session_Format>Talk</Session_Format>
    <Level>Advanced</Level>
    <Scope>Technical deep dive</Scope>
    <Assigned_Track>Reasoning + RL (15)</Assigned_Track>
    <Room>Yerba Buena Ballroom 2-6: Reasoning + RL</Room>
    <Scheduled_At>5 Jun 2025 11:15 AM</Scheduled_At>
    <Speakers>Will Brown</Speakers>
    <Companies>Prime Intellect</Companies>
    
    
</170>
<171>
    <Session_ID>925259</Session_ID>
    <Title>Building AI Agents that actually automate Knowledge Work</Title>
    <Description>Agents are all the rage in 2025, and every single b2b SaaS startup/incumbent promises AI agents that can "automate work" in some way. 

But how do you actually build this? The answer is two fold: 
1. really really good tools 
2. carefully tailored agent reasoning over these tools that range from assistant-to-automation based UXs.  

The main goal of this talk is to a practical overview of agent architectures that can automate real-world work, with a focus on document-centric tasks. Learn the core building blocks of best-in-class "tools" around processing, manipulating, and indexing/retrieving PDFs to Excel spreadsheets. Also learn the range of agent architectures suited for different tasks, from chat assistant-based UXs with high human-in-the-loop, to automation UXs that rely on encoding a business process into an end-to-end task solver. These architectures have to be generalizable but also highly accurate as agents get increasingly better at reasoning and code-writing. </Description>
    <Session_Format>Talk</Session_Format>
    <Level>Intermediate</Level>
    <Scope>Technical deep dive</Scope>
    <Assigned_Track></Assigned_Track>
    <Room>Golden Gate Ballroom A: Retrieval + Search</Room>
    <Scheduled_At>5 Jun 2025 11:15 AM</Scheduled_At>
    <Speakers>Jerry Liu</Speakers>
    <Companies>LlamaIndex</Companies>
    
    
</171>
<172>
    <Session_ID>929855</Session_ID>
    <Title>Devin 2.0 and the Future of SWE</Title>
    <Description>A talk on the future of software engineering with Scott Wu of Cognition AI, the makers of Devin.</Description>
    <Session_Format>Talk</Session_Format>
    <Level>Advanced</Level>
    <Scope>Technical deep dive</Scope>
    <Assigned_Track></Assigned_Track>
    <Room>Yerba Buena Ballroom 7&8: SWE Agents</Room>
    <Scheduled_At>5 Jun 2025 11:15 AM</Scheduled_At>
    <Speakers>Scott Wu</Speakers>
    <Companies>Cognition AI</Companies>
    
    
</172>
<173>
    <Session_ID>936156</Session_ID>
    <Title>On Engineering AI Systems that Endure The Bitter Lesson</Title>
    <Description>Will discuss the principles for building AI software that underpin DSPy, highlighting the differences between conventional prompting (or finetuning/RL) versus the design and programming of truly modular AI systems.</Description>
    <Session_Format>Talk</Session_Format>
    <Level>Advanced</Level>
    <Scope>Introductory (landscape)</Scope>
    <Assigned_Track></Assigned_Track>
    <Room>Golden Gate Ballroom B: Evals</Room>
    <Scheduled_At>5 Jun 2025 11:15 AM</Scheduled_At>
    <Speakers>Omar Khattab</Speakers>
    <Companies>Databricks</Companies>
    
    
</173>
<174>
    <Session_ID>938258</Session_ID>
    <Title>Robotics: why now?</Title>
    <Description>Sharing recent progress from Physical Intelligence and why it is an exciting time to push the frontier in general purpose robotics</Description>
    <Session_Format>Keynote</Session_Format>
    <Level>Introductory and overview</Level>
    <Scope>Introductory (landscape)</Scope>
    <Assigned_Track></Assigned_Track>
    <Room>Foothill E: Autonomy + Robotics</Room>
    <Scheduled_At>5 Jun 2025 11:15 AM</Scheduled_At>
    <Speakers>Quan Vuong, Jost Tobias Springenberg</Speakers>
    <Companies>Physical Intelligence, Physical Intelligence</Companies>
    
    
</174>
<175>
    <Session_ID>938753</Session_ID>
    <Title>Safety and security for code-executing agents</Title>
    <Description>Code is the lingua franca for both software engineers and highly capable AI models. As we give agents the ability to build, test, and run code that they generate, the command line becomes their canvas—and their attack surface.

This keynote explores what it takes to bring code-executing agents from research to real-world deployment while maintaining control and security. We’ll cover how terminals offer AI an ideal interface, why they’re deceptively risky, and what it means to embed security, guardrails, and trust at every layer.

It’s not just about what agents can do—it’s about what they should do, and how we make sure they do it safely.</Description>
    <Session_Format>Keynote</Session_Format>
    <Level>Introductory and overview</Level>
    <Scope>Technical deep dive</Scope>
    <Assigned_Track></Assigned_Track>
    <Room>Foothill C: Security</Room>
    <Scheduled_At>5 Jun 2025 11:15 AM</Scheduled_At>
    <Speakers>Fouad Matin</Speakers>
    <Companies>OpenAI</Companies>
    
    
</175>
<176>
    <Session_ID>903966</Session_ID>
    <Title>Scaling Enterprise-Grade RAG Systems: Lessons from the Legal Frontier</Title>
    <Description>In domains like law, compliance, and tax, building enterprise-grade RAG means very large scale, spikey workloads, a focus on accuracy, and non-negotiable privacy.
In this talk, we'll share war stories and battle scars of how Harvey has built the world's most advanced AI agents for the legal profession on top of a highly optimized retrieval architecture. We'll cover how to get better retrieval via both sparse and dense retrieval methods, why domain-specific reranking is essential, and how to handle ambiguity in real-world queries.
We'll also touch on how LanceDB's search engine enables this architecture by delivering low-latency, high-throughput retrieval across millions of documents of varying sizes without compromising privacy. This solid foundation enables Harvey to build a product that brings highly accurate answers to hundreds of law firms and professional services firms across 45 countries.</Description>
    <Session_Format>Talk</Session_Format>
    <Level>Intermediate</Level>
    <Scope>Case Study/War Story</Scope>
    <Assigned_Track>Retrieval + Search (09)</Assigned_Track>
    <Room>Golden Gate Ballroom A: Retrieval + Search</Room>
    <Scheduled_At>5 Jun 2025 11:35 AM</Scheduled_At>
    <Speakers>Chang She, Calvin Qi</Speakers>
    <Companies>LanceDB, Harvey AI</Companies>
    
    
</176>
<177>
    <Session_ID>909905</Session_ID>
    <Title>The Unofficial Guide to Apple’s Private Cloud Compute</Title>
    <Description>In October 2024, Apple released a new private AI technology onto millions of devices called “Private Cloud Compute”. It brings the same level of privacy and security a local device offers but on an “untrusted" remote server. This talk discusses how Private Cloud Compute represents a paradigm shift in confidential computing and explores the core advancements that made it possible to become mainstream. We’ll explore its novel architecture that allows developers to run sensitive, multi-tenant workloads with cryptographically-provably privacy guarantees at scale and at reasonable cost. Attendees will leave with an understanding of how to leverage this technology for data and AI applications where privacy and security is paramount.</Description>
    <Session_Format>Talk</Session_Format>
    <Level>Intermediate</Level>
    <Scope>Technical deep dive</Scope>
    <Assigned_Track>Security (13)</Assigned_Track>
    <Room>Foothill C: Security</Room>
    <Scheduled_At>5 Jun 2025 11:35 AM</Scheduled_At>
    <Speakers>Jonathan Mortensen</Speakers>
    <Companies>Confident Security</Companies>
    
    
</177>
<178>
    <Session_ID>914012</Session_ID>
    <Title>Your Coding Agent Just Got Cloned And Your Brain Isn't Ready</Title>
    <Description>Will the future engineer code alongside a single coding agent, or will they spend their day orchestrating many agents? Traditional development rewards synchronous focus. This session dives into the significant mindshift required to move from sequential coding to orchestrating parallel agents. We are the builders of "Jules", Google's massively parallel asynchronous coding agent (to be opened up in May). We'll share real-world insights from building Jules and explore how to rewire your brain for this powerful new "post-IDE" development paradigm.</Description>
    <Session_Format>Talk</Session_Format>
    <Level>Intermediate</Level>
    <Scope>Case Study/War Story</Scope>
    <Assigned_Track>SWE Agents (11)</Assigned_Track>
    <Room>Yerba Buena Ballroom 7&8: SWE Agents</Room>
    <Scheduled_At>5 Jun 2025 11:35 AM</Scheduled_At>
    <Speakers>Rustin Banks</Speakers>
    <Companies>Google Labs</Companies>
    
    
</178>
<179>
    <Session_ID>914786</Session_ID>
    <Title>Measuring AGI: Interactive Reasoning Benchmarks</Title>
    <Description>ARC Prize Foundation is building the North Star for AGI—rigorous, open benchmarks that track reasoning progress in modern AI. We'll show why static AGI evaluations are useful, but fall short when comparing models to human intelligence. Sneak peak preview of ARC-AGI-3: a dynamic, game-like benchmark launching Q1 '26.</Description>
    <Session_Format>Talk</Session_Format>
    <Level>Intermediate</Level>
    <Scope>Introductory (landscape)</Scope>
    <Assigned_Track>Reasoning + RL (15)</Assigned_Track>
    <Room>Yerba Buena Ballroom 2-6: Reasoning + RL</Room>
    <Scheduled_At>5 Jun 2025 11:35 AM</Scheduled_At>
    <Speakers>Greg Kamradt</Speakers>
    <Companies>ARC Prize Foundation</Companies>
    
    
</179>
<180>
    <Session_ID>914845</Session_ID>
    <Title>Good design hasn’t changed with AI</Title>
    <Description>Bad designs are still bad. AI doesn’t make it good. The novelty of AI makes the bad things tolerable, for a short time. Building great designs and experiences with AI have the same first principles pre-AI. When people use software, they want it to feel responsive, safe, accessible and delightful. We’ll go over the big and small details that goes into software that people want to use, not forced to use.</Description>
    <Session_Format>Talk</Session_Format>
    <Level>Introductory and overview</Level>
    <Scope>Introductory (landscape)</Scope>
    <Assigned_Track>Design Engineering (10)</Assigned_Track>
    <Room>Foothill G 1&2: Design Engineering</Room>
    <Scheduled_At>5 Jun 2025 11:35 AM</Scheduled_At>
    <Speakers>John Pham</Speakers>
    <Companies>The San Francisco Compute Company</Companies>
    
    
</180>
<181>
    <Session_ID>914891</Session_ID>
    <Title>Machines of Buying & Selling Grace</Title>
    <Description>How to go beyond browser automation to truly agentic commerce, where AI can buy, sell and negotiate on behalf of users and merchants.</Description>
    <Session_Format>Talk</Session_Format>
    <Level>Intermediate</Level>
    <Scope>Technical deep dive</Scope>
    <Assigned_Track></Assigned_Track>
    <Room>Golden Gate Ballroom C: AI in the Fortune 500</Room>
    <Scheduled_At>5 Jun 2025 11:35 AM</Scheduled_At>
    <Speakers>Adam Behrens</Speakers>
    <Companies>New Generation</Companies>
    
    
</181>
<182>
    <Session_ID>916025</Session_ID>
    <Title>CIOs and Industry Leaders: Do You Trust Your AI’s Inferences?</Title>
    <Description>Enterprise AI adoption is accelerating, but with it comes a hard question: Do we trust the model’s decisions? In this 18-minute talk, I’ll explore the invisible risks behind automated decision-making in safety-critical and revenue-sensitive environments. Drawing on case studies across manufacturing, telecom, and industrial IoT, I’ll highlight how explainability, traceability, and robust guardrails drive adoption and protect enterprise value.
Attendees will walk away with:
• A 3-step framework for operationalizing AI trust
• Real-world lessons from building guardrails in on-prem and hybrid systems
• Tools and techniques for debugging and explaining inferences at scale
• A blueprint for building trust between models, engineers, and executive stakeholders</Description>
    <Session_Format>Talk</Session_Format>
    <Level>Expert</Level>
    <Scope>Case Study/War Story</Scope>
    <Assigned_Track></Assigned_Track>
    <Room>SOMA: AI Architects</Room>
    <Scheduled_At>5 Jun 2025 11:35 AM</Scheduled_At>
    <Speakers>Sahil Yadav, Hariharan Ganesan</Speakers>
    <Companies>AOI, NA</Companies>
    
    
</182>
<183>
    <Session_ID>916140</Session_ID>
    <Title>Real-time Experiments with an AI Co-Scientist</Title>
    <Description>The sheer volume of data and complexity of modern scientific challenges necessitate tools that go beyond mere analysis. The vision of an "AI Co-scientist" – a true collaborative partner in the lab – requires sophisticated engineering to bridge the gap between powerful AI reasoning and the dynamic reality of physical experiments. This talk dives into the engineering required to build robust AI Co-scientists for hands-on research. We will explore scalable architectures, such as multi-agent systems leveraging foundation models like Gemini for complex reasoning, hypothesis refinement (inspired by the "generate, debate, evolve" paradigm described in recent AI Co-scientist research), and intelligent tool use. The core focus will be on the engineering challenges and solutions for integrating diverse, real-time empirical data streams – visual data from cameras, quantitative readings from sensors, positional feedback from actuators, and instrument outputs – directly into the AI's reasoning loop. I will illustrate this with concrete, technically detailed examples in chemistry (adaptive reaction monitoring), robotics (vision-guided assembly with SO Arm 100 and LeRobot library), and synthetic biology (real-time bacterial growth monitoring & interpretation). We'll discuss engineering strategies for handling data heterogeneity, latency, noise, and enabling the AI to interpret, correlate, and act upon live experimental feedback. Finally, we will touch upon how thoughtful engineering of these AI Co-scientists can contribute to democratizing access to advanced scientific capabilities.
</Description>
    <Session_Format>Talk</Session_Format>
    <Level>Intermediate</Level>
    <Scope>Technical deep dive</Scope>
    <Assigned_Track>Autonomy + Robotics (16)</Assigned_Track>
    <Room>Foothill E: Autonomy + Robotics</Room>
    <Scheduled_At>5 Jun 2025 11:35 AM</Scheduled_At>
    <Speakers>Stefania Druga</Speakers>
    
    
    
</183>
<184>
    <Session_ID>936133</Session_ID>
    <Title>Turning Fails into Features: Zapier’s Hard-Won Eval Lessons</Title>
    <Description>Every agent failure can be a roadmap to your next breakthrough. This talk reveals how Zapier's evaluation system transforms frustrating user experiences into targeted improvements, creating a data flywheel that continuously strengthens our agents. You'll learn practical approaches for building the data flywheel, detecting implicit feedback signals, building solid evals, prioritizing metrics that actually matter, and why your most reliable evals might secretly be sabotaging your performance.</Description>
    <Session_Format>Talk</Session_Format>
    <Level>Advanced</Level>
    <Scope>Technical deep dive</Scope>
    <Assigned_Track></Assigned_Track>
    <Room>Golden Gate Ballroom B: Evals</Room>
    <Scheduled_At>5 Jun 2025 11:35 AM</Scheduled_At>
    <Speakers>Rafal Wilinski, Vitor Balocco</Speakers>
    <Companies>Zapier, Zapier</Companies>
    
    
</184>
<185>
    <Session_ID>943701</Session_ID>
    <Title>Veo 3 for developers</Title>
    <Description>This talk will briefly trace the history of video generation models before diving into Veo 3, Google DeepMind's latest state-of-the-art model that marks a significant leap by generating video with synchronized audio—including dialogue, sound effects, and music—all from text and image prompts. We'll show how it can understanding intricate details, maintain coherence over longer sequences, and simulate realistic physics and camera movements.

For developers, Veo 3, accessible via Vertex AI (preview), unlocks many new capabilities. We'll discuss how its advanced capabilities, such as semantic context rendering and cinematic control, can empower innovation in filmmaking, game development, education, and more. This session will cover how developers can integrate Veo 3 into their workflows, or test it out today in the Gemini App, Flow, and via the Gemini APIs on Google Cloud.</Description>
    <Session_Format>Talk</Session_Format>
    <Level>Introductory and overview</Level>
    <Scope>Product launch</Scope>
    <Assigned_Track></Assigned_Track>
    <Room>Foothill F: Generative Media</Room>
    <Scheduled_At>5 Jun 2025 11:35 AM</Scheduled_At>
    <Speakers>Paige Bailey</Speakers>
    <Companies>Google DeepMind</Companies>
    
    
</185>
<186>
    <Session_ID>910197</Session_ID>
    <Title>Magic Editor Under the Hood: Weaving Generative AI into a Billion-User App</Title>
    <Description>Go behind the scenes of Google Photos' Magic Editor. Explore the engineering feats required to integrate complex CV and cutting-edge generative AI models into a seamless mobile experience. We'll discuss optimizing massive models for latency/size, the crucial interplay with graphics rendering (OpenGL/Halide), and the practicalities of turning research concepts into polished features people actually use.</Description>
    <Session_Format>Talk</Session_Format>
    <Level>Intermediate</Level>
    <Scope>Case Study/War Story</Scope>
    <Assigned_Track>Generative Media (14)</Assigned_Track>
    <Room>Foothill F: Generative Media</Room>
    <Scheduled_At>5 Jun 2025 11:55 AM</Scheduled_At>
    <Speakers>Kelvin Ma</Speakers>
    <Companies>Google Photos</Companies>
    
    
</186>
<187>
    <Session_ID>913839</Session_ID>
    <Title>Evaluating AI Search: A Practical Framework for Augmented AI Systems</Title>
    <Description>AI search is becoming the front door to information, whether through Retrieval-Augmented Generation (RAG), Search-Augmented Generation (SAG), or custom agents that synthesize answers on top of indexed content. As users rely more heavily on these systems, evaluating their quality becomes mission-critical. But traditional metrics like precision and recall don’t capture the full picture.

In this talk, we introduce a practical evaluation framework for AI-powered search, across three dimensions:
- Are the retrieved sources relevant to the query?
- And is the final answer complete?
- Are the sources faithfully used in the generated answer?

We’ll share lessons from working with search companies and present early findings from a new benchmark evaluating popular augmented AI systems across these dimensions. Rather than ranking winners and losers, we explore where different systems excel or break down, and how these tradeoffs inform product decisions.

This talk is for AI engineers and product teams who want to build trusted, high-quality AI search experiences, and need a way to measure if it’s actually working.</Description>
    <Session_Format>Talk</Session_Format>
    <Level>Intermediate</Level>
    <Scope>Technical deep dive</Scope>
    <Assigned_Track>Retrieval + Search (09)</Assigned_Track>
    <Room>Golden Gate Ballroom A: Retrieval + Search</Room>
    <Scheduled_At>5 Jun 2025 11:55 AM</Scheduled_At>
    <Speakers>Julia Neagu, Deanna Emery, Maitar Asher</Speakers>
    <Companies>Quotient AI, Quotient AI, Tavily</Companies>
    
    
</187>
<188>
    <Session_ID>914912</Session_ID>
    <Title>Does AI Actually Boost Developer Productivity? (Stanford / 100k Devs Study)</Title>
    <Description>Forget vendor hype: Is AI actually boosting developer productivity, or just shifting bottlenecks? Stop guessing.

Our study at Stanford cuts through the noise, analyzing real-world productivity data from nearly 100,000 developers across hundreds of companies. We reveal the hard numbers: while the average productivity boost is significant (~20%), the reality is complex – some teams even see productivity decrease with AI adoption.

The crucial insights lie in why this variance occurs. Discover which company types, industries, and tech stacks achieve dramatic gains versus minimal impact (or worse). Leave with the objective, data-driven evidence needed to build a winning AI strategy tailored to your context, not just follow the trend.
</Description>
    <Session_Format>Talk</Session_Format>
    <Level>Introductory and overview</Level>
    <Scope>Introductory (landscape)</Scope>
    <Assigned_Track>AI Architects (L1)</Assigned_Track>
    <Room>SOMA: AI Architects</Room>
    <Scheduled_At>5 Jun 2025 11:55 AM</Scheduled_At>
    <Speakers>Yegor Denisov-Blanch</Speakers>
    
    
    
</188>
<189>
    <Session_ID>915428</Session_ID>
    <Title>The Bitter Layout or: How I Learned to Love the Model Picker</Title>
    <Description>Are conversational interfaces the future or, as many designers have suggested, a lazy solution that is bottlenecking AI-HCI? Despite well-documented usability issues, the design of many AI applications defaults to an input field, turn-by-turn flow, and an endless model picker — I call this “The Bitter Layout”. 

In this talk, we’ll explore how Clay Christensen’s theory of commoditization from the early PC industry can explain why scaling laws require AI interfaces to remain modular until models fully commoditize. The killer feature of conversational interfaces may not be that they’re natural, but that they’re conformable. Learn how to evolve interfaces as inference scales, spot shifts in the basis of competition, and stop worrying about the next model update steamrolling your design decisions.</Description>
    <Session_Format>Online Talk</Session_Format>
    <Level>Intermediate</Level>
    <Scope>Technical deep dive</Scope>
    <Assigned_Track>Online</Assigned_Track>
    <Room>Foothill G 1&2: Design Engineering</Room>
    <Scheduled_At>5 Jun 2025 11:55 AM</Scheduled_At>
    <Speakers>Maximillian Piras</Speakers>
    
    
    
</189>
<190>
    <Session_ID>915745</Session_ID>
    <Title>Post-Training Open Models with RL for Autonomous Coding</Title>
    <Description>The models and techniques to build fully autonomous coding agents - not just coding copilots - are already here. In this talk, former Google DeepMind staff research scientist, now CEO of Reflection Misha Laskin will present new research on post-training open weight LLMs for autonomous SWE tasks. He’ll focus on how scaling LLMs with Reinforcement Learning improves the autonomous coding capabilities of LLMs, and provide insight on the technical challenges required to train such systems at scale. </Description>
    <Session_Format>Talk</Session_Format>
    <Level>Advanced</Level>
    <Scope>Technical deep dive</Scope>
    <Assigned_Track>Reasoning + RL (15)</Assigned_Track>
    <Room>Yerba Buena Ballroom 2-6: Reasoning + RL</Room>
    <Scheduled_At>5 Jun 2025 11:55 AM</Scheduled_At>
    <Speakers>Misha  Laskin</Speakers>
    <Companies>Reflection</Companies>
    
    
</190>
<191>
    <Session_ID>915978</Session_ID>
    <Title>Fuzzing in the GenAI Era</Title>
    <Description>"Evaluation" is one of those concepts that every AI practitioner vaguely knows is important, but few practitioners truly understand. Is "eval" the dataset for measuring the quality of your AI system? Is "eval" the measure, the metric of quality? Is "eval" the process of human annotation and scoring? Or is "eval" a third-party dataset run once to benchmark a model?

To mitigate this cacophony, this talk will provide an opinionated and principled perspective for what we actually mean when we say “evaluation”, beyond the traditional for-loop-over-a-static dataset. 

In particular, this perspective draws heavy inspiration from *fuzzing*, i.e. bombarding AI with simulated, unexpected user inputs to uncover corner cases at scale. This factors into sub-problems regarding:

- Quality Metric. What is the actual criteria we, as humans, are using to determine if an AI system is producing good or bad responses? How do we elicit these criteria before the human SME can articulate them? How do we, as efficiently as possible, operationalize this criteria with an automated *Judge*?

- Stimuli Generation. Given a metric, how do we know, with confidence, that an AI system is performing well with respect to the metric? What data is representative and sufficient for discovering all potential bugs of an AI system? And how do we generate this complex, diverse, faithful data at scale? 

We will discuss in detail the philosophy, technology, and case studies behind both problems of Quality Metric and Stimuli Generation, and how they interact in concert.</Description>
    <Session_Format>Talk</Session_Format>
    <Level>Intermediate</Level>
    <Scope>Technical deep dive</Scope>
    <Assigned_Track>Security (13)</Assigned_Track>
    <Room>Foothill C: Security</Room>
    <Scheduled_At>5 Jun 2025 11:55 AM</Scheduled_At>
    <Speakers>Leonard Tang</Speakers>
    <Companies>Haize Labs</Companies>
    
    
</191>
<192>
    <Session_ID>916085</Session_ID>
    <Title>How Intuit uses LLMs to explain taxes to millions of taxpayers</Title>
    <Description>I will talk about how Intuit uses LLMs to explain tax situations to Turbotax users.
Users want explanations of their tax situations - this drives confidence in the product. Over the course of last two tax years, Intuit has built out explanations using Anthropic and openAI’s models to develop genAI powered explanations. This includes design a complex system with prompt engineered solutions and both LLM & human powered evaluations to ensure high quality bar that our users expect when filing taxes with us.
During the course of my talk, I will talk across GenAI development lifecycle at scale - including development , evaluations and scaling. And security evaluations. We also developed a fine-tuned version of Claude Haiku & shall be covering that in the presentation.
We also expanded into tax question and answering powered by RAG, including graphRAG and I would be covering those developments too.</Description>
    <Session_Format>Talk</Session_Format>
    <Level>Intermediate</Level>
    <Scope>Case Study/War Story</Scope>
    <Assigned_Track>AI in the Fortune 500 (L2)</Assigned_Track>
    <Room>Golden Gate Ballroom C: AI in the Fortune 500</Room>
    <Scheduled_At>5 Jun 2025 11:55 AM</Scheduled_At>
    <Speakers>Jaspreet Singh</Speakers>
    
    
    
</192>
<193>
    <Session_ID>916103</Session_ID>
    <Title>What Is a Humanoid Foundation Model? An Introduction to GR00T N1</Title>
    <Description>Foundation models don’t just write or draw anymore—they’re starting to move.

GR00T N1 is NVIDIA’s open Vision-Language-Action (VLA) foundation model for humanoid robots. Built with a dual-system architecture, it combines a System 2 module for high-level reasoning with a System 1 module for real-time, fluid motor control. It’s trained end-to-end on a an impressive mix of data—from human videos to robot trajectories to synthetic simulations—and deployed on a full-sized humanoid robot performing bimanual manipulation tasks in the real world.
This talk is a high-level, beginner-friendly overview of GR00T N1:
- What makes a robot foundation model different from an LLM or vision model
- How GR00T’s architecture is inspired by cognitive systems
- Why grounding language, vision, and action together unlocks new generalist capabilities

If you’ve ever wondered how large-scale AI is crossing over into the physical world, this session will get you up to speed—no robotics PhD required.</Description>
    <Session_Format>Talk</Session_Format>
    <Level>Introductory and overview</Level>
    <Scope>Introductory (landscape)</Scope>
    <Assigned_Track>Autonomy + Robotics (16)</Assigned_Track>
    <Room>Foothill E: Autonomy + Robotics</Room>
    <Scheduled_At>5 Jun 2025 11:55 AM</Scheduled_At>
    <Speakers>Annika Brundyn, Aastha Jhunjhunwala</Speakers>
    <Companies>unknown, unknown</Companies>
    
    
</193>
<194>
    <Session_ID>936814</Session_ID>
    <Title>The Agent Awakens: Collaborative Development with GitHub Copilot</Title>
    <Description></Description>
    <Session_Format>Talk</Session_Format>
    <Level></Level>
    <Scope></Scope>
    <Assigned_Track></Assigned_Track>
    <Room>Yerba Buena Ballroom 7&8: SWE Agents</Room>
    <Scheduled_At>5 Jun 2025 11:55 AM</Scheduled_At>
    <Speakers>Christopher Harrison</Speakers>
    <Companies>GitHub</Companies>
    
    
</194>
<195>
    <Session_ID>939231</Session_ID>
    <Title>Evals Are Not Unit Tests</Title>
    <Description>How to think about evaluating a non-deterministic system — and how to actually succeed at it.</Description>
    <Session_Format>Talk</Session_Format>
    <Level>Introductory and overview</Level>
    <Scope>Introductory (landscape)</Scope>
    <Assigned_Track>Evals (12)</Assigned_Track>
    <Room>Golden Gate Ballroom B: Evals</Room>
    <Scheduled_At>5 Jun 2025 11:55 AM</Scheduled_At>
    <Speakers>Ido Pesok</Speakers>
    <Companies>Vercel</Companies>
    
    
</195>
<196>
    <Session_ID>914361</Session_ID>
    <Title>AI and Game Theory: A Case Study on NYT's Connections</Title>
    <Description>This session will examine the interplay between human intuition and artificial intelligence in puzzle-solving, using the popular New York Times Connections game as a practical case study. 

We'll investigate how gameplay can be systematically evaluated through AI algorithms, exploring machine learning strategies such as clustering, semantic mapping, and natural language processing. 

Attendees will gain insights into building AI-driven puzzle solvers, learn methods for quantitatively assessing gameplay complexity, and discuss the potential impacts of AI on puzzle game design and player engagement.</Description>
    <Session_Format>Talk</Session_Format>
    <Level>Intermediate</Level>
    <Scope>Technical deep dive</Scope>
    <Assigned_Track>Design Engineering (10)</Assigned_Track>
    <Room>Foothill G 1&2: Design Engineering</Room>
    <Scheduled_At>5 Jun 2025 12:15 PM</Scheduled_At>
    <Speakers>Shafik Quoraishee</Speakers>
    <Companies>New York Times</Companies>
    
    
</196>
<197>
    <Session_ID>914814</Session_ID>
    <Title>AX is the only Experience that Matters</Title>
    <Description>If you’re building devtools for humans, you’re building for the past. 

Already a quarter of Y Combinator’s latest batch used AI to write 95% or more of their code. AI agents are scaling at an exponential rate and soon, they’ll outnumber human developers by orders of magnitude.


The real bottleneck isn’t intelligence. It’s tooling. Terminals, local machines, and dashboards weren’t built for agents. They make do… until they can’t.

In this talk, I’ll share how we killed the CLI at Daytona, rebuilt our infrastructure from first principles, and what it takes to build devtools that agents can actually use. Because in an agent-native future, if agents can’t use your tool, no one will.
</Description>
    <Session_Format>Talk</Session_Format>
    <Level>Introductory and overview</Level>
    <Scope>Case Study/War Story</Scope>
    <Assigned_Track>AI Architects (L1)</Assigned_Track>
    <Room>SOMA: AI Architects</Room>
    <Scheduled_At>5 Jun 2025 12:15 PM</Scheduled_At>
    <Speakers>Ivan Burazin</Speakers>
    <Companies>Daytona</Companies>
    
    
</197>
<198>
    <Session_ID>916074</Session_ID>
    <Title>OpenThinker - Unreasonably Effective Reasoning Distillation at Scale</Title>
    <Description>Peel back the curtain on state of the art model post-training through the story of OpenThinker, a SOTA small reasoning model (outperforming DeepSeek distill), built in the open. Learn about the dataset recipe used to build the strongest reasoning models which you can apply to your own domain-specific specialized reasoning models. Hear about the strategies that scale (and that don't) based on our rigorous experimentation on the journey from thousands of data points (Bespoke-Stratos) to millions of data (OpenThinker3). Build upon our open source engineering solutions for large-scale synthetic data generation, training on multiple supercomputing clusters, and building out fast reliable evaluations.</Description>
    <Session_Format>Online Talk</Session_Format>
    <Level>Advanced</Level>
    <Scope>Technical deep dive</Scope>
    <Assigned_Track>Online</Assigned_Track>
    <Room>Yerba Buena Ballroom 2-6: Reasoning + RL</Room>
    <Scheduled_At>5 Jun 2025 12:15 PM</Scheduled_At>
    <Speakers>Ryan Marten</Speakers>
    <Companies>Bespoke Labs</Companies>
    
    
</198>
<199>
    <Session_ID>933458</Session_ID>
    <Title>Don’t get one-shotted: Leveraging AI to test, review, merge, and deploy code</Title>
    <Description>As AI tools like GitHub Copilot and ChatGPT help engineers generate code at an unprecedented rate, the “outer loop”—reviewing, testing, merging, and deploying—becomes more vital than ever. Studies have shown that up to half of AI-generated solutions contain bugs or vulnerabilities, underscoring the continued importance of thorough, human-in-the-loop reviews. In this talk we'll take a look at how next-gen developer tools can harness AI not just for generating code, but also reviewing it. By thoughtfully integrating AI into that fully understands your entire codebase, teams can accelerate velocity without sacrificing quality.

Attendees will learn real-world strategies and best practices for establishing an “outer loop” that safely and efficiently deploys high volumes of AI-assisted code,  without compromising reliability. We’ll also discuss pitfalls to avoid when integrating AI into existing pipelines.</Description>
    <Session_Format>Talk</Session_Format>
    <Level>Introductory and overview</Level>
    <Scope>Introductory (landscape)</Scope>
    <Assigned_Track></Assigned_Track>
    <Room>Yerba Buena Ballroom 7&8: SWE Agents</Room>
    <Scheduled_At>5 Jun 2025 12:15 PM</Scheduled_At>
    <Speakers>Tomas Reimers</Speakers>
    
    
    
</199>
<200>
    <Session_ID>933610</Session_ID>
    <Title>Ship it! Building Production-Ready Agents</Title>
    <Description>Explore the practical challenges and solutions for deploying AI agents in real-world production environments. Through detailed technical analysis and practical examples, we'll examine strategies for building and orchestrating agent systems at scale. We'll cover critical infrastructure decisions, scalability frameworks, and best practices for creating robust, production-ready agent architectures.</Description>
    <Session_Format>Talk</Session_Format>
    <Level>Advanced</Level>
    <Scope>Technical deep dive</Scope>
    <Assigned_Track></Assigned_Track>
    <Room>Golden Gate Ballroom C: AI in the Fortune 500</Room>
    <Scheduled_At>5 Jun 2025 12:15 PM</Scheduled_At>
    <Speakers>Mike Chambers</Speakers>
    <Companies>Amazon Web Services</Companies>
    
    
</200>
<201>
    <Session_ID>933678</Session_ID>
    <Title>RAG in 2025: State of the Art and the Road Forward</Title>
    <Description> The talk will have three parts
1.Roadmap debate: RAG vs. finetuning vs. long-context
2.RAG today: benefits, challenges, and current solutions
3.RAG tomorrow: AI models do more work</Description>
    <Session_Format>Talk</Session_Format>
    <Level>Intermediate</Level>
    <Scope>Introductory (landscape)</Scope>
    <Assigned_Track></Assigned_Track>
    <Room>Golden Gate Ballroom A: Retrieval + Search</Room>
    <Scheduled_At>5 Jun 2025 12:15 PM</Scheduled_At>
    <Speakers>Tengyu Ma</Speakers>
    
    
    
</201>
<202>
    <Session_ID>936795</Session_ID>
    <Title>Securing Agents with Open Standards</Title>
    <Description>Shipping AI agents that are safe for production means solving some tough identity and authorization challenges that are not always obvious at the prototype stage. In practice, this comes down to a handful of deeply technical questions:
- How do you make sure agents are only acting for the right user?
- How do you prevent over-broad API access or data leaks?
- How do you handle user approvals when there is no UI, or you need a human in the loop?
- And how do you avoid the usual pain points like manual credential sharing, stale keys, or unpredictable scopes without writing a lot of brittle, custom code?

This talk digs into the real technical trade-offs behind building secure, user-aware AI agents. We will go beyond what to do and explain why, sharing the architectural decisions, open standards, and hard lessons learned from integrating OAuth, OIDC, RAR, and async authorization into agent-driven workflows.

You will see a hands-on demo using an open-source Node.js agent and open protocols, with a focus on practical integration and no magic. The session will show how these solutions have shaped our approach to identity in GenAI and where we see the field heading next.

If you are an engineer building AI apps that need real guardrails, not just a happy-path demo, we hope to leave you with some practical patterns, design rationale, and a clear view of the trade-offs for making your own agents production ready.</Description>
    <Session_Format>Talk</Session_Format>
    <Level>Intermediate</Level>
    <Scope>Technical deep dive</Scope>
    <Assigned_Track></Assigned_Track>
    <Room>Foothill C: Security</Room>
    <Scheduled_At>5 Jun 2025 12:15 PM</Scheduled_At>
    <Speakers>Bobby Tiernay, Kam Sween</Speakers>
    <Companies>Auth0, Auth0</Companies>
    
    
</202>
<203>
    <Session_ID>943296</Session_ID>
    <Title>Small, sharp tools in the era of generative AI</Title>
    <Description>Replicate makes it easy to run thousands of AI models in the cloud without any machine learning expertise. In this session, we'll show how to make those models available to LLMs as tools that can be combined and chained together, and things start to get really interesting.</Description>
    <Session_Format>Workshop</Session_Format>
    <Level>Intermediate</Level>
    <Scope>Technical deep dive</Scope>
    <Assigned_Track></Assigned_Track>
    <Room>Foothill F: Generative Media</Room>
    <Scheduled_At>5 Jun 2025 12:15 PM</Scheduled_At>
    <Speakers>Zeke Sikelianos</Speakers>
    <Companies>Replicate</Companies>
    
    
</203>
<204>
    <Session_ID>933580</Session_ID>
    <Title>Optimizing inference for voice models in production</Title>
    <Description>How do you get time to first byte (TTFB) below 150 milliseconds for voice models -- and scale it in production? As it turns out, open-source TTS models like Orpheus have an LLM backbone that lets us use familiar tools and optimizations like TensorRT-LLM and FP8 quantization to serve the models with low latency. But client code, network infrastructure, and other outside-the-GPU factors can introduce latency in the production stack. In this talk, we'll cover the basic mechanics of TTS inference, common pitfalls to avoid in integrating them into production systems, and how to extend this high-performance system to serve customized models with voice cloning and fine-tuning.</Description>
    <Session_Format></Session_Format>
    <Level>Advanced</Level>
    <Scope>Technical deep dive</Scope>
    <Assigned_Track></Assigned_Track>
    <Room>Willow: Expo Sessions</Room>
    <Scheduled_At>5 Jun 2025 12:30 PM</Scheduled_At>
    <Speakers>Philip Kiely</Speakers>
    <Companies>Baseten</Companies>
    
    
</204>
<205>
    <Session_ID>933599</Session_ID>
    <Title>Serving Voice  AI at Scale</Title>
    <Description>Real-Time  Voice AI applications demand the lowest possible latencies to enhance user  experiences with more advanced reasoning and agentic capabilities. AWS is  hosting Arjun Desai, co-founder of Cartesia, in a fireside chat for a  technical deep dive into learnings and best practices for building a  state-of-the-art inference stack that serves global enterprise customers.</Description>
    <Session_Format></Session_Format>
    <Level>Advanced</Level>
    <Scope>Technical deep dive</Scope>
    <Assigned_Track></Assigned_Track>
    <Room>Nobhill A&B: Expo Sessions</Room>
    <Scheduled_At>5 Jun 2025 12:30 PM</Scheduled_At>
    <Speakers>Arjun Desai, Rohit Talluri</Speakers>
    <Companies>unknown, Amazon Web Services (AWS)</Companies>
    
    
</205>
<206>
    <Session_ID>933712</Session_ID>
    <Title>Prompt Engineering is Dead</Title>
    <Description>Manual prompt crafting doesn't scale. In this session, we'll explore how to replace it with a test-driven, automated approach. You'll see how to define output evaluators, write minimal prompts, and let agents iterate toward optimal performance—all without manual tweaking. If you're still hand-tuning prompts, you're doing it wrong.</Description>
    <Session_Format></Session_Format>
    <Level>Advanced</Level>
    <Scope>Technical deep dive</Scope>
    <Assigned_Track></Assigned_Track>
    <Room>Juniper: Expo Sessions</Room>
    <Scheduled_At>5 Jun 2025 12:30 PM</Scheduled_At>
    <Speakers>Nir Gazit</Speakers>
    
    
    
</206>
<207>
    <Session_ID>933569</Session_ID>
    <Title>Building CISO-approved agent fleet architecture</Title>
    <Description>Security is the biggest blocker for agent orchestration adoption in regulated industries for SWE agents. Gitpod's agent orchestration went from an originally self-hosted kubernetes architecture to the current 'bring your own cloud' model that enables deployment our SWE agent orchestration platform in secure environments. The architecture allows customers to securely connect their foundational models and agent memory solutions and comes with features like auto-suspend and resume for agent fleets. In this talk we deep dive into the architecture to share our years of learnings in how to secure agent workloads at scale in secure and regulated environments. </Description>
    <Session_Format></Session_Format>
    <Level>Advanced</Level>
    <Scope>Technical deep dive</Scope>
    <Assigned_Track></Assigned_Track>
    <Room>Juniper: Expo Sessions</Room>
    <Scheduled_At>5 Jun 2025 12:45 PM</Scheduled_At>
    <Speakers>Lou Bichard</Speakers>
    
    
    
</207>
<208>
    <Session_ID>933656</Session_ID>
    <Title>Agents, Access, and the Future of Machine Identity</Title>
    <Description>AI agents are calling APIs, submitting forms, and sending emails—but how do you control what they’re allowed to do? As agents act on behalf of users or organizations, traditional patterns like OAuth, session tokens, and role-based access often fall short.
In this talk, we’ll explore how machine identity is evolving to meet this new landscape. You’ll learn:

- How to think about authentication for agents (not just humans)
- What it means to authorize an action when the actor is an LLM or headless service
- Real-world strategies from WorkOS and Cloudflare for assigning, managing, and revoking agent identity and access

By the end, you’ll walk away with practical tools and mental models to build agent-powered systems that are secure, auditable, and scalable.</Description>
    <Session_Format></Session_Format>
    <Level>Introductory and overview</Level>
    <Scope>Introductory (landscape)</Scope>
    <Assigned_Track></Assigned_Track>
    <Room>Willow: Expo Sessions</Room>
    <Scheduled_At>5 Jun 2025 12:45 PM</Scheduled_At>
    <Speakers>Nick Nisi</Speakers>
    <Companies>WorkOS </Companies>
    
    
</208>
<209>
    <Session_ID>933671</Session_ID>
    <Title>Agentic GraphRAG: Simplifying Retrieval Across Structured & Unstructured Data</Title>
    <Description>Agentic workflows often become complex, brittle, and hard to maintain when they need to retrieve and reason across both structured data (typically requiring precise query execution) and unstructured data (commonly handled via vector search in RAG). In this talk, we’ll explore how mapping key information into a knowledge graph can simplify these workflows and improve retrieval quality. You’ll learn core concepts behind GraphRAG, how to integrate it into agent tools, and get access to end-to-end code examples so you can start building right away.</Description>
    <Session_Format></Session_Format>
    <Level>Intermediate</Level>
    <Scope>Introductory (landscape)</Scope>
    <Assigned_Track></Assigned_Track>
    <Room>Nobhill A&B: Expo Sessions</Room>
    <Scheduled_At>5 Jun 2025 12:45 PM</Scheduled_At>
    <Speakers>Zach Blumenfeld</Speakers>
    
    
    
</209>
<210>
    <Session_ID>936816</Session_ID>
    <Title>Building Protected MCP Servers</Title>
    <Description>Join us to see how VS Code and GitHub Copilot's expanding suite of AI features can match or even surpasses the benefits of other popular AI developer tools.  We'll focus on practical scenarios to ensure immediate applicability and work through live demos of Copilot features such as: Code generation using Edits, Planning/problem solving using Chat, Inline terminal command generation, Boilerplate code generation using Agent mode, Improving boilerplate with custom instructions and then refactoring using Agent mode and Edits, Improving test generation and code reviews with custom instructions, as well as an Introduction to MCP. 
</Description>
    <Session_Format>Talk</Session_Format>
    <Level></Level>
    <Scope></Scope>
    <Assigned_Track></Assigned_Track>
    <Room>Nobhill C&D: Microsoft</Room>
    <Scheduled_At>5 Jun 2025 12:45 PM</Scheduled_At>
    <Speakers>Den Delimarsky (DEVDIV), Julia Kasper</Speakers>
    <Companies>Microsoft, Microsoft</Companies>
    
    
</210>
<211>
    <Session_ID>936935</Session_ID>
    <Title>Braintrust Lunch & Learn</Title>
    <Description></Description>
    <Session_Format></Session_Format>
    <Level></Level>
    <Scope></Scope>
    <Assigned_Track></Assigned_Track>
    <Room>Golden Gate Ballroom B: Evals</Room>
    <Scheduled_At>5 Jun 2025 12:45 PM</Scheduled_At>
    <Speakers>Lunch Learn</Speakers>
    
    
    
</211>
<212>
    <Session_ID>933618</Session_ID>
    <Title>Conquering Agent Chaos</Title>
    <Description>Agent deployments can be dicey, especially at first.  This session goes over all the things that cause headache with deployments from serverless issues to networking issues - and how we fix them.</Description>
    <Session_Format></Session_Format>
    <Level>Introductory and overview</Level>
    <Scope>Product launch</Scope>
    <Assigned_Track></Assigned_Track>
    <Room>Willow: Expo Sessions</Room>
    <Scheduled_At>5 Jun 2025 01:00 PM</Scheduled_At>
    <Speakers>Rick Blalock</Speakers>
    
    
    
</212>
<213>
    <Session_ID>933626</Session_ID>
    <Title>Hope is Not a Strategy: Retrieval Patterns for MCP</Title>
    <Description>MCP is a solid integration layer — but how does it hold up when it comes to output quality? Often, not as well as you'd like. Here are some practical retrieval patterns, from basic to advanced, that worked well in my experiments:
* Naive: Just plug in plain MCP and hope the LLM gets it right. Sometimes it does. Sometimes you’ll need a miracle.
* Semantic: Add more descriptive field names and extra metadata. It helps — but usually just a bit.
* Templated: Use a structured template and have the LLM fill it out step by step. More effort, but by far the most reliable results.</Description>
    <Session_Format></Session_Format>
    <Level>Intermediate</Level>
    <Scope>Technical deep dive</Scope>
    <Assigned_Track></Assigned_Track>
    <Room>Salons 9-15: Expo Hall</Room>
    <Scheduled_At>5 Jun 2025 01:00 PM</Scheduled_At>
    <Speakers>Philipp Krenn</Speakers>
    
    
    
</213>
<214>
    <Session_ID>933676</Session_ID>
    <Title>Human-seeded Evals</Title>
    <Description>In this talk I'll introduce the concept of Human-seeded Evals, explain the principle and demo them with Pydantic Logfire.</Description>
    <Session_Format>Talk</Session_Format>
    <Level>Introductory and overview</Level>
    <Scope>Introductory (landscape)</Scope>
    <Assigned_Track></Assigned_Track>
    <Room>Nobhill A&B: Expo Sessions</Room>
    <Scheduled_At>5 Jun 2025 01:00 PM</Scheduled_At>
    <Speakers>Samuel Colvin</Speakers>
    
    
    
</214>
<215>
    <Session_ID>936902</Session_ID>
    <Title>Vibe Coding at Scale: Customizing AI Assistants for Enterprise Environments</Title>
    <Description>"Vibe coding" often falters in complex enterprise environments. Drawing from real implementations, this talk demonstrates systematic approaches to customizing AI assistants for challenging codebases. We'll explore specialized techniques for navigating complex architectures, evidence-based strategies for undocumented legacy systems, methodologies for maintaining context across polyglot environments, and frameworks for standardizing AI usage while preserving developer autonomy. Through case studies from finance and healthcare, we'll present a comprehensive evaluation framework that bridges the gap between AI's theoretical capabilities and practical enterprise implementation, enabling true flow-state collaboration even within the most complex development ecosystems.</Description>
    <Session_Format>Talk</Session_Format>
    <Level></Level>
    <Scope></Scope>
    <Assigned_Track></Assigned_Track>
    <Room>Juniper: Expo Sessions</Room>
    <Scheduled_At>5 Jun 2025 01:00 PM</Scheduled_At>
    <Speakers>Harald Kirschner</Speakers>
    
    
    
</215>
<216>
    <Session_ID>936901</Session_ID>
    <Title>Unlocking AI-Powered DevOps Within Your Organization</Title>
    <Description>"Software development is a team sport, with many different roles, where eveyone can win. But success isn't guaranteed; it depends on specific practices, policies, and tools which enable minimally-siloed, AI-accelerated collaboration across all parts of the DevOps process, from PM to development to CI/CD and security.
 
 Discover the patterns and tools which lead to success, methods for changing the status quo, and perhaps a few horror stories. We'll touch on innersourcing, cloud development, AI, automation, governance, security, scaling and more -- with actionable learnings for everyone from small maintainer communities to F500 Enterprises."</Description>
    <Session_Format>Talk</Session_Format>
    <Level></Level>
    <Scope></Scope>
    <Assigned_Track></Assigned_Track>
    <Room>Nobhill C&D: Microsoft</Room>
    <Scheduled_At>5 Jun 2025 01:10 PM</Scheduled_At>
    <Speakers>Jon Peck</Speakers>
    <Companies>GitHub</Companies>
    
    
</216>
<217>
    <Session_ID>933702</Session_ID>
    <Title>Smarter Together: Designing Multi-Agent Systems with Shared, Evolving Memory</Title>
    <Description>In today’s most advanced AI systems, intelligence is no longer confined to a single model or agent—it emerges from coordination. But coordination requires memory: short-term, long-term, and shared. In this talk, we’ll break down how agent systems can store, retrieve, and evolve shared memory to become smarter over time. You'll learn what it takes to architect these continuously learning systems, how to track and improve memory quality, and why robust, flexible infrastructure is the foundation of it all. Stick around to see how this works in practice—live.</Description>
    <Session_Format></Session_Format>
    <Level>Advanced</Level>
    <Scope>Technical deep dive</Scope>
    <Assigned_Track></Assigned_Track>
    <Room>Salons 9-15: Expo Hall</Room>
    <Scheduled_At>5 Jun 2025 01:15 PM</Scheduled_At>
    <Speakers>Mikiko Bazeley</Speakers>
    
    
    
</217>
<218>
    <Session_ID>933491</Session_ID>
    <Title>Pipecat Cloud: Open Source Enterprise Voice AI</Title>
    <Description>Learn about building voice agents with for customer support, call center workflows, market research, and many other use cases.  Pipecat is the open source, vendor neutral realtime agent framework used by teams at NVIDIA, OpenAI, Google DeepMind, AWS, and hundreds of startups and scale-ups.</Description>
    <Session_Format></Session_Format>
    <Level>Introductory and overview</Level>
    <Scope>Introductory (landscape)</Scope>
    <Assigned_Track></Assigned_Track>
    <Room>Salons 9-15: Expo Hall</Room>
    <Scheduled_At>5 Jun 2025 01:30 PM</Scheduled_At>
    <Speakers>Chad Bailey</Speakers>
    <Companies>Daily</Companies>
    
    
</218>
<219>
    <Session_ID>933453</Session_ID>
    <Title>Onboarding your robot coworkers: customizing AI code review agents to your team’s style</Title>
    <Description>It’s not enough that AI can review and understand your code in a vacuum. In order to be effective, AI agents need context around your entire codebase and understand the nuances of the way your team works. This talk will examine technical approaches and best practices for teaching AI tools to enforce highly customized style guides and coding conventions no matter what tech stack you’re working in.</Description>
    <Session_Format></Session_Format>
    <Level>Intermediate</Level>
    <Scope>Introductory (landscape)</Scope>
    <Assigned_Track></Assigned_Track>
    <Room>Salons 9-15: Expo Hall</Room>
    <Scheduled_At>5 Jun 2025 01:45 PM</Scheduled_At>
    <Speakers>Tomas Reimers</Speakers>
    
    
    
</219>
<220>
    <Session_ID>913351</Session_ID>
    <Title>How to defend your sites from AI bots</Title>
    <Description>Constantly seeing CAPTCHAs? It used to be easy to detect the humans from the droids, but what else can we do when synthetic clients make up nearly half of all web requests. Rotating IPs, spoofed browsers, and agents acting on behalf of real users - are we doomed to forever be solving puzzles?

In this talk, we’ll explore user agents, HTTP fingerprints, and IP reputation signals that make humans and agents stand out from scrapers, build a realistic threat model, and dig into the behaviors that reveal the LLM-mimicry. Leave with AX- and UX-safe code, benchmarks, and tools to help you take back control.</Description>
    <Session_Format>Talk</Session_Format>
    <Level>Intermediate</Level>
    <Scope>Technical deep dive</Scope>
    <Assigned_Track>Security (13)</Assigned_Track>
    <Room>Foothill C: Security</Room>
    <Scheduled_At>5 Jun 2025 02:00 PM</Scheduled_At>
    <Speakers>David Mytton</Speakers>
    <Companies>Arcjet</Companies>
    
    
</220>
<221>
    <Session_ID>914049</Session_ID>
    <Title>How to Build Agents without losing control</Title>
    <Description>Planning agents help solve complex tasks by breaking them into steps. They work across enterprise systems where data lives in many places. These agents are powerful but can be hard to control. This session shows how to use blueprints as guardrails for these agents. I will explain techniques to ensure agents follow the right plan. I will cover evaluation methods to verify agents stay aligned with user goals.</Description>
    <Session_Format>Talk</Session_Format>
    <Level>Advanced</Level>
    <Scope>Technical deep dive</Scope>
    <Assigned_Track>AI in the Fortune 500 (L2)</Assigned_Track>
    <Room>Golden Gate Ballroom C: AI in the Fortune 500</Room>
    <Scheduled_At>5 Jun 2025 02:00 PM</Scheduled_At>
    <Speakers>Yogi Miraje</Speakers>
    <Companies>FactSet Research Systems Inc</Companies>
    
    
</221>
<222>
    <Session_ID>914081</Session_ID>
    <Title>General Intelligence is Multimodal</Title>
    <Description>Talking about Luma AI, our mission, and how our ML infrastructure enables SOTA multimodal model development </Description>
    <Session_Format>Talk</Session_Format>
    <Level>Advanced</Level>
    <Scope>Case Study/War Story</Scope>
    <Assigned_Track>Generative Media (14)</Assigned_Track>
    <Room>Foothill F: Generative Media</Room>
    <Scheduled_At>5 Jun 2025 02:00 PM</Scheduled_At>
    <Speakers>Keegan McCallum</Speakers>
    
    
    
</222>
<223>
    <Session_ID>914533</Session_ID>
    <Title>How to Train Your Agent: Building Reliable Agents with RL</Title>
    <Description>Have you ever launched an awesome agentic demo, only to realize no amount of prompting will make it reliable enough to deploy in production? Agent reliability is a famously difficult problem to solve!

In this talk we’ll learn how to use GRPO to help your agent learn from its successes and failures and improve over time. We’ve seen dramatic results with this technique, such as an email assistant agent that whose success rate jumped from 74% to 94% after replacing o4-mini with an open source model optimized using GRPO.

We’ll share case studies as well as practical lessons learned around the types of problems this works well for and the unexpected pitfalls to avoid.</Description>
    <Session_Format>Talk</Session_Format>
    <Level>Intermediate</Level>
    <Scope>Case Study/War Story</Scope>
    <Assigned_Track>Reasoning + RL (15)</Assigned_Track>
    <Room>Yerba Buena Ballroom 2-6: Reasoning + RL</Room>
    <Scheduled_At>5 Jun 2025 02:00 PM</Scheduled_At>
    <Speakers>Kyle Corbitt</Speakers>
    <Companies>OpenPipe</Companies>
    
    
</223>
<224>
    <Session_ID>915389</Session_ID>
    <Title>AI and Human Whiteboarding Partnership</Title>
    <Description>Covid sent everybody home and created the space of virtual whiteboards. At first the experience reused the physical constraints but soon it became better than a physical whiteboard thanks to using virtual native concepts like copy-paste and using keyboard input.
The next step in this evolution is to integrate AI into the workflow. We've tried a lot of things with Excalidraw and ended up landing on turning prompt into diagram. Come to the talk to understand how it fits into the workflow and how we implemented it.</Description>
    <Session_Format>Talk</Session_Format>
    <Level>Introductory and overview</Level>
    <Scope>Case Study/War Story</Scope>
    <Assigned_Track>Design Engineering (10)</Assigned_Track>
    <Room>Foothill G 1&2: Design Engineering</Room>
    <Scheduled_At>5 Jun 2025 02:00 PM</Scheduled_At>
    <Speakers>Christopher Chedeau</Speakers>
    <Companies>Facebook</Companies>
    
    
</224>
<225>
    <Session_ID>915934</Session_ID>
    <Title>Teaching Cars to Think: Language Models and Autonomous Vehicles</Title>
    <Description>This session explores Waymo's latest research on the End-to-End Multimodal Model for Autonomous Driving (EMMA) and advanced sensor simulation techniques. Jyh-Jing Hwang will demonstrate how multimodal large language models like Gemini could improve autonomous driving through unified end-to-end architectures that process raw sensor data directly into driving decisions. 

The presentation will showcase EMMA's state-of-the-art performance in trajectory planning, 3D object detection, and road graph understanding, as well as another Drive&Gen research approach to sensor simulation for evaluating an end-to-end motion planning model. Attendees will gain insights into the benefits of co-training across multiple autonomous driving tasks and the potential of controlled video generation for testing under various environmental conditions.

More on EMMA here: https://waymo.com/blog/2024/10/introducing-emma
</Description>
    <Session_Format>Talk</Session_Format>
    <Level>Intermediate</Level>
    <Scope>Technical deep dive</Scope>
    <Assigned_Track>Autonomy + Robotics (16)</Assigned_Track>
    <Room>Foothill E: Autonomy + Robotics</Room>
    <Scheduled_At>5 Jun 2025 02:00 PM</Scheduled_At>
    <Speakers>Jyh-Jing Hwang</Speakers>
    <Companies>Waymo </Companies>
    
    
</225>
<226>
    <Session_ID>916215</Session_ID>
    <Title>Building Alice’s Brain: How We Built an AI Sales Rep that Learns Like a Human</Title>
    <Description>AI agents are becoming essential tools for teams of all sizes and industries - but training them to become experts in your product, business, and customerbase remains a challenge. 

What if onboarding a digital worker was as simple as uploading your pitch deck? At 11x, we built Alice, an AI SDR that writes outbound emails with the nuance and context of a top-performing human sales rep - because she learns like one too!

In this talk, we'll share how we built a knowledge base that allows 11x customers to "train" Alice on their internal materials: PDFs, websites, call recordings, and more. We'll talk through the ingestion pipeline in detail, discuss storage/retrieval technologies and their tradeoffs, and explain how Alice uses the knowledge base to drive high-performance email outreach at scale.</Description>
    <Session_Format>Talk</Session_Format>
    <Level>Intermediate</Level>
    <Scope>Case Study/War Story</Scope>
    <Assigned_Track>Retrieval + Search (09)</Assigned_Track>
    <Room>Golden Gate Ballroom A: Retrieval + Search</Room>
    <Scheduled_At>5 Jun 2025 02:00 PM</Scheduled_At>
    <Speakers>Sherwood Callaway, Satwik Singh</Speakers>
    <Companies>11x AI, 11x AI</Companies>
    
    
</226>
<227>
    <Session_ID>933686</Session_ID>
    <Title>CIAM for AI: Who Are Your Agents and What Can They Do?</Title>
    <Description>AI agents are changing the way modern SaaS products operate. Whether automating workflows, integrating with APIs, or acting on behalf of users, AI-driven assistants and autonomous systems are becoming core product features. But securing these agents presents a fundamental challenge: How do you authenticate AI agents? How do you control what they can access? How do you ensure they act within the right permissions? This talk will explore these concepts and more while highlighting current research and best practices.</Description>
    <Session_Format>Talk</Session_Format>
    <Level>Introductory and overview</Level>
    <Scope>Introductory (landscape)</Scope>
    <Assigned_Track></Assigned_Track>
    <Room>SOMA: AI Architects</Room>
    <Scheduled_At>5 Jun 2025 02:00 PM</Scheduled_At>
    <Speakers>Michael Grinich</Speakers>
    <Companies>WorkOS</Companies>
    
    
</227>
<228>
    <Session_ID>939130</Session_ID>
    <Title>[Evals Keynote] tba</Title>
    <Description>tbc</Description>
    <Session_Format>Talk</Session_Format>
    <Level></Level>
    <Scope></Scope>
    <Assigned_Track>Evals (12)</Assigned_Track>
    <Room>Golden Gate Ballroom B: Evals</Room>
    <Scheduled_At>5 Jun 2025 02:00 PM</Scheduled_At>
    <Speakers>Ankur Goyal</Speakers>
    <Companies>Braintrust</Companies>
    
    
</228>
<229>
    <Session_ID>939942</Session_ID>
    <Title>Introducing Claude Code</Title>
    <Description>Hear about Claude Code directly from its creator: origin story, getting your team set up, and practical tips for getting more out of Code.</Description>
    <Session_Format>Talk</Session_Format>
    <Level>Intermediate</Level>
    <Scope>Technical deep dive</Scope>
    <Assigned_Track>SWE Agents (11)</Assigned_Track>
    <Room>Yerba Buena Ballroom 7&8: SWE Agents</Room>
    <Scheduled_At>5 Jun 2025 02:00 PM</Scheduled_At>
    <Speakers>Boris Cherny</Speakers>
    <Companies>Anthropic</Companies>
    
    
</229>
<230>
    <Session_ID>914024</Session_ID>
    <Title>Building a Smarter AI Agent with Neural RAG</Title>
    <Description>RAG quality for AI agents is critical, and traditional keyword-based search engines consistently underperform in agentic or multi-step tasks, where semantic grounding and contextual nuance matter most.

In this talk, Will Bryk, CEO of Exa will live code two AI agent applications–one using traditional keyword search RAG and one using neural network RAG via vector search. He’ll then evaluate both applications based on task performance, relevance, and latency. With a live demo (no theory or pre-baked applications), the audience will get a firsthand look at the practical differences between keyword and semantic systems in production, and learn embedding strategies, indexing trade-offs, hybrid retrieval techniques, prompt tuning, and more. </Description>
    <Session_Format>Talk</Session_Format>
    <Level>Advanced</Level>
    <Scope>Technical deep dive</Scope>
    <Assigned_Track>Retrieval + Search (09)</Assigned_Track>
    <Room>Golden Gate Ballroom A: Retrieval + Search</Room>
    <Scheduled_At>5 Jun 2025 02:20 PM</Scheduled_At>
    <Speakers>Will Bryk</Speakers>
    <Companies>Exa</Companies>
    
    
</230>
<231>
    <Session_ID>915059</Session_ID>
    <Title>2025 is the Year of Evals!  Just like 2024, and 2023, and …</Title>
    <Description>AI is getting deployed without guardrails, without governance, without due diligence.  Surely this is the year we’ll see a Fortune 500 CEO fired because of a preventable AI incident.  Surely this is the year we’ll see enterprises wake up to pre-deployment evaluation and post-deployment monitoring being an urgent need.  This story hasn’t changed for a decade, but surely this is the year it will.

In this talk, I’ll cover what enterprise-level AI/ML evaluation has looked like for the last decade - what’s changed, what hasn’t, what sells, what doesn’t, and where I see things going from here on out.  Evaluation matters - we all know this - but using my experience in the trenches over the last decade or so I hope to bridge the gap between what practitioners need and what the C-suite pays for in the space of AI evaluations.
</Description>
    <Session_Format>Talk</Session_Format>
    <Level>Intermediate</Level>
    <Scope>Case Study/War Story</Scope>
    <Assigned_Track>Evals (12)</Assigned_Track>
    <Room>Golden Gate Ballroom B: Evals</Room>
    <Scheduled_At>5 Jun 2025 02:20 PM</Scheduled_At>
    <Speakers>John Dickerson</Speakers>
    
    
    
</231>
<232>
    <Session_ID>915387</Session_ID>
    <Title>Software Development Agents: What Works and What Doesn't</Title>
    <Description>The adoption of AI into software development has been bumpy. While autocomplete tools like Copilot have gone mainstream, autonomous agents like Devin and OpenHands have generated both enthusiasm and skepticism. Some engineers claim they generate a 10x productivity boost; others that they just create noise and tech debt.

The difference between the enthusiasts and the skeptics is that the enthusiasts have reasonable expectations for what these agents can do, and have both practical and intuitive knowledge for how to use them effectively.

In this session, we'll talk about what tasks are appropriate for today's software agents, what tasks they might start to succeed at in 2025, and what tasks are best left to humans no matter how good they get.

Session Outline:
Learn how to use software development agents like OpenHands (fka OpenDevin) effectively, without creating noise and tech debt.</Description>
    <Session_Format>Talk</Session_Format>
    <Level>Intermediate</Level>
    <Scope>Introductory (landscape)</Scope>
    <Assigned_Track>SWE Agents (11)</Assigned_Track>
    <Room>Yerba Buena Ballroom 7&8: SWE Agents</Room>
    <Scheduled_At>5 Jun 2025 02:20 PM</Scheduled_At>
    <Speakers>Robert Brennan</Speakers>
    <Companies>All Hands AI</Companies>
    
    
</232>
<233>
    <Session_ID>915751</Session_ID>
    <Title>How to Secure Agents using OAuth</Title>
    <Description>We all know sharing passwords is bad (unless you want free TV), so why are we sharing API keys with AI?  We shouldn't, and that’s why we need to talk about OAuth.

In this talk, we will give a brief intro to OAuth.  Then we will talk about the state of authorization in MCP.  We will show how an MCP client uses OAuth to authenticate a user and securely access private resources and tools hosted by an MCP server.  Then we’ll look at ways autonomous agents can use OAuth on their own behalf, talking to other agents and MCP servers directly.  We’ll learn how to use OAuth to build agents that humans and machines can trust.</Description>
    <Session_Format>Talk</Session_Format>
    <Level>Intermediate</Level>
    <Scope>Technical deep dive</Scope>
    <Assigned_Track>Security (13)</Assigned_Track>
    <Room>Foothill C: Security</Room>
    <Scheduled_At>5 Jun 2025 02:20 PM</Scheduled_At>
    <Speakers>Jared Hanson</Speakers>
    <Companies>Keycard</Companies>
    
    
</233>
<234>
    <Session_ID>915921</Session_ID>
    <Title>Testing the Un-Testable: Monitoring AI Products in the Wild</Title>
    <Description>Evals are straightforward—like unit tests, they confirm your model got specific test cases right.

But in the real world, your AI encounters millions of unpredictable interactions each day. How do you gauge user trust, identify frustrations, and adapt when there's no single "correct" output? Diving through endless logs and manually adding one eval at a time won't cut it.

In this session, we'll explore how leading teams are moving beyond static evals; leveraging semantic analytics, LLM teachers, and AI-powered monitoring to deeply understand user experiences at scale—building AI products that don’t just pass tests, but genuinely resonate with users.</Description>
    <Session_Format>Talk</Session_Format>
    <Level>Intermediate</Level>
    <Scope>Case Study/War Story</Scope>
    <Assigned_Track>AI Architects (L1)</Assigned_Track>
    <Room>SOMA: AI Architects</Room>
    <Scheduled_At>5 Jun 2025 02:20 PM</Scheduled_At>
    <Speakers>Ben Hylak, Sid Bendre</Speakers>
    <Companies>Raindrop.ai, Oleve</Companies>
    
    
</234>
<235>
    <Session_ID>925912</Session_ID>
    <Title>POC to PROD: Hard Lessons from 200+ Enterprise GenAI Deployments</Title>
    <Description>The transition from experimental GenAI demonstrations to robust, production-grade systems involves significant technical and organizational complexities. Humans provide a ceiling on the true ROI of automations. This session synthesizes key patterns and practical strategies gathered from more than 200 GenAI implementations across multiple industries and business sizes.

Beyond the general lessons that apply to most products leveraging GenAI, we'll cover detailed observations within three application areas: multimodal understanding and search, enterprise knowledge retrieval, and AI agent architectures. We will share real-world comparative performance data and metrics on embedding models, vector index implementations, and explore various implementation methodologies that balance performance and cost.

Additionally, the session addresses organizational insights critical to successful AI deployments, such as the importance of clearly defined evaluation processes and understanding real-world user interaction challenges, highlighted by examples from healthcare environments. Attendees will gain an understanding of decision-making criteria, including the appropriate complexity of prompt engineering versus more elaborate orchestration methods, token/cost management strategies in multilingual settings, and the challenges in driving behavioral change with new UX and application interaction capabilities.

Participants will leave equipped with practical, data-supported insights for effectively navigating their own GenAI projects, including benchmarks and criteria for informed technology selection, and techniques to streamline the transition from initial concept to sustainable operational deployment. Please note, we all know this field evolves rapidly and we will mark which lessons we believe are immutable.</Description>
    <Session_Format>Talk</Session_Format>
    <Level>Advanced</Level>
    <Scope>Case Study/War Story</Scope>
    <Assigned_Track>AI in the Fortune 500 (L2)</Assigned_Track>
    <Room>Golden Gate Ballroom C: AI in the Fortune 500</Room>
    <Scheduled_At>5 Jun 2025 02:20 PM</Scheduled_At>
    <Speakers>Randall Hunt</Speakers>
    <Companies>Caylent</Companies>
    
    
</235>
<236>
    <Session_ID>926721</Session_ID>
    <Title>What Reinforcement Learning with Verifiable Rewards Changed</Title>
    <Description>Reinforcement learning with verifiable rewards (RLVR) came onto the field with a storm after the DeepSeek R1 model showed that training reasonable models was accessible to the entire AI industry. Next it became table stakes for high scores in math and code, but quickly it's shifting to opening the doors on new types of models entirely -- those enabling tool use, reasoning, code execution, and everything to come together to new experiences.

This talk describes how RLVR emerged in such a sudden way, what we can glean about AI research generally, and how RLVR changed the AI models we will use forever. </Description>
    <Session_Format>Talk</Session_Format>
    <Level>Intermediate</Level>
    <Scope>Introductory (landscape)</Scope>
    <Assigned_Track></Assigned_Track>
    <Room>Yerba Buena Ballroom 2-6: Reasoning + RL</Room>
    <Scheduled_At>5 Jun 2025 02:20 PM</Scheduled_At>
    <Speakers>Nathan Lambert</Speakers>
    <Companies>Allen Institute for AI</Companies>
    
    
</236>
<237>
    <Session_ID>934617</Session_ID>
    <Title>tldraw computer</Title>
    <Description>Learn about tldraw's latest experiments with AI on an infinite canvas. In 2024, we created tldraw computer, a loose visual programming environment where arrows and LLMs powered every step of a graph on tldraw's canvas.</Description>
    <Session_Format>Talk</Session_Format>
    <Level>Introductory and overview</Level>
    <Scope>Case Study/War Story</Scope>
    <Assigned_Track>Design Engineering (10)</Assigned_Track>
    <Room>Foothill G 1&2: Design Engineering</Room>
    <Scheduled_At>5 Jun 2025 02:20 PM</Scheduled_At>
    <Speakers>Steve Ruiz</Speakers>
    <Companies>tldraw</Companies>
    
    
</237>
<238>
    <Session_ID>945538</Session_ID>
    <Title>General purpose robots as professional Chefs</Title>
    <Description>How we converted a bimanual robot into a professional chef that works in novel kitchens and learn new recipes from a single demonstration.</Description>
    <Session_Format>Talk</Session_Format>
    <Level>Intermediate</Level>
    <Scope>Introductory (landscape)</Scope>
    <Assigned_Track>Autonomy + Robotics (16)</Assigned_Track>
    <Room>Foothill E: Autonomy + Robotics</Room>
    <Scheduled_At>5 Jun 2025 02:20 PM</Scheduled_At>
    <Speakers>Nikhil Abraham</Speakers>
    <Companies>CloudChef</Companies>
    
    
</238>
<239>
    <Session_ID>907695</Session_ID>
    <Title>Layering every technique in RAG, one query at a time</Title>
    <Description>Start with the simplest Search - in-memory embeddings with relevance ranking. End with the most complex planet-scale Search - 70+ corpus mix of token, embeddings, and knowledge graphs, all jointly retrieved, custom ranked, joint re-ranked, and then LLM-processed, at 160,000 queries per second in under 200msec.

This talk will be a fun “one query at a time” survey of all techniques in RAG in incremental complexity, showing the limits of each technique and what the next layered one opens up in terms of capabilities to handle ever-more complex queries in RAG. You’ll learn why queries like [falafel] are notoriously hard to Search over, why chunking your documents can be disastrous, how you can sometimes can get away with a simple bm25, and how some Search problems are so hard to solve that you’re better off punting the problem to the LLM or the UX. Brought to you by the team that worked on 50+ Search products, in the context of Google.com and custom Enterprise Search.</Description>
    <Session_Format>Talk</Session_Format>
    <Level>Intermediate</Level>
    <Scope>Technical deep dive</Scope>
    <Assigned_Track>Retrieval + Search (09)</Assigned_Track>
    <Room>Golden Gate Ballroom A: Retrieval + Search</Room>
    <Scheduled_At>5 Jun 2025 02:40 PM</Scheduled_At>
    <Speakers>David Karam</Speakers>
    
    
    
</239>
<240>
    <Session_ID>914017</Session_ID>
    <Title>Beyond the Prototype: Using AI to Write High-Quality Code</Title>
    <Description>In this case study-based keynote, Josh Albrecht, CTO of Imbue, examines the critical engineering challenges in building AI coding systems that create more than just prototypes. Drawing from Imbue's research developing Sculptor, an experimental coding agent environment, Josh shares key insights into the fundamental technical obstacles encountered when evolving AI-assisted coding from toy applications to more robust software systems. 

The session will explore approaches to core challenges like safely executing code, managing context across large codebases, automating test generation, and creating systems that can identify potential pitfalls in AI-generated code. Attendees will gain practical insights into the technical underpinnings of next-generation coding agents that aim to handle complex software engineering challenges architecting larger systems, increasing meaningful test coverage and designing systems that are easy to debug—moving us closer to AI systems that can help create maintainable software.
</Description>
    <Session_Format>Talk</Session_Format>
    <Level>Intermediate</Level>
    <Scope>Case Study/War Story</Scope>
    <Assigned_Track>SWE Agents (11)</Assigned_Track>
    <Room>Yerba Buena Ballroom 7&8: SWE Agents</Room>
    <Scheduled_At>5 Jun 2025 02:40 PM</Scheduled_At>
    <Speakers>Josh Albrecht</Speakers>
    <Companies>Imbue</Companies>
    
    
</240>
<241>
    <Session_ID>914798</Session_ID>
    <Title>Why you should care about AI interpretability</Title>
    <Description>Mechanistic interpretability is a frontier field that aims to reverse engineer neural networks. At Goodfire, we're operationalizing the latest in interpretability research with Ember: a universal platform for neural programming. Ember decodes the neurons of an AI model to give direct, programmable access to its internal representations.
In this talk, we'll share more about what's unlocked by moving beyond black-box inputs and outputs, including entirely new ways to apply, train, and align AI models. We're excited for a future in which neural programming allows users to discover new knowledge hidden in their model, precisely shape its behaviors, and improve its performance. </Description>
    <Session_Format>Talk</Session_Format>
    <Level>Intermediate</Level>
    <Scope>Technical deep dive</Scope>
    <Assigned_Track>Generative Media (14)</Assigned_Track>
    <Room>Foothill F: Generative Media</Room>
    <Scheduled_At>5 Jun 2025 02:40 PM</Scheduled_At>
    <Speakers>Mark Bissell</Speakers>
    <Companies>Goodfire AI</Companies>
    
    
</241>
<242>
    <Session_ID>914934</Session_ID>
    <Title>The Web Browser Is All You Need</Title>
    <Description>With the rise of MCP servers, A2A, and our trusty friend, OpenAPI, it turns out the web browser may be the default MCP server for the rest of the internet.

In this talk, we'll walk through how a web browsing tool is probably the only tool you'll need to enable production AI Agents. </Description>
    <Session_Format>Talk</Session_Format>
    <Level>Introductory and overview</Level>
    <Scope>Introductory (landscape)</Scope>
    <Assigned_Track>AI Infrastructure (05)</Assigned_Track>
    <Room>SOMA: AI Architects</Room>
    <Scheduled_At>5 Jun 2025 02:40 PM</Scheduled_At>
    <Speakers>Paul Klein IV</Speakers>
    
    
    
</242>
<243>
    <Session_ID>915873</Session_ID>
    <Title>How we hacked YC Spring 2025 batch’s AI agents</Title>
    <Description>We hacked 7 of the16 publicly-accessible YC X25 AI agents. This allowed us to leak user data, execute code remotely, and take over databases. All within 30 minutes each. In this session, we'll walk through the common mistakes these companies made and how you can mitigate these security concerns before your agents put your business at risk.</Description>
    <Session_Format>Talk</Session_Format>
    <Level>Intermediate</Level>
    <Scope>Technical deep dive</Scope>
    <Assigned_Track>Security (13)</Assigned_Track>
    <Room>Foothill C: Security</Room>
    <Scheduled_At>5 Jun 2025 02:40 PM</Scheduled_At>
    <Speakers>Rene Brandel</Speakers>
    <Companies>Casco (YC X25)</Companies>
    
    
</243>
<244>
    <Session_ID>916104</Session_ID>
    <Title>How to look at your data; what to look for, how to measure</Title>
    <Description>By the end of this talk, you'll understand what it takes to apply clustering techniques and data analysis to understand what is the valuable work that your AI application is doing through analyzing conversation histories and how to create generative evals to benchmark your newly discovered superpowers. </Description>
    <Session_Format>Talk</Session_Format>
    <Level>Introductory and overview</Level>
    <Scope>Case Study/War Story</Scope>
    <Assigned_Track>Evals (12)</Assigned_Track>
    <Room>Golden Gate Ballroom B: Evals</Room>
    <Scheduled_At>5 Jun 2025 02:40 PM</Scheduled_At>
    <Speakers>Jeff Huber, Jason Liu</Speakers>
    <Companies>Chroma, 567 Studio</Companies>
    
    
</244>
<245>
    <Session_ID>935969</Session_ID>
    <Title>Building Agents (the hard parts!)</Title>
    <Description>AI workloads are rapidly shifting from AI being used for augmentation (co-pilots), to AI becoming responsible for full, end-to-end automation (agents). But building effective agents, and even more importantly, agent experiences that boost productivity requires many pieces. In this talk, we'll be covering the building blocks of agents, how to put them together, and what we've learned from top companies building agents along the way. </Description>
    <Session_Format>Talk</Session_Format>
    <Level>Intermediate</Level>
    <Scope>Technical deep dive</Scope>
    <Assigned_Track>AI in the Fortune 500 (L2)</Assigned_Track>
    <Room>Golden Gate Ballroom C: AI in the Fortune 500</Room>
    <Scheduled_At>5 Jun 2025 02:40 PM</Scheduled_At>
    <Speakers>Rita  Kozlov</Speakers>
    <Companies>cloudflare</Companies>
    
    
</245>
<246>
    <Session_ID>939640</Session_ID>
    <Title>Towards Verified Superintelligence</Title>
    <Description>I describe a new paradigm towards open-endedly self-improving intelligence by scaling verification to remove the human data and supervision bottleneck. The objective is to achieve trustless alignment of superintelligence.</Description>
    <Session_Format>Talk</Session_Format>
    <Level>Intermediate</Level>
    <Scope>Introductory (landscape)</Scope>
    <Assigned_Track>Reasoning + RL (15)</Assigned_Track>
    <Room>Yerba Buena Ballroom 2-6: Reasoning + RL</Room>
    <Scheduled_At>5 Jun 2025 02:40 PM</Scheduled_At>
    <Speakers>Christian Szegedy</Speakers>
    <Companies>-</Companies>
    
    
</246>
<247>
    <Session_ID>904751</Session_ID>
    <Title>Ship Production Software in Minutes, Not Months</Title>
    <Description>Planning, coding, testing, monitoring—the endless cycle that spans 10+ tools that fragment our focus and slows delivery to a crawl. Vibe coding doesn't work when you've got 10TB of code. If you just sighed, you're one of many professional software engineers trapped in the traditional software development lifecycle (SDLC) that was designed before AI could parallelize your entire workflow.

But what if you could orchestrate multiple AI agents on tasks beyond just generating code, while you focus on the creative decisions that matter?

In this talk, I'll demonstrate how real enterprise organizations are changing their entire SDLC—going from understanding, planning, coding, and testing all the way to incident response—using AI agents. You'll witness the next evolution of software engineering—where AI doesn't just generate code, but orchestrates the entire development lifecycle.</Description>
    <Session_Format>Talk</Session_Format>
    <Level>Intermediate</Level>
    <Scope>Product launch</Scope>
    <Assigned_Track>SWE Agents (11)</Assigned_Track>
    <Room>Yerba Buena Ballroom 7&8: SWE Agents</Room>
    <Scheduled_At>5 Jun 2025 03:00 PM</Scheduled_At>
    <Speakers>Eno Reyes</Speakers>
    <Companies>Factory</Companies>
    
    
</247>
<248>
    <Session_ID>915826</Session_ID>
    <Title>CI in the Era of AI: From Unit Tests to Stochastic Evals</Title>
    <Description>Software engineers have long understood that high-quality code requires comprehensive automated testing. For decades, our industry has relied on deterministic tests with clear pass/fail outcomes to ensure reliability. 

High-quality software depends on automated testing. That's certainly true at Zed, where we're building a next-generation native IDE in Rust. Zed runs at 120 frames per second, but it would also crash once a second if we didn't maintain and run a comprehensive suite of unit tests on every change.

But what happens when AI enters the equation?

In this talk, we'll explore how continuous integration evolves when working with AI components. "Evals" - parlance from the machine learning field - are fundamentally a continuation of the software testing tradition, but with a critical difference: they're inherently stochastic.

Zed's traditional CI goes to extreme lengths to eliminate non-determinism, as nobody likes having their pull requests blocked by flaky builds. We've even fully simulated network interactions with a deterministic random scheduler. AI components, however, forced us to confront a fundamental paradigm shift—uncertainty isn't a bug but an intrinsic feature of these systems, compelling us to embrace what we couldn't avoid.

We'll share our journey of reconceptualizing evals as "stochastic unit tests" - still verifying system behavior, but without binary pass/fail grades.

We'll discuss practical approaches to:
- Thoughtfully building test suites for AI components
- Shifting from red/green outcomes to "shades of gray"
- Replacing build gates with trend analysis and performance monitoring
- Maintaining engineering confidence despite statistical variance

Whether you're incorporating AI into existing systems or building new AI-powered tools, this talk will provide practical insights into maintaining quality when determinism gives way to probability.</Description>
    <Session_Format>Online Talk</Session_Format>
    <Level>Intermediate</Level>
    <Scope>Technical deep dive</Scope>
    <Assigned_Track></Assigned_Track>
    <Room>Juniper: Expo Sessions</Room>
    <Scheduled_At>5 Jun 2025 03:15 PM</Scheduled_At>
    <Speakers>Nathan Sobo</Speakers>
    
    
    
</248>
<249>
    <Session_ID>933474</Session_ID>
    <Title>Cattle, not genies: building AI agents from first principles</Title>
    <Description>As magical as they may seem, AI agents should be treated like any other software system. This talk will cover the best practices in designing and building AI systems including observability, security hardening, and proper UX.</Description>
    <Session_Format></Session_Format>
    <Level>Intermediate</Level>
    <Scope>Introductory (landscape)</Scope>
    <Assigned_Track></Assigned_Track>
    <Room>Willow: Expo Sessions</Room>
    <Scheduled_At>5 Jun 2025 03:15 PM</Scheduled_At>
    <Speakers>Kenneth DuMez</Speakers>
    
    
    
</249>
<250>
    <Session_ID>936298</Session_ID>
    <Title>To the moon! Navigating deep context in legacy code with Augment Agent</Title>
    <Description>Shortened presentation-only version of our Apollo 11 workshop</Description>
    <Session_Format>Talk</Session_Format>
    <Level>Introductory and overview</Level>
    <Scope>Introductory (landscape)</Scope>
    <Assigned_Track></Assigned_Track>
    <Room>Nobhill A&B: Expo Sessions</Room>
    <Scheduled_At>5 Jun 2025 03:15 PM</Scheduled_At>
    <Speakers>Forrest Brazeal, Matt Ball</Speakers>
    <Companies>Augment Code, Augment Code </Companies>
    
    
</250>
<251>
    <Session_ID>933575</Session_ID>
    <Title>The emerging skillset of wielding coding agents</Title>
    <Description>It's raining coding agents. But while many are saying they're feeling the AGI, others say they're not that useful for serious programming. How much is hype and how much is a skill issue? We'll share empirical observations that help explain the divergence of developer opinion. And we'll cover emergent strategies uncovered by users of Amp, a new coding agent in research preview, that can help you employ agents to complete more complex tasks in production codebases.</Description>
    <Session_Format></Session_Format>
    <Level>Introductory and overview</Level>
    <Scope>Technical deep dive</Scope>
    <Assigned_Track></Assigned_Track>
    <Room>Willow: Expo Sessions</Room>
    <Scheduled_At>5 Jun 2025 03:30 PM</Scheduled_At>
    <Speakers>Beyang Liu</Speakers>
    
    
    
</251>
<252>
    <Session_ID>933633</Session_ID>
    <Title>The Eyes Are The (Context) Window to The Soul: How Windsurf Gets to Know You</Title>
    <Description>Sometimes it seems like Windsurf knows you a little too well. It's one thing to generate generic code, but to predict your next intent? From matching existing code patterns and styles to tracking how local changes affect the larger codebase, this talk digs into the technical challenges of context awareness and why simply indexing code falls short. Relive our journey tackling the core issue in the AI IDE space : balancing retrieval quality with latency constraints and scaling effectively as codebases grow. For those curious about the infrastructure behind context-aware AI, this talk offers insights into our approach of turning massive codebases into collections of useful context.</Description>
    <Session_Format>Talk</Session_Format>
    <Level>Intermediate</Level>
    <Scope>Introductory (landscape)</Scope>
    <Assigned_Track></Assigned_Track>
    <Room>Nobhill A&B: Expo Sessions</Room>
    <Scheduled_At>5 Jun 2025 03:30 PM</Scheduled_At>
    <Speakers>Sam  Fertig</Speakers>
    
    
    
</252>
<253>
    <Session_ID>936907</Session_ID>
    <Title>Empowering Developers to build Cutting-Edge AI experiences on device</Title>
    <Description></Description>
    <Session_Format>Talk</Session_Format>
    <Level></Level>
    <Scope></Scope>
    <Assigned_Track></Assigned_Track>
    <Room>Juniper: Expo Sessions</Room>
    <Scheduled_At>5 Jun 2025 03:30 PM</Scheduled_At>
    <Speakers>Emma Ning</Speakers>
    <Companies>Microsoft</Companies>
    
    
</253>
<254>
    <Session_ID>936564</Session_ID>
    <Title>Trends Across the AI Frontier</Title>
    <Description>The entire AI stack is developing faster than ever - from chips to infrastructure to models. How do you sort the signal from the noise? Artificial Analysis an independent benchmarking and insights company dedicated to helping developers and companies pick the right models and technologies for building applications. This talk will walk through the state of the frontier across the AI stack. </Description>
    <Session_Format>Keynote</Session_Format>
    <Level>Introductory and overview</Level>
    <Scope>Introductory (landscape)</Scope>
    <Assigned_Track></Assigned_Track>
    <Room>Keynote/General Session (Yerba Buena 7&8)</Room>
    <Scheduled_At>5 Jun 2025 04:00 PM</Scheduled_At>
    <Speakers>Micah Hill-Smith, George Cameron</Speakers>
    <Companies>Artificial Analysis, Artificial Analysis</Companies>
    
    
</254>
<255>
    <Session_ID>943899</Session_ID>
    <Title>Evals Closing Keynote</Title>
    <Description>The final word on Evals</Description>
    <Session_Format>Keynote</Session_Format>
    <Level></Level>
    <Scope></Scope>
    <Assigned_Track></Assigned_Track>
    <Room>Keynote/General Session (Yerba Buena 7&8)</Room>
    <Scheduled_At>5 Jun 2025 04:20 PM</Scheduled_At>
    <Speakers>Ankur Goyal</Speakers>
    <Companies>Braintrust</Companies>
    
    
</255>
<256>
    <Session_ID>943904</Session_ID>
    <Title>State of AI Engineering 2025</Title>
    <Description>survey results!</Description>
    <Session_Format>Keynote</Session_Format>
    <Level></Level>
    <Scope></Scope>
    <Assigned_Track></Assigned_Track>
    <Room>Keynote/General Session (Yerba Buena 7&8)</Room>
    <Scheduled_At>5 Jun 2025 04:25 PM</Scheduled_At>
    <Speakers>Barr Yaron</Speakers>
    
    
    
</256>
<257>
    <Session_ID>941906</Session_ID>
    <Title>fun stories from building OpenRouter and where all this is going</Title>
    <Description>How the first LLM aggregator got started, some of the weird moments in its early growth, architecture challenges, and where we'll be taking it down the road</Description>
    <Session_Format>Keynote</Session_Format>
    <Level>Intermediate</Level>
    <Scope>Technical deep dive</Scope>
    <Assigned_Track></Assigned_Track>
    <Room>Keynote/General Session (Yerba Buena 7&8)</Room>
    <Scheduled_At>5 Jun 2025 04:35 PM</Scheduled_At>
    <Speakers>Alex Atallah</Speakers>
    <Companies>OpenRouter</Companies>
    
    
</257>
<258>
    <Session_ID>925974</Session_ID>
    <Title>Prompt Engineering is Dead - Everything is a Spec</Title>
    <Description>[!!Subject to change!!]

Large models are trained through mountains of data and learned reward functions, yet - quis custodiet ipsos custodes? - what exactly are those amorphous blobs of data and rewards trying to specify? Building LLMs in any domain demands both clarity of thought and the skill to communicate those thoughts precisely - not only to other humans but to the models themselves. Without either, we risk unpleasant surprises.

This talk dives into:
 • Why prompt spaghetti and data gumbo inevitably collapse at scale, unleashing behaviors we never intended - while a rigorously versioned spec keeps safety, personality, and UX firmly aligned, and makes incidents easier and faster to diagnose and fix.
 • How OpenAI’s public Model Spec provides a clear template, complemented by emerging “dev tools” that turn hazy human intent into precise, human-and-machine-readable policy.
 • How deliberative alignment training teaches models to first read and reason about the spec, boosting robustness without inflating context windows.
 • Practical tactics for catching ambiguity, untangling contradictions, and preserving global consistency. Plus, techniques for verifying that deployed models truly follow the contract we crafted.

Resources: Model Spec (2025‑04‑11) and Deliberative Alignment, Guan et al., 2024.</Description>
    <Session_Format>Keynote</Session_Format>
    <Level>Intermediate</Level>
    <Scope>Introductory (landscape)</Scope>
    <Assigned_Track></Assigned_Track>
    <Room>Keynote/General Session (Yerba Buena 7&8)</Room>
    <Scheduled_At>5 Jun 2025 04:55 PM</Scheduled_At>
    <Speakers>Sean Grove</Speakers>
    <Companies>OpenAI</Companies>
    
    
</258>
<259>
    <Session_ID>936046</Session_ID>
    <Title>AI Engineer World's Fair Hackathon - Grand Prize</Title>
    <Description></Description>
    <Session_Format>Keynote</Session_Format>
    <Level></Level>
    <Scope></Scope>
    <Assigned_Track></Assigned_Track>
    <Room>Keynote/General Session (Yerba Buena 7&8)</Room>
    <Scheduled_At>5 Jun 2025 05:15 PM</Scheduled_At>
    <Speakers>Shawn  Wang, Benjamin Dunphy</Speakers>
    <Companies>unknown, unknown</Companies>
    
    
</259>
