{
  "name": "generateNextMessage",
  "canonicalReference": "@hashbrownai/core!generateNextMessage:function",
  "kind": "Function",
  "fileUrlPath": "../packages/core/src/api/generateNextMessage.ts",
  "isDeprecated": false,
  "members": [
    {
      "kind": "Function",
      "canonicalReference": "@hashbrownai/core!generateNextMessage:function(1)",
      "docComment": "/**\n * Asynchronously generates the next message in a chat conversation.\n *\n * This function uses a generator to yield chunks of chat completion data from a specified API. It constructs a request using the provided configuration, sends it to the API, and processes the response in a streaming manner.\n *\n * @param config - Configuration object for generating the next message.\n *\n * @param  - {typeof fetch} config.fetchImplementation - The fetch implementation to use for making the API request.\n *\n * @param  - {string} config.apiUrl - The URL of the API endpoint to send the request to.\n *\n * @param  - {string} config.model - The model identifier to use for generating the chat completion.\n *\n * @param  - {Chat.Message[]} config.messages - An array of chat messages to include in the request.\n *\n * @param  - {Chat.Tool[]} [config.tools] - Optional array of tools to include in the request.\n *\n * @param  - {number} [config.maxTokens] - Optional maximum number of tokens to generate.\n *\n * @param  - {number} [config.temperature] - Optional temperature setting for the model.\n *\n * @param  - {Chat.ResponseFormat} [config.responseFormat] - Optional response format for the chat completion.\n *\n * @param  - {Array<(requestInit: RequestInit) => RequestInit>} config.middleware - Array of middleware functions to modify the request.\n *\n * @yields {AsyncGenerator<Chat.CompletionChunk>} - An async generator yielding chunks of chat completion data.\n *\n * @throws\n *\n * {Error} - Throws an error if the response is not OK or if the response body is null.\n */\n",
      "excerptTokens": [
        {
          "kind": "Content",
          "text": "export declare function generateNextMessage(config: "
        },
        { "kind": "Content", "text": "{\n    fetchImplementation: typeof " },
        {
          "kind": "Reference",
          "text": "fetch",
          "canonicalReference": "!fetch:function"
        },
        {
          "kind": "Content",
          "text": ";\n    apiUrl: string;\n    model: string;\n    messages: "
        },
        {
          "kind": "Reference",
          "text": "Chat.Message",
          "canonicalReference": "@hashbrownai/core!Chat.Message:type"
        },
        { "kind": "Content", "text": "[];\n    tools?: " },
        {
          "kind": "Reference",
          "text": "Chat.Tool",
          "canonicalReference": "@hashbrownai/core!Chat.Tool:type"
        },
        {
          "kind": "Content",
          "text": "[];\n    maxTokens?: number;\n    temperature?: number;\n    responseFormat?: object;\n    abortSignal?: "
        },
        {
          "kind": "Reference",
          "text": "AbortSignal",
          "canonicalReference": "!AbortSignal:interface"
        },
        { "kind": "Content", "text": ";\n    middleware: " },
        {
          "kind": "Reference",
          "text": "Array",
          "canonicalReference": "!Array:interface"
        },
        { "kind": "Content", "text": "<(requestInit: " },
        {
          "kind": "Reference",
          "text": "RequestInit",
          "canonicalReference": "!RequestInit:interface"
        },
        { "kind": "Content", "text": ") => " },
        {
          "kind": "Reference",
          "text": "RequestInit",
          "canonicalReference": "!RequestInit:interface"
        },
        { "kind": "Content", "text": ">;\n}" },
        { "kind": "Content", "text": "): " },
        {
          "kind": "Reference",
          "text": "AsyncGenerator",
          "canonicalReference": "!AsyncGenerator:interface"
        },
        { "kind": "Content", "text": "<" },
        {
          "kind": "Reference",
          "text": "Chat.CompletionChunk",
          "canonicalReference": "@hashbrownai/core!Chat.CompletionChunk:type"
        },
        { "kind": "Content", "text": ">" },
        { "kind": "Content", "text": ";" }
      ],
      "fileUrlPath": "../packages/core/src/api/generateNextMessage.ts",
      "returnTypeTokenRange": { "startIndex": 17, "endIndex": 21 },
      "releaseTag": "Public",
      "overloadIndex": 1,
      "parameters": [
        {
          "parameterName": "config",
          "parameterTypeTokenRange": { "startIndex": 1, "endIndex": 16 },
          "isOptional": false
        }
      ],
      "name": "generateNextMessage",
      "docs": {
        "modifiers": {
          "isInternal": false,
          "isPublic": false,
          "isAlpha": false,
          "isBeta": false,
          "isOverride": false,
          "isExperimental": false
        },
        "summary": "Asynchronously generates the next message in a chat conversation.\n\nThis function uses a generator to yield chunks of chat completion data from a specified API. It constructs a request using the provided configuration, sends it to the API, and processes the response in a streaming manner.\n\n",
        "usageNotes": "",
        "remarks": "",
        "deprecated": "",
        "returns": "",
        "see": [],
        "params": [
          {
            "name": "config",
            "description": "Configuration object for generating the next message.\n\n"
          },
          {
            "name": "",
            "description": "  - {typeof fetch} config.fetchImplementation - The fetch implementation to use for making the API request.\n\n"
          },
          {
            "name": "",
            "description": "  - {string} config.apiUrl - The URL of the API endpoint to send the request to.\n\n"
          },
          {
            "name": "",
            "description": "  - {string} config.model - The model identifier to use for generating the chat completion.\n\n"
          },
          {
            "name": "",
            "description": "  - {Chat.Message[]} config.messages - An array of chat messages to include in the request.\n\n"
          },
          {
            "name": "",
            "description": "  - {Chat.Tool[]} [config.tools] - Optional array of tools to include in the request.\n\n"
          },
          {
            "name": "",
            "description": "  - {number} [config.maxTokens] - Optional maximum number of tokens to generate.\n\n"
          },
          {
            "name": "",
            "description": "  - {number} [config.temperature] - Optional temperature setting for the model.\n\n"
          },
          {
            "name": "",
            "description": "  - {Chat.ResponseFormat} [config.responseFormat] - Optional response format for the chat completion.\n\n"
          },
          {
            "name": "",
            "description": "  - {Array<(requestInit: RequestInit) => RequestInit>} config.middleware - Array of middleware functions to modify the request.\n\n@yields {AsyncGenerator<Chat.CompletionChunk>} - An async generator yielding chunks of chat completion data.\n\n"
          }
        ]
      }
    }
  ]
}
